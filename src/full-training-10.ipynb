{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from modules.utils import load_cifar10, load_cifar100\n",
    "from modules.cnn_with_spectral_pooling import CNN_Spectral_Pool\n",
    "\n",
    "% matplotlib inline\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download CIFAR data, if necessary, and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already downloaded..\n",
      "getting batch 1\n",
      "getting batch 2\n",
      "getting batch 3\n",
      "getting batch 4\n",
      "getting batch 5\n"
     ]
    }
   ],
   "source": [
    "xtrain, ytrain, xtest, ytest = load_cifar10(num_batches=5, get_test_data=True, channels_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 3, 32, 32), (50000,), (10000, 3, 32, 32), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape, ytrain.shape, xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build graph with optimal hyperparametersgraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modules.cnn_with_spectral_pooling import CNN_Spectral_Pool\n",
    "validation_size = 4096\n",
    "\n",
    "cnn = CNN_Spectral_Pool(M=7,\n",
    "                        num_output=10,\n",
    "                        verbose=True,\n",
    "                        learning_rate=1.09e-3,\n",
    "                        l2_norm=2.7e-5,\n",
    "                        lr_reduction_factor=0.5,\n",
    "                        lr_reduction_epochs=[11,21,31,41],\n",
    "                        gamma=0.6336)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tf graph...\n",
      "Adding conv layer 1 | Input size: 32 | Input channels: 3 | #filters: 128 | filter size: 3\n",
      "Adding spectral pool layer 1 | Input size: 32 | filter size: (20,20) | Freq Dropout Bounds: (3.0642857142857145,11.0)\n",
      "Adding conv layer 2 | Input size: 20 | Input channels: 128 | #filters: 160 | filter size: 3\n",
      "Adding spectral pool layer 2 | Input size: 20 | filter size: (12,12) | Freq Dropout Bounds: (1.7999999999999998,7.0)\n",
      "Adding conv layer 3 | Input size: 12 | Input channels: 160 | #filters: 192 | filter size: 3\n",
      "Adding spectral pool layer 3 | Input size: 12 | filter size: (7,7) | Freq Dropout Bounds: (0.9428571428571428,4.0)\n",
      "Adding conv layer 4 | Input size: 7 | Input channels: 192 | #filters: 224 | filter size: 3\n",
      "Adding spectral pool layer 4 | Input size: 7 | filter size: (4,4) | Freq Dropout Bounds: (0.6428571428571429,3.0)\n",
      "Adding conv layer 5 | Input size: 4 | Input channels: 224 | #filters: 256 | filter size: 3\n",
      "Adding spectral pool layer 5 | Input size: 4 | filter size: (3,3) | Freq Dropout Bounds: (0.3857142857142857,2.0)\n",
      "Adding conv layer 6 | Input size: 3 | Input channels: 256 | #filters: 288 | filter size: 3\n",
      "Adding spectral pool layer 6 | Input size: 3 | filter size: (3,3) | Freq Dropout Bounds: (0.34285714285714286,2.0)\n",
      "Adding conv layer 7 | Input size: 3 | Input channels: 288 | #filters: 288 | filter size: 3\n",
      "Adding spectral pool layer 7 | Input size: 3 | filter size: (3,3) | Freq Dropout Bounds: (0.3,2.0)\n",
      "Adding conv layer 8 | Input size: 3 | Input channels: 288 | #filters: 288 | filter size: 1\n",
      "Adding conv layer 9 | Input size: 3 | Input channels: 288 | #filters: 10 | filter size: 1\n",
      "Adding final softmax layer using global averaging\n",
      "(?, 10)\n",
      "number of batches for training: 179 validation: 16\n",
      "training epoch 1 \n",
      "45824/45904 loss: 2.244171380996704 | training accuracy: 15.675% | validation accuracy : 25.708%\n",
      "\n",
      "\tBest validation accuracy! iteration:179 accuracy: 25.7080078125%\n",
      "\n",
      "training epoch 2 \n",
      "45824/45904 loss: 1.8324254751205444 | training accuracy: 31.411% | validation accuracy : 38.086%\n",
      "\n",
      "\tBest validation accuracy! iteration:358 accuracy: 38.0859375%\n",
      "\n",
      "training epoch 3 \n",
      "45824/45904 loss: 1.6047168970108032 | training accuracy: 40.411% | validation accuracy : 44.092%\n",
      "\n",
      "\tBest validation accuracy! iteration:537 accuracy: 44.091796875%\n",
      "\n",
      "training epoch 4 \n",
      "45824/45904 loss: 1.4764772653579712 | training accuracy: 46.033% | validation accuracy : 51.538%\n",
      "\n",
      "\tBest validation accuracy! iteration:716 accuracy: 51.5380859375%\n",
      "\n",
      "training epoch 5 \n",
      "45824/45904 loss: 1.3491913080215454 | training accuracy: 51.207% | validation accuracy : 51.343%\n",
      "training epoch 6 \n",
      "45824/45904 loss: 1.2961852550506592 | training accuracy: 53.254% | validation accuracy : 54.883%\n",
      "\n",
      "\tBest validation accuracy! iteration:1074 accuracy: 54.8828125%\n",
      "\n",
      "training epoch 7 \n",
      "45824/45904 loss: 1.2538975477218628 | training accuracy: 54.768% | validation accuracy : 57.422%\n",
      "\n",
      "\tBest validation accuracy! iteration:1253 accuracy: 57.421875%\n",
      "\n",
      "training epoch 8 \n",
      "45824/45904 loss: 1.172356128692627 | training accuracy: 58.413% | validation accuracy : 60.498%\n",
      "\n",
      "\tBest validation accuracy! iteration:1432 accuracy: 60.498046875%\n",
      "\n",
      "training epoch 9 \n",
      "45824/45904 loss: 1.1126123666763306 | training accuracy: 60.348% | validation accuracy : 64.087%\n",
      "\n",
      "\tBest validation accuracy! iteration:1611 accuracy: 64.0869140625%\n",
      "\n",
      "training epoch 10 \n",
      "45824/45904 loss: 1.0765533447265625 | training accuracy: 61.745% | validation accuracy : 63.965%\n",
      "training epoch 11 \n",
      "\tLearning rate reduced to 5.4500e-04 at epoch 11\n",
      "45824/45904 loss: 0.952730119228363 | training accuracy: 66.236% | validation accuracy : 66.479%\n",
      "\n",
      "\tBest validation accuracy! iteration:1969 accuracy: 66.4794921875%\n",
      "\n",
      "training epoch 12 \n",
      "45824/45904 loss: 0.9234063625335693 | training accuracy: 67.388% | validation accuracy : 68.042%\n",
      "\n",
      "\tBest validation accuracy! iteration:2148 accuracy: 68.0419921875%\n",
      "\n",
      "training epoch 13 \n",
      "45824/45904 loss: 0.878514289855957 | training accuracy: 69.154% | validation accuracy : 69.238%\n",
      "\n",
      "\tBest validation accuracy! iteration:2327 accuracy: 69.23828125%\n",
      "\n",
      "training epoch 14 \n",
      "45824/45904 loss: 0.8419631123542786 | training accuracy: 70.415% | validation accuracy : 69.849%\n",
      "\n",
      "\tBest validation accuracy! iteration:2506 accuracy: 69.8486328125%\n",
      "\n",
      "training epoch 15 \n",
      "45824/45904 loss: 0.8324477672576904 | training accuracy: 70.616% | validation accuracy : 69.849%\n",
      "training epoch 16 \n",
      "45824/45904 loss: 0.8044774532318115 | training accuracy: 71.674% | validation accuracy : 68.872%\n",
      "training epoch 17 \n",
      "45824/45904 loss: 0.7872147560119629 | training accuracy: 72.172% | validation accuracy : 70.239%\n",
      "\n",
      "\tBest validation accuracy! iteration:3043 accuracy: 70.2392578125%\n",
      "\n",
      "training epoch 18 \n",
      "45824/45904 loss: 0.7695176005363464 | training accuracy: 73.062% | validation accuracy : 70.972%\n",
      "\n",
      "\tBest validation accuracy! iteration:3222 accuracy: 70.9716796875%\n",
      "\n",
      "training epoch 19 \n",
      "45824/45904 loss: 0.725149393081665 | training accuracy: 74.481% | validation accuracy : 71.826%\n",
      "\n",
      "\tBest validation accuracy! iteration:3401 accuracy: 71.826171875%\n",
      "\n",
      "training epoch 20 \n",
      "45824/45904 loss: 0.7261724472045898 | training accuracy: 74.393% | validation accuracy : 71.191%\n",
      "training epoch 21 \n",
      "\tLearning rate reduced to 2.7250e-04 at epoch 21\n",
      "45824/45904 loss: 0.6702477931976318 | training accuracy: 76.401% | validation accuracy : 72.363%\n",
      "\n",
      "\tBest validation accuracy! iteration:3759 accuracy: 72.36328125%\n",
      "\n",
      "training epoch 22 \n",
      "45824/45904 loss: 0.6297585964202881 | training accuracy: 77.985% | validation accuracy : 71.484%\n",
      "training epoch 23 \n",
      "45824/45904 loss: 0.6047140955924988 | training accuracy: 78.712% | validation accuracy : 72.607%\n",
      "\n",
      "\tBest validation accuracy! iteration:4117 accuracy: 72.607421875%\n",
      "\n",
      "training epoch 24 \n",
      "45824/45904 loss: 0.5988898277282715 | training accuracy: 78.834% | validation accuracy : 72.290%\n",
      "training epoch 25 \n",
      "45824/45904 loss: 0.5870358943939209 | training accuracy: 79.399% | validation accuracy : 72.485%\n",
      "training epoch 26 \n",
      "45824/45904 loss: 0.5590182542800903 | training accuracy: 80.412% | validation accuracy : 72.876%\n",
      "\n",
      "\tBest validation accuracy! iteration:4654 accuracy: 72.8759765625%\n",
      "\n",
      "training epoch 27 \n",
      "45824/45904 loss: 0.5480164885520935 | training accuracy: 80.879% | validation accuracy : 72.925%\n",
      "\n",
      "\tBest validation accuracy! iteration:4833 accuracy: 72.9248046875%\n",
      "\n",
      "training epoch 28 \n",
      "45824/45904 loss: 0.5471938848495483 | training accuracy: 80.892% | validation accuracy : 73.389%\n",
      "\n",
      "\tBest validation accuracy! iteration:5012 accuracy: 73.388671875%\n",
      "\n",
      "training epoch 29 \n",
      "45824/45904 loss: 0.5242722034454346 | training accuracy: 81.604% | validation accuracy : 73.438%\n",
      "\n",
      "\tBest validation accuracy! iteration:5191 accuracy: 73.4375%\n",
      "\n",
      "training epoch 30 \n",
      "45824/45904 loss: 0.4988156855106354 | training accuracy: 82.544% | validation accuracy : 73.340%\n",
      "training epoch 31 \n",
      "\tLearning rate reduced to 1.3625e-04 at epoch 31\n",
      "45824/45904 loss: 0.4698657989501953 | training accuracy: 83.533% | validation accuracy : 74.268%\n",
      "\n",
      "\tBest validation accuracy! iteration:5549 accuracy: 74.267578125%\n",
      "\n",
      "training epoch 32 \n",
      "45824/45904 loss: 0.4712168872356415 | training accuracy: 83.504% | validation accuracy : 73.682%\n",
      "training epoch 33 \n",
      "45824/45904 loss: 0.4363350570201874 | training accuracy: 84.864% | validation accuracy : 73.950%\n",
      "training epoch 34 \n",
      "45824/45904 loss: 0.43797796964645386 | training accuracy: 84.814% | validation accuracy : 73.730%\n",
      "training epoch 35 \n",
      "45824/45904 loss: 0.43797072768211365 | training accuracy: 84.966% | validation accuracy : 73.755%\n",
      "training epoch 36 \n",
      "45824/45904 loss: 0.4154472053050995 | training accuracy: 85.632% | validation accuracy : 73.267%\n",
      "training epoch 37 \n",
      "45824/45904 loss: 0.40897637605667114 | training accuracy: 85.724% | validation accuracy : 74.536%\n",
      "\n",
      "\tBest validation accuracy! iteration:6623 accuracy: 74.5361328125%\n",
      "\n",
      "training epoch 38 \n",
      "45824/45904 loss: 0.38628676533699036 | training accuracy: 86.802% | validation accuracy : 73.511%\n",
      "training epoch 39 \n",
      "45824/45904 loss: 0.4012337327003479 | training accuracy: 86.171% | validation accuracy : 74.292%\n",
      "training epoch 40 \n",
      "45824/45904 loss: 0.3833023011684418 | training accuracy: 86.896% | validation accuracy : 74.170%\n",
      "training epoch 41 \n",
      "\tLearning rate reduced to 6.8125e-05 at epoch 41\n",
      "45824/45904 loss: 0.3718864321708679 | training accuracy: 87.336% | validation accuracy : 73.779%\n",
      "training epoch 42 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45824/45904 loss: 0.3729507327079773 | training accuracy: 87.181% | validation accuracy : 73.462%\n",
      "training epoch 43 \n",
      "45824/45904 loss: 0.35515356063842773 | training accuracy: 87.891% | validation accuracy : 74.097%\n",
      "training epoch 44 \n",
      "45824/45904 loss: 0.3369365632534027 | training accuracy: 88.473% | validation accuracy : 74.146%\n",
      "training epoch 45 \n",
      "45824/45904 loss: 0.3236543536186218 | training accuracy: 88.822% | validation accuracy : 73.950%\n",
      "training epoch 46 \n",
      "45824/45904 loss: 0.32767200469970703 | training accuracy: 88.842% | validation accuracy : 74.512%\n",
      "training epoch 47 \n",
      "45824/45904 loss: 0.3159792125225067 | training accuracy: 89.353% | validation accuracy : 73.535%\n",
      "training epoch 48 \n",
      "45824/45904 loss: 0.3018873929977417 | training accuracy: 89.848% | validation accuracy : 73.608%\n",
      "training epoch 49 \n",
      "45824/45904 loss: 0.3186611533164978 | training accuracy: 89.351% | validation accuracy : 74.072%\n",
      "training epoch 50 \n",
      "45824/45904 loss: 0.314355731010437 | training accuracy: 89.307% | validation accuracy : 73.755%\n",
      "Best validation accuracy: 74.536%; Model name: 'optimal_hyperparams/optimal_hyperparams_1513542547.9187834'.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "cnn.train(xtrain[:-validation_size],\n",
    "          ytrain[:-validation_size],\n",
    "          xtrain[-validation_size:],\n",
    "          ytrain[-validation_size:],\n",
    "          batch_size=256,\n",
    "          epochs=50,\n",
    "          extra_conv_layer=True,\n",
    "          use_global_averaging=True,\n",
    "          model_name='optimal_hyperparams'\n",
    ")\n",
    "full_model_name = cnn.full_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tf graph...\n",
      "Adding conv layer 1 | Input size: 32 | Input channels: 3 | #filters: 128 | filter size: 3\n",
      "Adding spectral pool layer 1 | Input size: 32 | filter size: (20,20) | Freq Dropout Bounds: (3.0642857142857145,11.0)\n",
      "Adding conv layer 2 | Input size: 20 | Input channels: 128 | #filters: 160 | filter size: 3\n",
      "Adding spectral pool layer 2 | Input size: 20 | filter size: (12,12) | Freq Dropout Bounds: (1.7999999999999998,7.0)\n",
      "Adding conv layer 3 | Input size: 12 | Input channels: 160 | #filters: 192 | filter size: 3\n",
      "Adding spectral pool layer 3 | Input size: 12 | filter size: (7,7) | Freq Dropout Bounds: (0.9428571428571428,4.0)\n",
      "Adding conv layer 4 | Input size: 7 | Input channels: 192 | #filters: 224 | filter size: 3\n",
      "Adding spectral pool layer 4 | Input size: 7 | filter size: (4,4) | Freq Dropout Bounds: (0.6428571428571429,3.0)\n",
      "Adding conv layer 5 | Input size: 4 | Input channels: 224 | #filters: 256 | filter size: 3\n",
      "Adding spectral pool layer 5 | Input size: 4 | filter size: (3,3) | Freq Dropout Bounds: (0.3857142857142857,2.0)\n",
      "Adding conv layer 6 | Input size: 3 | Input channels: 256 | #filters: 288 | filter size: 3\n",
      "Adding spectral pool layer 6 | Input size: 3 | filter size: (3,3) | Freq Dropout Bounds: (0.34285714285714286,2.0)\n",
      "Adding conv layer 7 | Input size: 3 | Input channels: 288 | #filters: 288 | filter size: 3\n",
      "Adding spectral pool layer 7 | Input size: 3 | filter size: (3,3) | Freq Dropout Bounds: (0.3,2.0)\n",
      "Adding conv layer 8 | Input size: 3 | Input channels: 288 | #filters: 288 | filter size: 1\n",
      "Adding conv layer 9 | Input size: 3 | Input channels: 288 | #filters: 10 | filter size: 1\n",
      "Adding final softmax layer using global averaging\n",
      "(?, 10)\n",
      "number of batches for testing: 20\n",
      "Loading pre-trained model\n",
      "INFO:tensorflow:Restoring parameters from model/optimal_hyperparams/optimal_hyperparams_1513542547.9187834\n",
      "Test accuracy: 72.370\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "cnn.calc_test_accuracy(xtest, ytest, 'optimal_hyperparams/optimal_hyperparams_1513542547.9187834')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best result from manual tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tf graph...\n",
      "Adding conv layer 1 | Input size: 32 | Input channels: 3 | #filters: 128 | filter size: 3\n",
      "Adding spectral pool layer 1 | Input size: 32 | filter size: (25,25) | Freq Dropout Bounds: (3.5749999999999997,13.0)\n",
      "Adding conv layer 2 | Input size: 25 | Input channels: 128 | #filters: 160 | filter size: 3\n",
      "Adding spectral pool layer 2 | Input size: 25 | filter size: (19,19) | Freq Dropout Bounds: (2.5,10.0)\n",
      "Adding conv layer 3 | Input size: 19 | Input channels: 160 | #filters: 192 | filter size: 3\n",
      "Adding spectral pool layer 3 | Input size: 19 | filter size: (15,15) | Freq Dropout Bounds: (1.7999999999999998,8.0)\n",
      "Adding conv layer 4 | Input size: 15 | Input channels: 192 | #filters: 224 | filter size: 3\n",
      "Adding spectral pool layer 4 | Input size: 15 | filter size: (11,11) | Freq Dropout Bounds: (1.2000000000000002,6.0)\n",
      "Adding conv layer 5 | Input size: 11 | Input channels: 224 | #filters: 256 | filter size: 3\n",
      "Adding spectral pool layer 5 | Input size: 11 | filter size: (8,8) | Freq Dropout Bounds: (0.875,5.0)\n",
      "Adding conv layer 6 | Input size: 8 | Input channels: 256 | #filters: 288 | filter size: 3\n",
      "Adding spectral pool layer 6 | Input size: 8 | filter size: (6,6) | Freq Dropout Bounds: (0.6,4.0)\n",
      "Adding conv layer 7 | Input size: 6 | Input channels: 288 | #filters: 288 | filter size: 1\n",
      "Adding conv layer 8 | Input size: 6 | Input channels: 288 | #filters: 10 | filter size: 1\n",
      "Adding final softmax layer using global averaging\n",
      "(?, 10)\n",
      "number of batches for testing: 20\n",
      "Loading pre-trained model\n",
      "INFO:tensorflow:Restoring parameters from model/best_cifar_10/test_1513443174.5236883\n",
      "Test accuracy: 81.240\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "cnn = CNN_Spectral_Pool(M=6,\n",
    "                        num_output=10,\n",
    "                        verbose=True,\n",
    "                        gamma=0.79)\n",
    "cnn.calc_test_accuracy(xtest, ytest, 'best_cifar_10/test_1513443174.5236883')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
