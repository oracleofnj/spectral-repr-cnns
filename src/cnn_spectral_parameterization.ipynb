{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=1)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from modules.utils import load_cifar10\n",
    "from modules.cnn_with_spectral_parameterization import CNN_Spectral_Param\n",
    "from modules.cnn_with_spectral_pooling import CNN_Spectral_Pool\n",
    "\n",
    "% matplotlib inline\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already downloaded..\n",
      "getting batch 1\n"
     ]
    }
   ],
   "source": [
    "# In the interest of training time, we only used 1 of 5 cifar10 batches\n",
    "# The important part of the experiment is to compare the rates of convergence of training accuracy,\n",
    "# so subsetting the training dataset for both spectral and spatial models shouldn't impact\n",
    "# the relationship between their train accuracy convergences\n",
    "xtrain, ytrain, xtest, ytest = load_cifar10(1, channels_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 32, 32, 3), (10000,), (10000, 32, 32, 3), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape, ytrain.shape, xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_error_rate(name, error_rates):\n",
    "    with open('error_rates/' + name + '.txt', 'w') as f:\n",
    "        for err in error_rates:\n",
    "            f.write(\"%s\\n\" % err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches for training: 78\n",
      "epoch 1 \n",
      "Error rate: 0.712039262821\n",
      "Train acc: 0.287960737179\n",
      "Loss: 3.91446\n",
      "epoch 2 \n",
      "Error rate: 0.577724358974\n",
      "Train acc: 0.422275641026\n",
      "Loss: 3.46335\n",
      "epoch 3 \n",
      "Error rate: 0.53125\n",
      "Train acc: 0.46875\n",
      "Loss: 3.26634\n",
      "epoch 4 \n",
      "Error rate: 0.511017628205\n",
      "Train acc: 0.488982371795\n",
      "Loss: 3.17378\n",
      "epoch 5 \n",
      "Error rate: 0.475060096154\n",
      "Train acc: 0.524939903846\n",
      "Loss: 3.04977\n",
      "epoch 6 \n",
      "Error rate: 0.457532051282\n",
      "Train acc: 0.542467948718\n",
      "Loss: 2.98689\n",
      "epoch 7 \n",
      "Error rate: 0.424679487179\n",
      "Train acc: 0.575320512821\n",
      "Loss: 2.86349\n",
      "epoch 8 \n",
      "Error rate: 0.433493589744\n",
      "Train acc: 0.566506410256\n",
      "Loss: 2.863\n",
      "epoch 9 \n",
      "Error rate: 0.410757211538\n",
      "Train acc: 0.589242788462\n",
      "Loss: 2.78472\n",
      "epoch 10 \n",
      "Error rate: 0.407451923077\n",
      "Train acc: 0.592548076923\n",
      "Loss: 2.75034\n",
      "epoch 11 \n",
      "Error rate: 0.366486378205\n",
      "Train acc: 0.633513621795\n",
      "Loss: 2.62025\n",
      "epoch 12 \n",
      "Error rate: 0.38671875\n",
      "Train acc: 0.61328125\n",
      "Loss: 2.65171\n",
      "epoch 13 \n",
      "Error rate: 0.346754807692\n",
      "Train acc: 0.653245192308\n",
      "Loss: 2.53756\n",
      "epoch 14 \n",
      "Error rate: 0.380408653846\n",
      "Train acc: 0.619591346154\n",
      "Loss: 2.62671\n",
      "epoch 15 \n",
      "Error rate: 0.32952724359\n",
      "Train acc: 0.67047275641\n",
      "Loss: 2.46842\n",
      "epoch 16 \n",
      "Error rate: 0.351862980769\n",
      "Train acc: 0.648137019231\n",
      "Loss: 2.5055\n",
      "epoch 17 \n",
      "Error rate: 0.352764423077\n",
      "Train acc: 0.647235576923\n",
      "Loss: 2.48667\n",
      "epoch 18 \n",
      "Error rate: 0.35546875\n",
      "Train acc: 0.64453125\n",
      "Loss: 2.49349\n",
      "epoch 19 \n",
      "Error rate: 0.313201121795\n",
      "Train acc: 0.686798878205\n",
      "Loss: 2.38171\n",
      "epoch 20 \n",
      "Error rate: 0.321915064103\n",
      "Train acc: 0.678084935897\n",
      "Loss: 2.39101\n",
      "epoch 21 \n",
      "Error rate: 0.285256410256\n",
      "Train acc: 0.714743589744\n",
      "Loss: 2.28863\n",
      "epoch 22 \n",
      "Error rate: 0.322215544872\n",
      "Train acc: 0.677784455128\n",
      "Loss: 2.3644\n",
      "epoch 23 \n",
      "Error rate: 0.295372596154\n",
      "Train acc: 0.704627403846\n",
      "Loss: 2.29502\n",
      "epoch 24 \n",
      "Error rate: 0.338241185897\n",
      "Train acc: 0.661758814103\n",
      "Loss: 2.38639\n",
      "epoch 25 \n",
      "Error rate: 0.271734775641\n",
      "Train acc: 0.728265224359\n",
      "Loss: 2.21689\n",
      "epoch 26 \n",
      "Error rate: 0.310897435897\n",
      "Train acc: 0.689102564103\n",
      "Loss: 2.28613\n",
      "epoch 27 \n",
      "Error rate: 0.25921474359\n",
      "Train acc: 0.74078525641\n",
      "Loss: 2.15307\n",
      "epoch 28 \n",
      "Error rate: 0.297876602564\n",
      "Train acc: 0.702123397436\n",
      "Loss: 2.24196\n",
      "epoch 29 \n",
      "Error rate: 0.263521634615\n",
      "Train acc: 0.736478365385\n",
      "Loss: 2.15019\n",
      "epoch 30 \n",
      "Error rate: 0.283153044872\n",
      "Train acc: 0.716846955128\n",
      "Loss: 2.19453\n",
      "epoch 31 \n",
      "Error rate: 0.241586538462\n",
      "Train acc: 0.758413461538\n",
      "Loss: 2.07905\n",
      "epoch 32 \n",
      "Error rate: 0.266326121795\n",
      "Train acc: 0.733673878205\n",
      "Loss: 2.1309\n",
      "epoch 33 \n",
      "Error rate: 0.231470352564\n",
      "Train acc: 0.768529647436\n",
      "Loss: 2.03304\n",
      "epoch 34 \n",
      "Error rate: 0.279747596154\n",
      "Train acc: 0.720252403846\n",
      "Loss: 2.14275\n",
      "epoch 35 \n",
      "Error rate: 0.250801282051\n",
      "Train acc: 0.749198717949\n",
      "Loss: 2.06852\n",
      "epoch 36 \n",
      "Error rate: 0.293469551282\n",
      "Train acc: 0.706530448718\n",
      "Loss: 2.17781\n",
      "epoch 37 \n",
      "Error rate: 0.206129807692\n",
      "Train acc: 0.793870192308\n",
      "Loss: 1.95671\n",
      "epoch 38 \n",
      "Error rate: 0.251602564103\n",
      "Train acc: 0.748397435897\n",
      "Loss: 2.05343\n",
      "epoch 39 \n",
      "Error rate: 0.197115384615\n",
      "Train acc: 0.802884615385\n",
      "Loss: 1.91613\n",
      "epoch 40 \n",
      "Error rate: 0.240284455128\n",
      "Train acc: 0.759715544872\n",
      "Loss: 2.01785\n",
      "epoch 41 \n",
      "Error rate: 0.22796474359\n",
      "Train acc: 0.77203525641\n",
      "Loss: 1.98265\n",
      "epoch 42 \n",
      "Error rate: 0.236177884615\n",
      "Train acc: 0.763822115385\n",
      "Loss: 1.99073\n",
      "epoch 43 \n",
      "Error rate: 0.167868589744\n",
      "Train acc: 0.832131410256\n",
      "Loss: 1.83728\n",
      "epoch 44 \n",
      "Error rate: 0.268329326923\n",
      "Train acc: 0.731670673077\n",
      "Loss: 2.07093\n",
      "epoch 45 \n",
      "Error rate: 0.206129807692\n",
      "Train acc: 0.793870192308\n",
      "Loss: 1.90434\n",
      "epoch 46 \n",
      "Error rate: 0.242888621795\n",
      "Train acc: 0.757111378205\n",
      "Loss: 1.99563\n",
      "epoch 47 \n",
      "Error rate: 0.186498397436\n",
      "Train acc: 0.813501602564\n",
      "Loss: 1.84888\n",
      "epoch 48 \n",
      "Error rate: 0.220252403846\n",
      "Train acc: 0.779747596154\n",
      "Loss: 1.9253\n",
      "epoch 49 \n",
      "Error rate: 0.155148237179\n",
      "Train acc: 0.844851762821\n",
      "Loss: 1.77203\n",
      "epoch 50 \n",
      "Error rate: 0.218449519231\n",
      "Train acc: 0.781550480769\n",
      "Loss: 1.92902\n",
      "epoch 51 \n",
      "Error rate: 0.163461538462\n",
      "Train acc: 0.836538461538\n",
      "Loss: 1.78779\n",
      "epoch 52 \n",
      "Error rate: 0.226362179487\n",
      "Train acc: 0.773637820513\n",
      "Loss: 1.92176\n",
      "epoch 53 \n",
      "Error rate: 0.151742788462\n",
      "Train acc: 0.848257211538\n",
      "Loss: 1.75418\n",
      "epoch 54 \n",
      "Error rate: 0.203926282051\n",
      "Train acc: 0.796073717949\n",
      "Loss: 1.86436\n",
      "epoch 55 \n",
      "Error rate: 0.131109775641\n",
      "Train acc: 0.868890224359\n",
      "Loss: 1.69244\n",
      "epoch 56 \n",
      "Error rate: 0.22405849359\n",
      "Train acc: 0.77594150641\n",
      "Loss: 1.90898\n",
      "epoch 57 \n",
      "Error rate: 0.145532852564\n",
      "Train acc: 0.854467147436\n",
      "Loss: 1.72133\n",
      "epoch 58 \n",
      "Error rate: 0.180789262821\n",
      "Train acc: 0.819210737179\n",
      "Loss: 1.80319\n",
      "epoch 59 \n",
      "Error rate: 0.133012820513\n",
      "Train acc: 0.866987179487\n",
      "Loss: 1.68505\n",
      "epoch 60 \n",
      "Error rate: 0.185797275641\n",
      "Train acc: 0.814202724359\n",
      "Loss: 1.80539\n",
      "epoch 61 \n",
      "Error rate: 0.118189102564\n",
      "Train acc: 0.881810897436\n",
      "Loss: 1.64412\n",
      "epoch 62 \n",
      "Error rate: 0.176482371795\n",
      "Train acc: 0.823517628205\n",
      "Loss: 1.77448\n",
      "epoch 63 \n",
      "Error rate: 0.0991586538462\n",
      "Train acc: 0.900841346154\n",
      "Loss: 1.6018\n",
      "epoch 64 \n",
      "Error rate: 0.157051282051\n",
      "Train acc: 0.842948717949\n",
      "Loss: 1.71971\n",
      "epoch 65 \n",
      "Error rate: 0.0841346153846\n",
      "Train acc: 0.915865384615\n",
      "Loss: 1.55939\n",
      "epoch 66 \n",
      "Error rate: 0.188100961538\n",
      "Train acc: 0.811899038462\n",
      "Loss: 1.79452\n",
      "epoch 67 \n",
      "Error rate: 0.0792267628205\n",
      "Train acc: 0.920773237179\n",
      "Loss: 1.54431\n",
      "epoch 68 \n",
      "Error rate: 0.135516826923\n",
      "Train acc: 0.864483173077\n",
      "Loss: 1.66059\n",
      "epoch 69 \n",
      "Error rate: 0.133213141026\n",
      "Train acc: 0.866786858974\n",
      "Loss: 1.6544\n",
      "epoch 70 \n",
      "Error rate: 0.158954326923\n",
      "Train acc: 0.841045673077\n",
      "Loss: 1.71101\n",
      "epoch 71 \n",
      "Error rate: 0.0974559294872\n",
      "Train acc: 0.902544070513\n",
      "Loss: 1.56479\n",
      "epoch 72 \n",
      "Error rate: 0.168269230769\n",
      "Train acc: 0.831730769231\n",
      "Loss: 1.72058\n",
      "epoch 73 \n",
      "Error rate: 0.088141025641\n",
      "Train acc: 0.911858974359\n",
      "Loss: 1.54177\n",
      "epoch 74 \n",
      "Error rate: 0.133914262821\n",
      "Train acc: 0.866085737179\n",
      "Loss: 1.64868\n",
      "epoch 75 \n",
      "Error rate: 0.0741185897436\n",
      "Train acc: 0.925881410256\n",
      "Loss: 1.50975\n",
      "epoch 76 \n",
      "Error rate: 0.149338942308\n",
      "Train acc: 0.850661057692\n",
      "Loss: 1.67042\n",
      "epoch 77 \n",
      "Error rate: 0.064202724359\n",
      "Train acc: 0.935797275641\n",
      "Loss: 1.4838\n",
      "epoch 78 \n",
      "Error rate: 0.101362179487\n",
      "Train acc: 0.898637820513\n",
      "Loss: 1.56502\n",
      "epoch 79 \n",
      "Error rate: 0.0896434294872\n",
      "Train acc: 0.910356570513\n",
      "Loss: 1.52483\n",
      "epoch 80 \n",
      "Error rate: 0.12750400641\n",
      "Train acc: 0.87249599359\n",
      "Loss: 1.60967\n",
      "epoch 81 \n",
      "Error rate: 0.0790264423077\n",
      "Train acc: 0.920973557692\n",
      "Loss: 1.50158\n",
      "epoch 82 \n",
      "Error rate: 0.0995592948718\n",
      "Train acc: 0.900440705128\n",
      "Loss: 1.55841\n",
      "epoch 83 \n",
      "Error rate: 0.0496794871795\n",
      "Train acc: 0.950320512821\n",
      "Loss: 1.43167\n",
      "epoch 84 \n",
      "Error rate: 0.137319711538\n",
      "Train acc: 0.862680288462\n",
      "Loss: 1.62816\n",
      "epoch 85 \n",
      "Error rate: 0.0549879807692\n",
      "Train acc: 0.945012019231\n",
      "Loss: 1.44612\n",
      "epoch 86 \n",
      "Error rate: 0.0951522435897\n",
      "Train acc: 0.90484775641\n",
      "Loss: 1.53142\n",
      "epoch 87 \n",
      "Error rate: 0.0513822115385\n",
      "Train acc: 0.948617788462\n",
      "Loss: 1.42798\n",
      "epoch 88 \n",
      "Error rate: 0.105869391026\n",
      "Train acc: 0.894130608974\n",
      "Loss: 1.54742\n",
      "epoch 89 \n",
      "Error rate: 0.0390625\n",
      "Train acc: 0.9609375\n",
      "Loss: 1.40207\n",
      "epoch 90 \n",
      "Error rate: 0.128605769231\n",
      "Train acc: 0.871394230769\n",
      "Loss: 1.596\n",
      "epoch 91 \n",
      "Error rate: 0.0579927884615\n",
      "Train acc: 0.942007211538\n",
      "Loss: 1.43328\n",
      "epoch 92 \n",
      "Error rate: 0.0865384615385\n",
      "Train acc: 0.913461538462\n",
      "Loss: 1.50394\n",
      "epoch 93 \n",
      "Error rate: 0.0302483974359\n",
      "Train acc: 0.969751602564\n",
      "Loss: 1.36563\n",
      "epoch 94 \n",
      "Error rate: 0.0805288461538\n",
      "Train acc: 0.919471153846\n",
      "Loss: 1.48571\n",
      "epoch 95 \n",
      "Error rate: 0.0262419871795\n",
      "Train acc: 0.973758012821\n",
      "Loss: 1.35439\n",
      "epoch 96 \n",
      "Error rate: 0.0667067307692\n",
      "Train acc: 0.933293269231\n",
      "Loss: 1.44844\n",
      "epoch 97 \n",
      "Error rate: 0.0474759615385\n",
      "Train acc: 0.952524038462\n",
      "Loss: 1.40033\n",
      "epoch 98 \n",
      "Error rate: 0.117988782051\n",
      "Train acc: 0.882011217949\n",
      "Loss: 1.55768\n",
      "epoch 99 \n",
      "Error rate: 0.01953125\n",
      "Train acc: 0.98046875\n",
      "Loss: 1.33235\n",
      "epoch 100 \n",
      "Error rate: 0.122596153846\n",
      "Train acc: 0.877403846154\n",
      "Loss: 1.56797\n",
      "epoch 101 \n",
      "Error rate: 0.0169270833333\n",
      "Train acc: 0.983072916667\n",
      "Loss: 1.32663\n",
      "epoch 102 \n",
      "Error rate: 0.0630008012821\n",
      "Train acc: 0.936999198718\n",
      "Loss: 1.43302\n",
      "epoch 103 \n",
      "Error rate: 0.0300480769231\n",
      "Train acc: 0.969951923077\n",
      "Loss: 1.34798\n",
      "epoch 104 \n",
      "Error rate: 0.0871394230769\n",
      "Train acc: 0.912860576923\n",
      "Loss: 1.47507\n",
      "epoch 105 \n",
      "Error rate: 0.021734775641\n",
      "Train acc: 0.978265224359\n",
      "Loss: 1.3263\n",
      "epoch 106 \n",
      "Error rate: 0.0511818910256\n",
      "Train acc: 0.948818108974\n",
      "Loss: 1.39673\n",
      "epoch 107 \n",
      "Error rate: 0.0193309294872\n",
      "Train acc: 0.980669070513\n",
      "Loss: 1.31097\n",
      "epoch 108 \n",
      "Error rate: 0.056390224359\n",
      "Train acc: 0.943609775641\n",
      "Loss: 1.4042\n",
      "epoch 109 \n",
      "Error rate: 0.0150240384615\n",
      "Train acc: 0.984975961538\n",
      "Loss: 1.30155\n",
      "epoch 110 \n",
      "Error rate: 0.0313501602564\n",
      "Train acc: 0.968649839744\n",
      "Loss: 1.35023\n",
      "epoch 111 \n",
      "Error rate: 0.00901442307692\n",
      "Train acc: 0.990985576923\n",
      "Loss: 1.27625\n",
      "epoch 112 \n",
      "Error rate: 0.0864383012821\n",
      "Train acc: 0.913561698718\n",
      "Loss: 1.45944\n",
      "epoch 113 \n",
      "Error rate: 0.00971554487179\n",
      "Train acc: 0.990284455128\n",
      "Loss: 1.2838\n",
      "epoch 114 \n",
      "Error rate: 0.106670673077\n",
      "Train acc: 0.893329326923\n",
      "Loss: 1.50361\n",
      "epoch 115 \n",
      "Error rate: 0.017828525641\n",
      "Train acc: 0.982171474359\n",
      "Loss: 1.29818\n",
      "epoch 116 \n",
      "Error rate: 0.0627003205128\n",
      "Train acc: 0.937299679487\n",
      "Loss: 1.39812\n",
      "epoch 117 \n",
      "Error rate: 0.00771233974359\n",
      "Train acc: 0.992287660256\n",
      "Loss: 1.26725\n",
      "epoch 118 \n",
      "Error rate: 0.0809294871795\n",
      "Train acc: 0.919070512821\n",
      "Loss: 1.43844\n",
      "epoch 119 \n",
      "Error rate: 0.0167267628205\n",
      "Train acc: 0.983273237179\n",
      "Loss: 1.2859\n",
      "epoch 120 \n",
      "Error rate: 0.0439703525641\n",
      "Train acc: 0.956029647436\n",
      "Loss: 1.35502\n",
      "epoch 121 \n",
      "Error rate: 0.00641025641026\n",
      "Train acc: 0.99358974359\n",
      "Loss: 1.2533\n",
      "epoch 122 \n",
      "Error rate: 0.0546875\n",
      "Train acc: 0.9453125\n",
      "Loss: 1.37161\n",
      "epoch 123 \n",
      "Error rate: 0.00861378205128\n",
      "Train acc: 0.991386217949\n",
      "Loss: 1.25728\n",
      "epoch 124 \n",
      "Error rate: 0.0245392628205\n",
      "Train acc: 0.975460737179\n",
      "Loss: 1.30657\n",
      "epoch 125 \n",
      "Error rate: 0.00410657051282\n",
      "Train acc: 0.995893429487\n",
      "Loss: 1.23554\n",
      "epoch 126 \n",
      "Error rate: 0.0437700320513\n",
      "Train acc: 0.956229967949\n",
      "Loss: 1.3427\n",
      "epoch 127 \n",
      "Error rate: 0.00540865384615\n",
      "Train acc: 0.994591346154\n",
      "Loss: 1.24018\n",
      "epoch 128 \n",
      "Error rate: 0.0765224358974\n",
      "Train acc: 0.923477564103\n",
      "Loss: 1.40105\n",
      "epoch 129 \n",
      "Error rate: 0.0104166666667\n",
      "Train acc: 0.989583333333\n",
      "Loss: 1.25194\n",
      "epoch 130 \n",
      "Error rate: 0.0352564102564\n",
      "Train acc: 0.964743589744\n",
      "Loss: 1.31773\n",
      "epoch 131 \n",
      "Error rate: 0.0029046474359\n",
      "Train acc: 0.997095352564\n",
      "Loss: 1.22602\n",
      "epoch 132 \n",
      "Error rate: 0.0353565705128\n",
      "Train acc: 0.964643429487\n",
      "Loss: 1.31197\n",
      "epoch 133 \n",
      "Error rate: 0.00280448717949\n",
      "Train acc: 0.997195512821\n",
      "Loss: 1.21817\n",
      "epoch 134 \n",
      "Error rate: 0.0226362179487\n",
      "Train acc: 0.977363782051\n",
      "Loss: 1.27777\n",
      "epoch 135 \n",
      "Error rate: 0.00150240384615\n",
      "Train acc: 0.998497596154\n",
      "Loss: 1.20845\n",
      "epoch 136 \n",
      "Error rate: 0.0205328525641\n",
      "Train acc: 0.979467147436\n",
      "Loss: 1.27086\n",
      "epoch 137 \n",
      "Error rate: 0.021233974359\n",
      "Train acc: 0.978766025641\n",
      "Loss: 1.25893\n",
      "epoch 138 \n",
      "Error rate: 0.068609775641\n",
      "Train acc: 0.931390224359\n",
      "Loss: 1.37346\n",
      "epoch 139 \n",
      "Error rate: 0.0078125\n",
      "Train acc: 0.9921875\n",
      "Loss: 1.22919\n",
      "epoch 140 \n",
      "Error rate: 0.03125\n",
      "Train acc: 0.96875\n",
      "Loss: 1.29184\n",
      "epoch 141 \n",
      "Error rate: 0.00330528846154\n",
      "Train acc: 0.996694711538\n",
      "Loss: 1.20609\n",
      "epoch 142 \n",
      "Error rate: 0.025140224359\n",
      "Train acc: 0.974859775641\n",
      "Loss: 1.27155\n",
      "epoch 143 \n",
      "Error rate: 0.00240384615385\n",
      "Train acc: 0.997596153846\n",
      "Loss: 1.20212\n",
      "epoch 144 \n",
      "Error rate: 0.0229366987179\n",
      "Train acc: 0.977063301282\n",
      "Loss: 1.26018\n",
      "epoch 145 \n",
      "Error rate: 0.00180288461538\n",
      "Train acc: 0.998197115385\n",
      "Loss: 1.19067\n",
      "epoch 146 \n",
      "Error rate: 0.0162259615385\n",
      "Train acc: 0.983774038462\n",
      "Loss: 1.24657\n",
      "epoch 147 \n",
      "Error rate: 0.00200320512821\n",
      "Train acc: 0.997996794872\n",
      "Loss: 1.18839\n",
      "epoch 148 \n",
      "Error rate: 0.0410657051282\n",
      "Train acc: 0.958934294872\n",
      "Loss: 1.29107\n",
      "epoch 149 \n",
      "Error rate: 0.00250400641026\n",
      "Train acc: 0.99749599359\n",
      "Loss: 1.19029\n",
      "epoch 150 \n",
      "Error rate: 0.0116185897436\n",
      "Train acc: 0.988381410256\n",
      "Loss: 1.22593\n",
      "epoch 151 \n",
      "Error rate: 0.00180288461538\n",
      "Train acc: 0.998197115385\n",
      "Loss: 1.17975\n",
      "epoch 152 \n",
      "Error rate: 0.0302483974359\n",
      "Train acc: 0.969751602564\n",
      "Loss: 1.26304\n",
      "epoch 153 \n",
      "Error rate: 0.00460737179487\n",
      "Train acc: 0.995392628205\n",
      "Loss: 1.18639\n",
      "epoch 154 \n",
      "Error rate: 0.00841346153846\n",
      "Train acc: 0.991586538462\n",
      "Loss: 1.21088\n",
      "epoch 155 \n",
      "Error rate: 0.00120192307692\n",
      "Train acc: 0.998798076923\n",
      "Loss: 1.17146\n",
      "epoch 156 \n",
      "Error rate: 0.0116185897436\n",
      "Train acc: 0.988381410256\n",
      "Loss: 1.21271\n",
      "epoch 157 \n",
      "Error rate: 0.000500801282051\n",
      "Train acc: 0.999499198718\n",
      "Loss: 1.16334\n",
      "epoch 158 \n",
      "Error rate: 0.0572916666667\n",
      "Train acc: 0.942708333333\n",
      "Loss: 1.30849\n",
      "epoch 159 \n",
      "Error rate: 0.00801282051282\n",
      "Train acc: 0.991987179487\n",
      "Loss: 1.18435\n",
      "epoch 160 \n",
      "Error rate: 0.00841346153846\n",
      "Train acc: 0.991586538462\n",
      "Loss: 1.19814\n",
      "epoch 161 \n",
      "Error rate: 0.00620993589744\n",
      "Train acc: 0.993790064103\n",
      "Loss: 1.17707\n",
      "epoch 162 \n",
      "Error rate: 0.0215344551282\n",
      "Train acc: 0.978465544872\n",
      "Loss: 1.21884\n",
      "epoch 163 \n",
      "Error rate: 0.000901442307692\n",
      "Train acc: 0.999098557692\n",
      "Loss: 1.15085\n",
      "epoch 164 \n",
      "Error rate: 0.00410657051282\n",
      "Train acc: 0.995893429487\n",
      "Loss: 1.1771\n",
      "epoch 165 \n",
      "Error rate: 0.00300480769231\n",
      "Train acc: 0.996995192308\n",
      "Loss: 1.16205\n",
      "epoch 166 \n",
      "Error rate: 0.0122195512821\n",
      "Train acc: 0.987780448718\n",
      "Loss: 1.19818\n",
      "epoch 167 \n",
      "Error rate: 0.00250400641026\n",
      "Train acc: 0.99749599359\n",
      "Loss: 1.1535\n",
      "epoch 168 \n",
      "Error rate: 0.049078525641\n",
      "Train acc: 0.950921474359\n",
      "Loss: 1.27203\n",
      "epoch 169 \n",
      "Error rate: 0.0108173076923\n",
      "Train acc: 0.989182692308\n",
      "Loss: 1.17439\n",
      "epoch 170 \n",
      "Error rate: 0.00911458333333\n",
      "Train acc: 0.990885416667\n",
      "Loss: 1.18348\n",
      "epoch 171 \n",
      "Error rate: 0.000500801282051\n",
      "Train acc: 0.999499198718\n",
      "Loss: 1.13656\n",
      "epoch 172 \n",
      "Error rate: 0.00470753205128\n",
      "Train acc: 0.995292467949\n",
      "Loss: 1.16501\n",
      "epoch 173 \n",
      "Error rate: 0.000600961538462\n",
      "Train acc: 0.999399038462\n",
      "Loss: 1.13359\n",
      "epoch 174 \n",
      "Error rate: 0.0274439102564\n",
      "Train acc: 0.972556089744\n",
      "Loss: 1.21543\n",
      "epoch 175 \n",
      "Error rate: 0.00160256410256\n",
      "Train acc: 0.998397435897\n",
      "Loss: 1.13088\n",
      "epoch 176 \n",
      "Error rate: 0.00380608974359\n",
      "Train acc: 0.996193910256\n",
      "Loss: 1.1533\n",
      "epoch 177 \n",
      "Error rate: 0.000300480769231\n",
      "Train acc: 0.999699519231\n",
      "Loss: 1.11848\n",
      "epoch 178 \n",
      "Error rate: 0.0495793269231\n",
      "Train acc: 0.950420673077\n",
      "Loss: 1.25558\n",
      "epoch 179 \n",
      "Error rate: 0.00921474358974\n",
      "Train acc: 0.99078525641\n",
      "Loss: 1.1529\n",
      "epoch 180 \n",
      "Error rate: 0.00851362179487\n",
      "Train acc: 0.991486378205\n",
      "Loss: 1.15966\n",
      "epoch 181 \n",
      "Error rate: 0.000500801282051\n",
      "Train acc: 0.999499198718\n",
      "Loss: 1.12184\n",
      "epoch 182 \n",
      "Error rate: 0.00230368589744\n",
      "Train acc: 0.997696314103\n",
      "Loss: 1.13829\n",
      "epoch 183 \n",
      "Error rate: 0.000200320512821\n",
      "Train acc: 0.999799679487\n",
      "Loss: 1.11122\n",
      "epoch 184 \n",
      "Error rate: 0.0559895833333\n",
      "Train acc: 0.944010416667\n",
      "Loss: 1.25633\n",
      "epoch 185 \n",
      "Error rate: 0.00620993589744\n",
      "Train acc: 0.993790064103\n",
      "Loss: 1.13476\n",
      "epoch 186 \n",
      "Error rate: 0.0321514423077\n",
      "Train acc: 0.967848557692\n",
      "Loss: 1.20526\n",
      "epoch 187 \n",
      "Error rate: 0.00420673076923\n",
      "Train acc: 0.995793269231\n",
      "Loss: 1.12394\n",
      "epoch 188 \n",
      "Error rate: 0.0122195512821\n",
      "Train acc: 0.987780448718\n",
      "Loss: 1.15742\n",
      "epoch 189 \n",
      "Error rate: 0.000400641025641\n",
      "Train acc: 0.999599358974\n",
      "Loss: 1.10754\n",
      "epoch 190 \n",
      "Error rate: 0.0129206730769\n",
      "Train acc: 0.987079326923\n",
      "Loss: 1.15045\n",
      "epoch 191 \n",
      "Error rate: 0.000400641025641\n",
      "Train acc: 0.999599358974\n",
      "Loss: 1.09913\n",
      "epoch 192 \n",
      "Error rate: 0.00230368589744\n",
      "Train acc: 0.997696314103\n",
      "Loss: 1.12213\n",
      "epoch 193 \n",
      "Error rate: 0.000400641025641\n",
      "Train acc: 0.999599358974\n",
      "Loss: 1.09721\n",
      "epoch 194 \n",
      "Error rate: 0.00470753205128\n",
      "Train acc: 0.995292467949\n",
      "Loss: 1.12279\n",
      "epoch 195 \n",
      "Error rate: 0.00250400641026\n",
      "Train acc: 0.99749599359\n",
      "Loss: 1.10248\n",
      "epoch 196 \n",
      "Error rate: 0.0203325320513\n",
      "Train acc: 0.979667467949\n",
      "Loss: 1.15697\n",
      "epoch 197 \n",
      "Error rate: 0.0111177884615\n",
      "Train acc: 0.988882211538\n",
      "Loss: 1.11985\n",
      "epoch 198 \n",
      "Error rate: 0.00921474358974\n",
      "Train acc: 0.99078525641\n",
      "Loss: 1.13176\n",
      "epoch 199 \n",
      "Error rate: 0.00430689102564\n",
      "Train acc: 0.995693108974\n",
      "Loss: 1.1009\n",
      "epoch 200 \n",
      "Error rate: 0.0103165064103\n",
      "Train acc: 0.98968349359\n",
      "Loss: 1.12875\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "generic_3_spectral = CNN_Spectral_Param(num_output=10, kernel_size=3, architecture='generic', use_spectral_params=True)\n",
    "generic_3_spectral.train(xtrain, ytrain, batch_size=128, epochs=200)\n",
    "\n",
    "write_error_rate('generic_3_spectral', generic_3_spectral.error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches for training: 78\n",
      "epoch 1 \n",
      "Error rate: 0.714643429487\n",
      "Train acc: 0.285356570513\n",
      "Loss: 3.09257\n",
      "epoch 2 \n",
      "Error rate: 0.591045673077\n",
      "Train acc: 0.408954326923\n",
      "Loss: 2.64225\n",
      "epoch 3 \n",
      "Error rate: 0.554487179487\n",
      "Train acc: 0.445512820513\n",
      "Loss: 2.46102\n",
      "epoch 4 \n",
      "Error rate: 0.538361378205\n",
      "Train acc: 0.461638621795\n",
      "Loss: 2.40451\n",
      "epoch 5 \n",
      "Error rate: 0.4921875\n",
      "Train acc: 0.5078125\n",
      "Loss: 2.25062\n",
      "epoch 6 \n",
      "Error rate: 0.475060096154\n",
      "Train acc: 0.524939903846\n",
      "Loss: 2.19853\n",
      "epoch 7 \n",
      "Error rate: 0.448116987179\n",
      "Train acc: 0.551883012821\n",
      "Loss: 2.11179\n",
      "epoch 8 \n",
      "Error rate: 0.460436698718\n",
      "Train acc: 0.539563301282\n",
      "Loss: 2.11637\n",
      "epoch 9 \n",
      "Error rate: 0.418569711538\n",
      "Train acc: 0.581430288462\n",
      "Loss: 2.0149\n",
      "epoch 10 \n",
      "Error rate: 0.431290064103\n",
      "Train acc: 0.568709935897\n",
      "Loss: 2.02802\n",
      "epoch 11 \n",
      "Error rate: 0.39453125\n",
      "Train acc: 0.60546875\n",
      "Loss: 1.9269\n",
      "epoch 12 \n",
      "Error rate: 0.409354967949\n",
      "Train acc: 0.590645032051\n",
      "Loss: 1.96706\n",
      "epoch 13 \n",
      "Error rate: 0.369891826923\n",
      "Train acc: 0.630108173077\n",
      "Loss: 1.86481\n",
      "epoch 14 \n",
      "Error rate: 0.381109775641\n",
      "Train acc: 0.618890224359\n",
      "Loss: 1.88172\n",
      "epoch 15 \n",
      "Error rate: 0.341446314103\n",
      "Train acc: 0.658553685897\n",
      "Loss: 1.78707\n",
      "epoch 16 \n",
      "Error rate: 0.375500801282\n",
      "Train acc: 0.624499198718\n",
      "Loss: 1.85317\n",
      "epoch 17 \n",
      "Error rate: 0.355068108974\n",
      "Train acc: 0.644931891026\n",
      "Loss: 1.81492\n",
      "epoch 18 \n",
      "Error rate: 0.351862980769\n",
      "Train acc: 0.648137019231\n",
      "Loss: 1.81212\n",
      "epoch 19 \n",
      "Error rate: 0.324118589744\n",
      "Train acc: 0.675881410256\n",
      "Loss: 1.71467\n",
      "epoch 20 \n",
      "Error rate: 0.338842147436\n",
      "Train acc: 0.661157852564\n",
      "Loss: 1.76401\n",
      "epoch 21 \n",
      "Error rate: 0.337439903846\n",
      "Train acc: 0.662560096154\n",
      "Loss: 1.74349\n",
      "epoch 22 \n",
      "Error rate: 0.345052083333\n",
      "Train acc: 0.654947916667\n",
      "Loss: 1.77737\n",
      "epoch 23 \n",
      "Error rate: 0.308393429487\n",
      "Train acc: 0.691606570513\n",
      "Loss: 1.6697\n",
      "epoch 24 \n",
      "Error rate: 0.338942307692\n",
      "Train acc: 0.661057692308\n",
      "Loss: 1.74367\n",
      "epoch 25 \n",
      "Error rate: 0.297776442308\n",
      "Train acc: 0.702223557692\n",
      "Loss: 1.63998\n",
      "epoch 26 \n",
      "Error rate: 0.322415865385\n",
      "Train acc: 0.677584134615\n",
      "Loss: 1.70666\n",
      "epoch 27 \n",
      "Error rate: 0.280448717949\n",
      "Train acc: 0.719551282051\n",
      "Loss: 1.59842\n",
      "epoch 28 \n",
      "Error rate: 0.315304487179\n",
      "Train acc: 0.684695512821\n",
      "Loss: 1.68352\n",
      "epoch 29 \n",
      "Error rate: 0.271534455128\n",
      "Train acc: 0.728465544872\n",
      "Loss: 1.56599\n",
      "epoch 30 \n",
      "Error rate: 0.303385416667\n",
      "Train acc: 0.696614583333\n",
      "Loss: 1.64858\n",
      "epoch 31 \n",
      "Error rate: 0.259615384615\n",
      "Train acc: 0.740384615385\n",
      "Loss: 1.53228\n",
      "epoch 32 \n",
      "Error rate: 0.299979967949\n",
      "Train acc: 0.700020032051\n",
      "Loss: 1.63302\n",
      "epoch 33 \n",
      "Error rate: 0.247696314103\n",
      "Train acc: 0.752303685897\n",
      "Loss: 1.49791\n",
      "epoch 34 \n",
      "Error rate: 0.285657051282\n",
      "Train acc: 0.714342948718\n",
      "Loss: 1.59131\n",
      "epoch 35 \n",
      "Error rate: 0.253305288462\n",
      "Train acc: 0.746694711538\n",
      "Loss: 1.51242\n",
      "epoch 36 \n",
      "Error rate: 0.281450320513\n",
      "Train acc: 0.718549679487\n",
      "Loss: 1.57781\n",
      "epoch 37 \n",
      "Error rate: 0.234675480769\n",
      "Train acc: 0.765324519231\n",
      "Loss: 1.45777\n",
      "epoch 38 \n",
      "Error rate: 0.277243589744\n",
      "Train acc: 0.722756410256\n",
      "Loss: 1.56529\n",
      "epoch 39 \n",
      "Error rate: 0.231770833333\n",
      "Train acc: 0.768229166667\n",
      "Loss: 1.44565\n",
      "epoch 40 \n",
      "Error rate: 0.275741185897\n",
      "Train acc: 0.724258814103\n",
      "Loss: 1.5551\n",
      "epoch 41 \n",
      "Error rate: 0.231069711538\n",
      "Train acc: 0.768930288462\n",
      "Loss: 1.43074\n",
      "epoch 42 \n",
      "Error rate: 0.251602564103\n",
      "Train acc: 0.748397435897\n",
      "Loss: 1.48795\n",
      "epoch 43 \n",
      "Error rate: 0.230869391026\n",
      "Train acc: 0.769130608974\n",
      "Loss: 1.44055\n",
      "epoch 44 \n",
      "Error rate: 0.251903044872\n",
      "Train acc: 0.748096955128\n",
      "Loss: 1.49411\n",
      "epoch 45 \n",
      "Error rate: 0.197716346154\n",
      "Train acc: 0.802283653846\n",
      "Loss: 1.35928\n",
      "epoch 46 \n",
      "Error rate: 0.246895032051\n",
      "Train acc: 0.753104967949\n",
      "Loss: 1.48412\n",
      "epoch 47 \n",
      "Error rate: 0.19671474359\n",
      "Train acc: 0.80328525641\n",
      "Loss: 1.35082\n",
      "epoch 48 \n",
      "Error rate: 0.250100160256\n",
      "Train acc: 0.749899839744\n",
      "Loss: 1.47177\n",
      "epoch 49 \n",
      "Error rate: 0.183393429487\n",
      "Train acc: 0.816606570513\n",
      "Loss: 1.31914\n",
      "epoch 50 \n",
      "Error rate: 0.223657852564\n",
      "Train acc: 0.776342147436\n",
      "Loss: 1.41352\n",
      "epoch 51 \n",
      "Error rate: 0.160056089744\n",
      "Train acc: 0.839943910256\n",
      "Loss: 1.26198\n",
      "epoch 52 \n",
      "Error rate: 0.242688301282\n",
      "Train acc: 0.757311698718\n",
      "Loss: 1.45851\n",
      "epoch 53 \n",
      "Error rate: 0.193108974359\n",
      "Train acc: 0.806891025641\n",
      "Loss: 1.32863\n",
      "epoch 54 \n",
      "Error rate: 0.206029647436\n",
      "Train acc: 0.793970352564\n",
      "Loss: 1.36751\n",
      "epoch 55 \n",
      "Error rate: 0.178485576923\n",
      "Train acc: 0.821514423077\n",
      "Loss: 1.29269\n",
      "epoch 56 \n",
      "Error rate: 0.215845352564\n",
      "Train acc: 0.784154647436\n",
      "Loss: 1.38811\n",
      "epoch 57 \n",
      "Error rate: 0.169871794872\n",
      "Train acc: 0.830128205128\n",
      "Loss: 1.27295\n",
      "epoch 58 \n",
      "Error rate: 0.204627403846\n",
      "Train acc: 0.795372596154\n",
      "Loss: 1.35769\n",
      "epoch 59 \n",
      "Error rate: 0.153545673077\n",
      "Train acc: 0.846454326923\n",
      "Loss: 1.22754\n",
      "epoch 60 \n",
      "Error rate: 0.207632211538\n",
      "Train acc: 0.792367788462\n",
      "Loss: 1.35305\n",
      "epoch 61 \n",
      "Error rate: 0.152143429487\n",
      "Train acc: 0.847856570513\n",
      "Loss: 1.23134\n",
      "epoch 62 \n",
      "Error rate: 0.17718349359\n",
      "Train acc: 0.82281650641\n",
      "Loss: 1.28933\n",
      "epoch 63 \n",
      "Error rate: 0.154447115385\n",
      "Train acc: 0.845552884615\n",
      "Loss: 1.23026\n",
      "epoch 64 \n",
      "Error rate: 0.205028044872\n",
      "Train acc: 0.794971955128\n",
      "Loss: 1.34083\n",
      "epoch 65 \n",
      "Error rate: 0.122395833333\n",
      "Train acc: 0.877604166667\n",
      "Loss: 1.15283\n",
      "epoch 66 \n",
      "Error rate: 0.206730769231\n",
      "Train acc: 0.793269230769\n",
      "Loss: 1.35514\n",
      "epoch 67 \n",
      "Error rate: 0.118990384615\n",
      "Train acc: 0.881009615385\n",
      "Loss: 1.14389\n",
      "epoch 68 \n",
      "Error rate: 0.177884615385\n",
      "Train acc: 0.822115384615\n",
      "Loss: 1.28237\n",
      "epoch 69 \n",
      "Error rate: 0.108072916667\n",
      "Train acc: 0.891927083333\n",
      "Loss: 1.11762\n",
      "epoch 70 \n",
      "Error rate: 0.156350160256\n",
      "Train acc: 0.843649839744\n",
      "Loss: 1.22943\n",
      "epoch 71 \n",
      "Error rate: 0.148036858974\n",
      "Train acc: 0.851963141026\n",
      "Loss: 1.20444\n",
      "epoch 72 \n",
      "Error rate: 0.179286858974\n",
      "Train acc: 0.820713141026\n",
      "Loss: 1.27884\n",
      "epoch 73 \n",
      "Error rate: 0.121895032051\n",
      "Train acc: 0.878104967949\n",
      "Loss: 1.14069\n",
      "epoch 74 \n",
      "Error rate: 0.177083333333\n",
      "Train acc: 0.822916666667\n",
      "Loss: 1.27563\n",
      "epoch 75 \n",
      "Error rate: 0.106270032051\n",
      "Train acc: 0.893729967949\n",
      "Loss: 1.10438\n",
      "epoch 76 \n",
      "Error rate: 0.156951121795\n",
      "Train acc: 0.843048878205\n",
      "Loss: 1.2212\n",
      "epoch 77 \n",
      "Error rate: 0.112479967949\n",
      "Train acc: 0.887520032051\n",
      "Loss: 1.12186\n",
      "epoch 78 \n",
      "Error rate: 0.142728365385\n",
      "Train acc: 0.857271634615\n",
      "Loss: 1.18715\n",
      "epoch 79 \n",
      "Error rate: 0.0819310897436\n",
      "Train acc: 0.918068910256\n",
      "Loss: 1.04292\n",
      "epoch 80 \n",
      "Error rate: 0.1484375\n",
      "Train acc: 0.8515625\n",
      "Loss: 1.18661\n",
      "epoch 81 \n",
      "Error rate: 0.0641025641026\n",
      "Train acc: 0.935897435897\n",
      "Loss: 1.01266\n",
      "epoch 82 \n",
      "Error rate: 0.123497596154\n",
      "Train acc: 0.876502403846\n",
      "Loss: 1.13232\n",
      "epoch 83 \n",
      "Error rate: 0.111378205128\n",
      "Train acc: 0.888621794872\n",
      "Loss: 1.11714\n",
      "epoch 84 \n",
      "Error rate: 0.123697916667\n",
      "Train acc: 0.876302083333\n",
      "Loss: 1.14002\n",
      "epoch 85 \n",
      "Error rate: 0.0555889423077\n",
      "Train acc: 0.944411057692\n",
      "Loss: 0.990705\n",
      "epoch 86 \n",
      "Error rate: 0.104667467949\n",
      "Train acc: 0.895332532051\n",
      "Loss: 1.09182\n",
      "epoch 87 \n",
      "Error rate: 0.0442708333333\n",
      "Train acc: 0.955729166667\n",
      "Loss: 0.956653\n",
      "epoch 88 \n",
      "Error rate: 0.101262019231\n",
      "Train acc: 0.898737980769\n",
      "Loss: 1.07593\n",
      "epoch 89 \n",
      "Error rate: 0.114483173077\n",
      "Train acc: 0.885516826923\n",
      "Loss: 1.11664\n",
      "epoch 90 \n",
      "Error rate: 0.0912459935897\n",
      "Train acc: 0.90875400641\n",
      "Loss: 1.06577\n",
      "epoch 91 \n",
      "Error rate: 0.102063301282\n",
      "Train acc: 0.897936698718\n",
      "Loss: 1.07624\n",
      "epoch 92 \n",
      "Error rate: 0.101161858974\n",
      "Train acc: 0.898838141026\n",
      "Loss: 1.08105\n",
      "epoch 93 \n",
      "Error rate: 0.0862379807692\n",
      "Train acc: 0.913762019231\n",
      "Loss: 1.04351\n",
      "epoch 94 \n",
      "Error rate: 0.149138621795\n",
      "Train acc: 0.850861378205\n",
      "Loss: 1.19306\n",
      "epoch 95 \n",
      "Error rate: 0.0600961538462\n",
      "Train acc: 0.939903846154\n",
      "Loss: 0.992865\n",
      "epoch 96 \n",
      "Error rate: 0.0984575320513\n",
      "Train acc: 0.901542467949\n",
      "Loss: 1.06667\n",
      "epoch 97 \n",
      "Error rate: 0.0542868589744\n",
      "Train acc: 0.945713141026\n",
      "Loss: 0.976309\n",
      "epoch 98 \n",
      "Error rate: 0.095953525641\n",
      "Train acc: 0.904046474359\n",
      "Loss: 1.062\n",
      "epoch 99 \n",
      "Error rate: 0.0493790064103\n",
      "Train acc: 0.95062099359\n",
      "Loss: 0.963481\n",
      "epoch 100 \n",
      "Error rate: 0.0816306089744\n",
      "Train acc: 0.918369391026\n",
      "Loss: 1.03175\n",
      "epoch 101 \n",
      "Error rate: 0.0347556089744\n",
      "Train acc: 0.965244391026\n",
      "Loss: 0.918134\n",
      "epoch 102 \n",
      "Error rate: 0.124298878205\n",
      "Train acc: 0.875701121795\n",
      "Loss: 1.12449\n",
      "epoch 103 \n",
      "Error rate: 0.0437700320513\n",
      "Train acc: 0.956229967949\n",
      "Loss: 0.947128\n",
      "epoch 104 \n",
      "Error rate: 0.0721153846154\n",
      "Train acc: 0.927884615385\n",
      "Loss: 1.00833\n",
      "epoch 105 \n",
      "Error rate: 0.0366586538462\n",
      "Train acc: 0.963341346154\n",
      "Loss: 0.929413\n",
      "epoch 106 \n",
      "Error rate: 0.0828325320513\n",
      "Train acc: 0.917167467949\n",
      "Loss: 1.03006\n",
      "epoch 107 \n",
      "Error rate: 0.0275440705128\n",
      "Train acc: 0.972455929487\n",
      "Loss: 0.898357\n",
      "epoch 108 \n",
      "Error rate: 0.0614983974359\n",
      "Train acc: 0.938501602564\n",
      "Loss: 0.97737\n",
      "epoch 109 \n",
      "Error rate: 0.0182291666667\n",
      "Train acc: 0.981770833333\n",
      "Loss: 0.873304\n",
      "epoch 110 \n",
      "Error rate: 0.0564903846154\n",
      "Train acc: 0.943509615385\n",
      "Loss: 0.959759\n",
      "epoch 111 \n",
      "Error rate: 0.0513822115385\n",
      "Train acc: 0.948617788462\n",
      "Loss: 0.948805\n",
      "epoch 112 \n",
      "Error rate: 0.130809294872\n",
      "Train acc: 0.869190705128\n",
      "Loss: 1.12917\n",
      "epoch 113 \n",
      "Error rate: 0.0327524038462\n",
      "Train acc: 0.967247596154\n",
      "Loss: 0.911621\n",
      "epoch 114 \n",
      "Error rate: 0.0982572115385\n",
      "Train acc: 0.901742788462\n",
      "Loss: 1.05378\n",
      "epoch 115 \n",
      "Error rate: 0.0311498397436\n",
      "Train acc: 0.968850160256\n",
      "Loss: 0.90065\n",
      "epoch 116 \n",
      "Error rate: 0.100861378205\n",
      "Train acc: 0.899138621795\n",
      "Loss: 1.05218\n",
      "epoch 117 \n",
      "Error rate: 0.0189302884615\n",
      "Train acc: 0.981069711538\n",
      "Loss: 0.878513\n",
      "epoch 118 \n",
      "Error rate: 0.0851362179487\n",
      "Train acc: 0.914863782051\n",
      "Loss: 1.02062\n",
      "epoch 119 \n",
      "Error rate: 0.0128205128205\n",
      "Train acc: 0.987179487179\n",
      "Loss: 0.860741\n",
      "epoch 120 \n",
      "Error rate: 0.0936498397436\n",
      "Train acc: 0.906350160256\n",
      "Loss: 1.03496\n",
      "epoch 121 \n",
      "Error rate: 0.0198317307692\n",
      "Train acc: 0.980168269231\n",
      "Loss: 0.873152\n",
      "epoch 122 \n",
      "Error rate: 0.0632011217949\n",
      "Train acc: 0.936798878205\n",
      "Loss: 0.972691\n",
      "epoch 123 \n",
      "Error rate: 0.0155248397436\n",
      "Train acc: 0.984475160256\n",
      "Loss: 0.865574\n",
      "epoch 124 \n",
      "Error rate: 0.0574919871795\n",
      "Train acc: 0.942508012821\n",
      "Loss: 0.954472\n",
      "epoch 125 \n",
      "Error rate: 0.0123197115385\n",
      "Train acc: 0.987680288462\n",
      "Loss: 0.851123\n",
      "epoch 126 \n",
      "Error rate: 0.0658052884615\n",
      "Train acc: 0.934194711538\n",
      "Loss: 0.966908\n",
      "epoch 127 \n",
      "Error rate: 0.00871394230769\n",
      "Train acc: 0.991286057692\n",
      "Loss: 0.835407\n",
      "epoch 128 \n",
      "Error rate: 0.0755208333333\n",
      "Train acc: 0.924479166667\n",
      "Loss: 0.992865\n",
      "epoch 129 \n",
      "Error rate: 0.00981570512821\n",
      "Train acc: 0.990184294872\n",
      "Loss: 0.840528\n",
      "epoch 130 \n",
      "Error rate: 0.0511818910256\n",
      "Train acc: 0.948818108974\n",
      "Loss: 0.942386\n",
      "epoch 131 \n",
      "Error rate: 0.00841346153846\n",
      "Train acc: 0.991586538462\n",
      "Loss: 0.828737\n",
      "epoch 132 \n",
      "Error rate: 0.0426682692308\n",
      "Train acc: 0.957331730769\n",
      "Loss: 0.916118\n",
      "epoch 133 \n",
      "Error rate: 0.00480769230769\n",
      "Train acc: 0.995192307692\n",
      "Loss: 0.818146\n",
      "epoch 134 \n",
      "Error rate: 0.0637019230769\n",
      "Train acc: 0.936298076923\n",
      "Loss: 0.959287\n",
      "epoch 135 \n",
      "Error rate: 0.00721153846154\n",
      "Train acc: 0.992788461538\n",
      "Loss: 0.82378\n",
      "epoch 136 \n",
      "Error rate: 0.0343549679487\n",
      "Train acc: 0.965645032051\n",
      "Loss: 0.895189\n",
      "epoch 137 \n",
      "Error rate: 0.00280448717949\n",
      "Train acc: 0.997195512821\n",
      "Loss: 0.803563\n",
      "epoch 138 \n",
      "Error rate: 0.0487780448718\n",
      "Train acc: 0.951221955128\n",
      "Loss: 0.920994\n",
      "epoch 139 \n",
      "Error rate: 0.0116185897436\n",
      "Train acc: 0.988381410256\n",
      "Loss: 0.831059\n",
      "epoch 140 \n",
      "Error rate: 0.0332532051282\n",
      "Train acc: 0.966746794872\n",
      "Loss: 0.889921\n",
      "epoch 141 \n",
      "Error rate: 0.00540865384615\n",
      "Train acc: 0.994591346154\n",
      "Loss: 0.806499\n",
      "epoch 142 \n",
      "Error rate: 0.0374599358974\n",
      "Train acc: 0.962540064103\n",
      "Loss: 0.894886\n",
      "epoch 143 \n",
      "Error rate: 0.00771233974359\n",
      "Train acc: 0.992287660256\n",
      "Loss: 0.813505\n",
      "epoch 144 \n",
      "Error rate: 0.0634014423077\n",
      "Train acc: 0.936598557692\n",
      "Loss: 0.943811\n",
      "epoch 145 \n",
      "Error rate: 0.00971554487179\n",
      "Train acc: 0.990284455128\n",
      "Loss: 0.819289\n",
      "epoch 146 \n",
      "Error rate: 0.0257411858974\n",
      "Train acc: 0.974258814103\n",
      "Loss: 0.86097\n",
      "epoch 147 \n",
      "Error rate: 0.0078125\n",
      "Train acc: 0.9921875\n",
      "Loss: 0.813618\n",
      "epoch 148 \n",
      "Error rate: 0.0335536858974\n",
      "Train acc: 0.966446314103\n",
      "Loss: 0.881996\n",
      "epoch 149 \n",
      "Error rate: 0.00450721153846\n",
      "Train acc: 0.995492788462\n",
      "Loss: 0.801241\n",
      "epoch 150 \n",
      "Error rate: 0.0221354166667\n",
      "Train acc: 0.977864583333\n",
      "Loss: 0.850441\n",
      "epoch 151 \n",
      "Error rate: 0.00380608974359\n",
      "Train acc: 0.996193910256\n",
      "Loss: 0.789238\n",
      "epoch 152 \n",
      "Error rate: 0.0330528846154\n",
      "Train acc: 0.966947115385\n",
      "Loss: 0.86996\n",
      "epoch 153 \n",
      "Error rate: 0.00240384615385\n",
      "Train acc: 0.997596153846\n",
      "Loss: 0.784122\n",
      "epoch 154 \n",
      "Error rate: 0.0114182692308\n",
      "Train acc: 0.988581730769\n",
      "Loss: 0.820404\n",
      "epoch 155 \n",
      "Error rate: 0.000801282051282\n",
      "Train acc: 0.999198717949\n",
      "Loss: 0.770198\n",
      "epoch 156 \n",
      "Error rate: 0.0497796474359\n",
      "Train acc: 0.950220352564\n",
      "Loss: 0.899823\n",
      "epoch 157 \n",
      "Error rate: 0.00480769230769\n",
      "Train acc: 0.995192307692\n",
      "Loss: 0.789762\n",
      "epoch 158 \n",
      "Error rate: 0.00991586538462\n",
      "Train acc: 0.990084134615\n",
      "Loss: 0.810927\n",
      "epoch 159 \n",
      "Error rate: 0.0105168269231\n",
      "Train acc: 0.989483173077\n",
      "Loss: 0.807447\n",
      "epoch 160 \n",
      "Error rate: 0.0331530448718\n",
      "Train acc: 0.966846955128\n",
      "Loss: 0.861348\n",
      "epoch 161 \n",
      "Error rate: 0.00500801282051\n",
      "Train acc: 0.994991987179\n",
      "Loss: 0.780829\n",
      "epoch 162 \n",
      "Error rate: 0.00891426282051\n",
      "Train acc: 0.991085737179\n",
      "Loss: 0.804406\n",
      "epoch 163 \n",
      "Error rate: 0.00140224358974\n",
      "Train acc: 0.99859775641\n",
      "Loss: 0.76124\n",
      "epoch 164 \n",
      "Error rate: 0.0193309294872\n",
      "Train acc: 0.980669070513\n",
      "Loss: 0.82451\n",
      "epoch 165 \n",
      "Error rate: 0.0172275641026\n",
      "Train acc: 0.982772435897\n",
      "Loss: 0.816874\n",
      "epoch 166 \n",
      "Error rate: 0.0109174679487\n",
      "Train acc: 0.989082532051\n",
      "Loss: 0.806239\n",
      "epoch 167 \n",
      "Error rate: 0.00410657051282\n",
      "Train acc: 0.995893429487\n",
      "Loss: 0.778312\n",
      "epoch 168 \n",
      "Error rate: 0.0183293269231\n",
      "Train acc: 0.981670673077\n",
      "Loss: 0.821213\n",
      "epoch 169 \n",
      "Error rate: 0.0160256410256\n",
      "Train acc: 0.983974358974\n",
      "Loss: 0.807279\n",
      "epoch 170 \n",
      "Error rate: 0.0164262820513\n",
      "Train acc: 0.983573717949\n",
      "Loss: 0.811267\n",
      "epoch 171 \n",
      "Error rate: 0.00110176282051\n",
      "Train acc: 0.998898237179\n",
      "Loss: 0.752186\n",
      "epoch 172 \n",
      "Error rate: 0.0203325320513\n",
      "Train acc: 0.979667467949\n",
      "Loss: 0.815782\n",
      "epoch 173 \n",
      "Error rate: 0.0161258012821\n",
      "Train acc: 0.983874198718\n",
      "Loss: 0.808079\n",
      "epoch 174 \n",
      "Error rate: 0.0853365384615\n",
      "Train acc: 0.914663461538\n",
      "Loss: 0.969934\n",
      "epoch 175 \n",
      "Error rate: 0.0106169871795\n",
      "Train acc: 0.989383012821\n",
      "Loss: 0.791673\n",
      "epoch 176 \n",
      "Error rate: 0.0400641025641\n",
      "Train acc: 0.959935897436\n",
      "Loss: 0.864238\n",
      "epoch 177 \n",
      "Error rate: 0.00250400641026\n",
      "Train acc: 0.99749599359\n",
      "Loss: 0.758396\n",
      "epoch 178 \n",
      "Error rate: 0.0126201923077\n",
      "Train acc: 0.987379807692\n",
      "Loss: 0.798046\n",
      "epoch 179 \n",
      "Error rate: 0.0010016025641\n",
      "Train acc: 0.998998397436\n",
      "Loss: 0.74705\n",
      "epoch 180 \n",
      "Error rate: 0.0166266025641\n",
      "Train acc: 0.983373397436\n",
      "Loss: 0.800449\n",
      "epoch 181 \n",
      "Error rate: 0.00120192307692\n",
      "Train acc: 0.998798076923\n",
      "Loss: 0.746093\n",
      "epoch 182 \n",
      "Error rate: 0.0561899038462\n",
      "Train acc: 0.943810096154\n",
      "Loss: 0.891946\n",
      "epoch 183 \n",
      "Error rate: 0.00981570512821\n",
      "Train acc: 0.990184294872\n",
      "Loss: 0.776904\n",
      "epoch 184 \n",
      "Error rate: 0.00821314102564\n",
      "Train acc: 0.991786858974\n",
      "Loss: 0.782682\n",
      "epoch 185 \n",
      "Error rate: 0.000200320512821\n",
      "Train acc: 0.999799679487\n",
      "Loss: 0.733327\n",
      "epoch 186 \n",
      "Error rate: 0.0049078525641\n",
      "Train acc: 0.995092147436\n",
      "Loss: 0.76253\n",
      "epoch 187 \n",
      "Error rate: 0.00470753205128\n",
      "Train acc: 0.995292467949\n",
      "Loss: 0.756124\n",
      "epoch 188 \n",
      "Error rate: 0.010016025641\n",
      "Train acc: 0.989983974359\n",
      "Loss: 0.781957\n",
      "epoch 189 \n",
      "Error rate: 0.00300480769231\n",
      "Train acc: 0.996995192308\n",
      "Loss: 0.737673\n",
      "epoch 190 \n",
      "Error rate: 0.00270432692308\n",
      "Train acc: 0.997295673077\n",
      "Loss: 0.752281\n",
      "epoch 191 \n",
      "Error rate: 0.00310496794872\n",
      "Train acc: 0.996895032051\n",
      "Loss: 0.745842\n",
      "epoch 192 \n",
      "Error rate: 0.0625\n",
      "Train acc: 0.9375\n",
      "Loss: 0.888075\n",
      "epoch 193 \n",
      "Error rate: 0.00430689102564\n",
      "Train acc: 0.995693108974\n",
      "Loss: 0.755796\n",
      "epoch 194 \n",
      "Error rate: 0.0475761217949\n",
      "Train acc: 0.952423878205\n",
      "Loss: 0.865428\n",
      "epoch 195 \n",
      "Error rate: 0.00440705128205\n",
      "Train acc: 0.995592948718\n",
      "Loss: 0.744484\n",
      "epoch 196 \n",
      "Error rate: 0.0230368589744\n",
      "Train acc: 0.976963141026\n",
      "Loss: 0.806242\n",
      "epoch 197 \n",
      "Error rate: 0.00170272435897\n",
      "Train acc: 0.998297275641\n",
      "Loss: 0.735541\n",
      "epoch 198 \n",
      "Error rate: 0.00360576923077\n",
      "Train acc: 0.996394230769\n",
      "Loss: 0.751745\n",
      "epoch 199 \n",
      "Error rate: 0.00150240384615\n",
      "Train acc: 0.998497596154\n",
      "Loss: 0.728173\n",
      "epoch 200 \n",
      "Error rate: 0.00661057692308\n",
      "Train acc: 0.993389423077\n",
      "Loss: 0.755938\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "generic_3_spatial = CNN_Spectral_Param(num_output=10, kernel_size=3, architecture='generic', use_spectral_params=False)\n",
    "generic_3_spatial.train(xtrain, ytrain, batch_size=128, epochs=200)\n",
    "\n",
    "write_error_rate('generic_3_spatial', generic_3_spatial.error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches for training: 78\n",
      "epoch 1 \n",
      "Error rate: 0.736378205128\n",
      "Train acc: 0.263621794872\n",
      "Loss: 6.54876\n",
      "epoch 2 \n",
      "Error rate: 0.616987179487\n",
      "Train acc: 0.383012820513\n",
      "Loss: 5.77415\n",
      "epoch 3 \n",
      "Error rate: 0.560396634615\n",
      "Train acc: 0.439603365385\n",
      "Loss: 5.57228\n",
      "epoch 4 \n",
      "Error rate: 0.541666666667\n",
      "Train acc: 0.458333333333\n",
      "Loss: 5.49118\n",
      "epoch 5 \n",
      "Error rate: 0.485677083333\n",
      "Train acc: 0.514322916667\n",
      "Loss: 5.29639\n",
      "epoch 6 \n",
      "Error rate: 0.487580128205\n",
      "Train acc: 0.512419871795\n",
      "Loss: 5.25989\n",
      "epoch 7 \n",
      "Error rate: 0.444210737179\n",
      "Train acc: 0.555789262821\n",
      "Loss: 5.10911\n",
      "epoch 8 \n",
      "Error rate: 0.461338141026\n",
      "Train acc: 0.538661858974\n",
      "Loss: 5.13288\n",
      "epoch 9 \n",
      "Error rate: 0.439302884615\n",
      "Train acc: 0.560697115385\n",
      "Loss: 5.02905\n",
      "epoch 10 \n",
      "Error rate: 0.437199519231\n",
      "Train acc: 0.562800480769\n",
      "Loss: 4.99672\n",
      "epoch 11 \n",
      "Error rate: 0.397335737179\n",
      "Train acc: 0.602664262821\n",
      "Loss: 4.87685\n",
      "epoch 12 \n",
      "Error rate: 0.422676282051\n",
      "Train acc: 0.577323717949\n",
      "Loss: 4.93659\n",
      "epoch 13 \n",
      "Error rate: 0.376302083333\n",
      "Train acc: 0.623697916667\n",
      "Loss: 4.77182\n",
      "epoch 14 \n",
      "Error rate: 0.401241987179\n",
      "Train acc: 0.598758012821\n",
      "Loss: 4.81455\n",
      "epoch 15 \n",
      "Error rate: 0.375801282051\n",
      "Train acc: 0.624198717949\n",
      "Loss: 4.7303\n",
      "epoch 16 \n",
      "Error rate: 0.380208333333\n",
      "Train acc: 0.619791666667\n",
      "Loss: 4.72157\n",
      "epoch 17 \n",
      "Error rate: 0.352864583333\n",
      "Train acc: 0.647135416667\n",
      "Loss: 4.62796\n",
      "epoch 18 \n",
      "Error rate: 0.371193910256\n",
      "Train acc: 0.628806089744\n",
      "Loss: 4.6514\n",
      "epoch 19 \n",
      "Error rate: 0.320512820513\n",
      "Train acc: 0.679487179487\n",
      "Loss: 4.51072\n",
      "epoch 20 \n",
      "Error rate: 0.373898237179\n",
      "Train acc: 0.626101762821\n",
      "Loss: 4.62311\n",
      "epoch 21 \n",
      "Error rate: 0.309294871795\n",
      "Train acc: 0.690705128205\n",
      "Loss: 4.43532\n",
      "epoch 22 \n",
      "Error rate: 0.353265224359\n",
      "Train acc: 0.646734775641\n",
      "Loss: 4.53014\n",
      "epoch 23 \n",
      "Error rate: 0.285757211538\n",
      "Train acc: 0.714242788462\n",
      "Loss: 4.34085\n",
      "epoch 24 \n",
      "Error rate: 0.346153846154\n",
      "Train acc: 0.653846153846\n",
      "Loss: 4.47467\n",
      "epoch 25 \n",
      "Error rate: 0.311899038462\n",
      "Train acc: 0.688100961538\n",
      "Loss: 4.34912\n",
      "epoch 26 \n",
      "Error rate: 0.320112179487\n",
      "Train acc: 0.679887820513\n",
      "Loss: 4.37114\n",
      "epoch 27 \n",
      "Error rate: 0.274038461538\n",
      "Train acc: 0.725961538462\n",
      "Loss: 4.23997\n",
      "epoch 28 \n",
      "Error rate: 0.31891025641\n",
      "Train acc: 0.68108974359\n",
      "Loss: 4.32929\n",
      "epoch 29 \n",
      "Error rate: 0.270733173077\n",
      "Train acc: 0.729266826923\n",
      "Loss: 4.18113\n",
      "epoch 30 \n",
      "Error rate: 0.307091346154\n",
      "Train acc: 0.692908653846\n",
      "Loss: 4.26869\n",
      "epoch 31 \n",
      "Error rate: 0.247796474359\n",
      "Train acc: 0.752203525641\n",
      "Loss: 4.09972\n",
      "epoch 32 \n",
      "Error rate: 0.302584134615\n",
      "Train acc: 0.697415865385\n",
      "Loss: 4.20483\n",
      "epoch 33 \n",
      "Error rate: 0.280048076923\n",
      "Train acc: 0.719951923077\n",
      "Loss: 4.13823\n",
      "epoch 34 \n",
      "Error rate: 0.301983173077\n",
      "Train acc: 0.698016826923\n",
      "Loss: 4.18461\n",
      "epoch 35 \n",
      "Error rate: 0.22906650641\n",
      "Train acc: 0.77093349359\n",
      "Loss: 3.98893\n",
      "epoch 36 \n",
      "Error rate: 0.276842948718\n",
      "Train acc: 0.723157051282\n",
      "Loss: 4.08767\n",
      "epoch 37 \n",
      "Error rate: 0.253305288462\n",
      "Train acc: 0.746694711538\n",
      "Loss: 4.02142\n",
      "epoch 38 \n",
      "Error rate: 0.273838141026\n",
      "Train acc: 0.726161858974\n",
      "Loss: 4.05847\n",
      "epoch 39 \n",
      "Error rate: 0.23828125\n",
      "Train acc: 0.76171875\n",
      "Loss: 3.95973\n",
      "epoch 40 \n",
      "Error rate: 0.275040064103\n",
      "Train acc: 0.724959935897\n",
      "Loss: 4.03725\n",
      "epoch 41 \n",
      "Error rate: 0.195913461538\n",
      "Train acc: 0.804086538462\n",
      "Loss: 3.82868\n",
      "epoch 42 \n",
      "Error rate: 0.260516826923\n",
      "Train acc: 0.739483173077\n",
      "Loss: 3.96844\n",
      "epoch 43 \n",
      "Error rate: 0.188802083333\n",
      "Train acc: 0.811197916667\n",
      "Loss: 3.78017\n",
      "epoch 44 \n",
      "Error rate: 0.242387820513\n",
      "Train acc: 0.757612179487\n",
      "Loss: 3.90034\n",
      "epoch 45 \n",
      "Error rate: 0.216045673077\n",
      "Train acc: 0.783954326923\n",
      "Loss: 3.81805\n",
      "epoch 46 \n",
      "Error rate: 0.246694711538\n",
      "Train acc: 0.753305288462\n",
      "Loss: 3.88132\n",
      "epoch 47 \n",
      "Error rate: 0.174278846154\n",
      "Train acc: 0.825721153846\n",
      "Loss: 3.6944\n",
      "epoch 48 \n",
      "Error rate: 0.223157051282\n",
      "Train acc: 0.776842948718\n",
      "Loss: 3.79294\n",
      "epoch 49 \n",
      "Error rate: 0.149238782051\n",
      "Train acc: 0.850761217949\n",
      "Loss: 3.61095\n",
      "epoch 50 \n",
      "Error rate: 0.222856570513\n",
      "Train acc: 0.777143429487\n",
      "Loss: 3.77498\n",
      "epoch 51 \n",
      "Error rate: 0.133313301282\n",
      "Train acc: 0.866686698718\n",
      "Loss: 3.54327\n",
      "epoch 52 \n",
      "Error rate: 0.203325320513\n",
      "Train acc: 0.796674679487\n",
      "Loss: 3.6872\n",
      "epoch 53 \n",
      "Error rate: 0.199919871795\n",
      "Train acc: 0.800080128205\n",
      "Loss: 3.68755\n",
      "epoch 54 \n",
      "Error rate: 0.241586538462\n",
      "Train acc: 0.758413461538\n",
      "Loss: 3.76904\n",
      "epoch 55 \n",
      "Error rate: 0.169771634615\n",
      "Train acc: 0.830228365385\n",
      "Loss: 3.58927\n",
      "epoch 56 \n",
      "Error rate: 0.186899038462\n",
      "Train acc: 0.813100961538\n",
      "Loss: 3.61113\n",
      "epoch 57 \n",
      "Error rate: 0.118890224359\n",
      "Train acc: 0.881109775641\n",
      "Loss: 3.449\n",
      "epoch 58 \n",
      "Error rate: 0.193309294872\n",
      "Train acc: 0.806690705128\n",
      "Loss: 3.60676\n",
      "epoch 59 \n",
      "Error rate: 0.17828525641\n",
      "Train acc: 0.82171474359\n",
      "Loss: 3.55685\n",
      "epoch 60 \n",
      "Error rate: 0.166165865385\n",
      "Train acc: 0.833834134615\n",
      "Loss: 3.52639\n",
      "epoch 61 \n",
      "Error rate: 0.152043269231\n",
      "Train acc: 0.847956730769\n",
      "Loss: 3.47843\n",
      "epoch 62 \n",
      "Error rate: 0.180989583333\n",
      "Train acc: 0.819010416667\n",
      "Loss: 3.53608\n",
      "epoch 63 \n",
      "Error rate: 0.140725160256\n",
      "Train acc: 0.859274839744\n",
      "Loss: 3.42344\n",
      "epoch 64 \n",
      "Error rate: 0.214443108974\n",
      "Train acc: 0.785556891026\n",
      "Loss: 3.58949\n",
      "epoch 65 \n",
      "Error rate: 0.112279647436\n",
      "Train acc: 0.887720352564\n",
      "Loss: 3.33852\n",
      "epoch 66 \n",
      "Error rate: 0.165364583333\n",
      "Train acc: 0.834635416667\n",
      "Loss: 3.45835\n",
      "epoch 67 \n",
      "Error rate: 0.126502403846\n",
      "Train acc: 0.873497596154\n",
      "Loss: 3.35934\n",
      "epoch 68 \n",
      "Error rate: 0.153044871795\n",
      "Train acc: 0.846955128205\n",
      "Loss: 3.41089\n",
      "epoch 69 \n",
      "Error rate: 0.0809294871795\n",
      "Train acc: 0.919070512821\n",
      "Loss: 3.23104\n",
      "epoch 70 \n",
      "Error rate: 0.150240384615\n",
      "Train acc: 0.849759615385\n",
      "Loss: 3.37481\n",
      "epoch 71 \n",
      "Error rate: 0.0845352564103\n",
      "Train acc: 0.91546474359\n",
      "Loss: 3.20938\n",
      "epoch 72 \n",
      "Error rate: 0.127604166667\n",
      "Train acc: 0.872395833333\n",
      "Loss: 3.29923\n",
      "epoch 73 \n",
      "Error rate: 0.128806089744\n",
      "Train acc: 0.871193910256\n",
      "Loss: 3.29884\n",
      "epoch 74 \n",
      "Error rate: 0.126802884615\n",
      "Train acc: 0.873197115385\n",
      "Loss: 3.29117\n",
      "epoch 75 \n",
      "Error rate: 0.107672275641\n",
      "Train acc: 0.892327724359\n",
      "Loss: 3.23275\n",
      "epoch 76 \n",
      "Error rate: 0.122796474359\n",
      "Train acc: 0.877203525641\n",
      "Loss: 3.26115\n",
      "epoch 77 \n",
      "Error rate: 0.0572916666667\n",
      "Train acc: 0.942708333333\n",
      "Loss: 3.10044\n",
      "epoch 78 \n",
      "Error rate: 0.107572115385\n",
      "Train acc: 0.892427884615\n",
      "Loss: 3.21109\n",
      "epoch 79 \n",
      "Error rate: 0.0492788461538\n",
      "Train acc: 0.950721153846\n",
      "Loss: 3.06086\n",
      "epoch 80 \n",
      "Error rate: 0.205428685897\n",
      "Train acc: 0.794571314103\n",
      "Loss: 3.42265\n",
      "epoch 81 \n",
      "Error rate: 0.103265224359\n",
      "Train acc: 0.896734775641\n",
      "Loss: 3.16867\n",
      "epoch 82 \n",
      "Error rate: 0.0973557692308\n",
      "Train acc: 0.902644230769\n",
      "Loss: 3.15926\n",
      "epoch 83 \n",
      "Error rate: 0.0822315705128\n",
      "Train acc: 0.917768429487\n",
      "Loss: 3.10838\n",
      "epoch 84 \n",
      "Error rate: 0.112580128205\n",
      "Train acc: 0.887419871795\n",
      "Loss: 3.1712\n",
      "epoch 85 \n",
      "Error rate: 0.0455729166667\n",
      "Train acc: 0.954427083333\n",
      "Loss: 3.00461\n",
      "epoch 86 \n",
      "Error rate: 0.0890424679487\n",
      "Train acc: 0.910957532051\n",
      "Loss: 3.09734\n",
      "epoch 87 \n",
      "Error rate: 0.0795272435897\n",
      "Train acc: 0.92047275641\n",
      "Loss: 3.07579\n",
      "epoch 88 \n",
      "Error rate: 0.152844551282\n",
      "Train acc: 0.847155448718\n",
      "Loss: 3.23733\n",
      "epoch 89 \n",
      "Error rate: 0.0536858974359\n",
      "Train acc: 0.946314102564\n",
      "Loss: 2.99178\n",
      "epoch 90 \n",
      "Error rate: 0.0755208333333\n",
      "Train acc: 0.924479166667\n",
      "Loss: 3.03943\n",
      "epoch 91 \n",
      "Error rate: 0.0323517628205\n",
      "Train acc: 0.967648237179\n",
      "Loss: 2.9246\n",
      "epoch 92 \n",
      "Error rate: 0.0890424679487\n",
      "Train acc: 0.910957532051\n",
      "Loss: 3.05174\n",
      "epoch 93 \n",
      "Error rate: 0.0718149038462\n",
      "Train acc: 0.928185096154\n",
      "Loss: 3.00866\n",
      "epoch 94 \n",
      "Error rate: 0.166466346154\n",
      "Train acc: 0.833533653846\n",
      "Loss: 3.22522\n",
      "epoch 95 \n",
      "Error rate: 0.0338541666667\n",
      "Train acc: 0.966145833333\n",
      "Loss: 2.9038\n",
      "epoch 96 \n",
      "Error rate: 0.133814102564\n",
      "Train acc: 0.866185897436\n",
      "Loss: 3.14096\n",
      "epoch 97 \n",
      "Error rate: 0.0268429487179\n",
      "Train acc: 0.973157051282\n",
      "Loss: 2.87974\n",
      "epoch 98 \n",
      "Error rate: 0.147836538462\n",
      "Train acc: 0.852163461538\n",
      "Loss: 3.15732\n",
      "epoch 99 \n",
      "Error rate: 0.0469751602564\n",
      "Train acc: 0.953024839744\n",
      "Loss: 2.91358\n",
      "epoch 100 \n",
      "Error rate: 0.113982371795\n",
      "Train acc: 0.886017628205\n",
      "Loss: 3.06253\n",
      "epoch 101 \n",
      "Error rate: 0.0313501602564\n",
      "Train acc: 0.968649839744\n",
      "Loss: 2.86411\n",
      "epoch 102 \n",
      "Error rate: 0.0789262820513\n",
      "Train acc: 0.921073717949\n",
      "Loss: 2.96583\n",
      "epoch 103 \n",
      "Error rate: 0.0272435897436\n",
      "Train acc: 0.972756410256\n",
      "Loss: 2.84288\n",
      "epoch 104 \n",
      "Error rate: 0.0845352564103\n",
      "Train acc: 0.91546474359\n",
      "Loss: 2.95857\n",
      "epoch 105 \n",
      "Error rate: 0.0224358974359\n",
      "Train acc: 0.977564102564\n",
      "Loss: 2.81013\n",
      "epoch 106 \n",
      "Error rate: 0.111778846154\n",
      "Train acc: 0.888221153846\n",
      "Loss: 3.02145\n",
      "epoch 107 \n",
      "Error rate: 0.0247395833333\n",
      "Train acc: 0.975260416667\n",
      "Loss: 2.80816\n",
      "epoch 108 \n",
      "Error rate: 0.0905448717949\n",
      "Train acc: 0.909455128205\n",
      "Loss: 2.95389\n",
      "epoch 109 \n",
      "Error rate: 0.0269431089744\n",
      "Train acc: 0.973056891026\n",
      "Loss: 2.79783\n",
      "epoch 110 \n",
      "Error rate: 0.0912459935897\n",
      "Train acc: 0.90875400641\n",
      "Loss: 2.94421\n",
      "epoch 111 \n",
      "Error rate: 0.0216346153846\n",
      "Train acc: 0.978365384615\n",
      "Loss: 2.77458\n",
      "epoch 112 \n",
      "Error rate: 0.0705128205128\n",
      "Train acc: 0.929487179487\n",
      "Loss: 2.89064\n",
      "epoch 113 \n",
      "Error rate: 0.0182291666667\n",
      "Train acc: 0.981770833333\n",
      "Loss: 2.75316\n",
      "epoch 114 \n",
      "Error rate: 0.0784254807692\n",
      "Train acc: 0.921574519231\n",
      "Loss: 2.88236\n",
      "epoch 115 \n",
      "Error rate: 0.0129206730769\n",
      "Train acc: 0.987079326923\n",
      "Loss: 2.73187\n",
      "epoch 116 \n",
      "Error rate: 0.0815304487179\n",
      "Train acc: 0.918469551282\n",
      "Loss: 2.88143\n",
      "epoch 117 \n",
      "Error rate: 0.0127203525641\n",
      "Train acc: 0.987279647436\n",
      "Loss: 2.72424\n",
      "epoch 118 \n",
      "Error rate: 0.0469751602564\n",
      "Train acc: 0.953024839744\n",
      "Loss: 2.79952\n",
      "epoch 119 \n",
      "Error rate: 0.0153245192308\n",
      "Train acc: 0.984675480769\n",
      "Loss: 2.71605\n",
      "epoch 120 \n",
      "Error rate: 0.0768229166667\n",
      "Train acc: 0.923177083333\n",
      "Loss: 2.84777\n",
      "epoch 121 \n",
      "Error rate: 0.0149238782051\n",
      "Train acc: 0.985076121795\n",
      "Loss: 2.70389\n",
      "epoch 122 \n",
      "Error rate: 0.0350560897436\n",
      "Train acc: 0.964943910256\n",
      "Loss: 2.74949\n",
      "epoch 123 \n",
      "Error rate: 0.00971554487179\n",
      "Train acc: 0.990284455128\n",
      "Loss: 2.67463\n",
      "epoch 124 \n",
      "Error rate: 0.0683092948718\n",
      "Train acc: 0.931690705128\n",
      "Loss: 2.8057\n",
      "epoch 125 \n",
      "Error rate: 0.00961538461538\n",
      "Train acc: 0.990384615385\n",
      "Loss: 2.66427\n",
      "epoch 126 \n",
      "Error rate: 0.0369591346154\n",
      "Train acc: 0.963040865385\n",
      "Loss: 2.72316\n",
      "epoch 127 \n",
      "Error rate: 0.00620993589744\n",
      "Train acc: 0.993790064103\n",
      "Loss: 2.63684\n",
      "epoch 128 \n",
      "Error rate: 0.0364583333333\n",
      "Train acc: 0.963541666667\n",
      "Loss: 2.71253\n",
      "epoch 129 \n",
      "Error rate: 0.00500801282051\n",
      "Train acc: 0.994991987179\n",
      "Loss: 2.62078\n",
      "epoch 130 \n",
      "Error rate: 0.0235376602564\n",
      "Train acc: 0.976462339744\n",
      "Loss: 2.6721\n",
      "epoch 131 \n",
      "Error rate: 0.021734775641\n",
      "Train acc: 0.978265224359\n",
      "Loss: 2.66009\n",
      "epoch 132 \n",
      "Error rate: 0.0760216346154\n",
      "Train acc: 0.923978365385\n",
      "Loss: 2.77334\n",
      "epoch 133 \n",
      "Error rate: 0.0130208333333\n",
      "Train acc: 0.986979166667\n",
      "Loss: 2.62857\n",
      "epoch 134 \n",
      "Error rate: 0.0925480769231\n",
      "Train acc: 0.907451923077\n",
      "Loss: 2.81157\n",
      "epoch 135 \n",
      "Error rate: 0.00951522435897\n",
      "Train acc: 0.990484775641\n",
      "Loss: 2.6075\n",
      "epoch 136 \n",
      "Error rate: 0.048577724359\n",
      "Train acc: 0.951422275641\n",
      "Loss: 2.69329\n",
      "epoch 137 \n",
      "Error rate: 0.00831330128205\n",
      "Train acc: 0.991686698718\n",
      "Loss: 2.58824\n",
      "epoch 138 \n",
      "Error rate: 0.0193309294872\n",
      "Train acc: 0.980669070513\n",
      "Loss: 2.62279\n",
      "epoch 139 \n",
      "Error rate: 0.00500801282051\n",
      "Train acc: 0.994991987179\n",
      "Loss: 2.57019\n",
      "epoch 140 \n",
      "Error rate: 0.0231370192308\n",
      "Train acc: 0.976862980769\n",
      "Loss: 2.61938\n",
      "epoch 141 \n",
      "Error rate: 0.00580929487179\n",
      "Train acc: 0.994190705128\n",
      "Loss: 2.55624\n",
      "epoch 142 \n",
      "Error rate: 0.0852363782051\n",
      "Train acc: 0.914763621795\n",
      "Loss: 2.74673\n",
      "epoch 143 \n",
      "Error rate: 0.0103165064103\n",
      "Train acc: 0.98968349359\n",
      "Loss: 2.56807\n",
      "epoch 144 \n",
      "Error rate: 0.0254407051282\n",
      "Train acc: 0.974559294872\n",
      "Loss: 2.60222\n",
      "epoch 145 \n",
      "Error rate: 0.00390625\n",
      "Train acc: 0.99609375\n",
      "Loss: 2.53432\n",
      "epoch 146 \n",
      "Error rate: 0.0190304487179\n",
      "Train acc: 0.980969551282\n",
      "Loss: 2.57746\n",
      "epoch 147 \n",
      "Error rate: 0.00470753205128\n",
      "Train acc: 0.995292467949\n",
      "Loss: 2.521\n",
      "epoch 148 \n",
      "Error rate: 0.0175280448718\n",
      "Train acc: 0.982471955128\n",
      "Loss: 2.56215\n",
      "epoch 149 \n",
      "Error rate: 0.0088141025641\n",
      "Train acc: 0.991185897436\n",
      "Loss: 2.52861\n",
      "epoch 150 \n",
      "Error rate: 0.0115184294872\n",
      "Train acc: 0.988481570513\n",
      "Loss: 2.53591\n",
      "epoch 151 \n",
      "Error rate: 0.00590945512821\n",
      "Train acc: 0.994090544872\n",
      "Loss: 2.50898\n",
      "epoch 152 \n",
      "Error rate: 0.00961538461538\n",
      "Train acc: 0.990384615385\n",
      "Loss: 2.5191\n",
      "epoch 153 \n",
      "Error rate: 0.00330528846154\n",
      "Train acc: 0.996694711538\n",
      "Loss: 2.49123\n",
      "epoch 154 \n",
      "Error rate: 0.0112179487179\n",
      "Train acc: 0.988782051282\n",
      "Loss: 2.51119\n",
      "epoch 155 \n",
      "Error rate: 0.00400641025641\n",
      "Train acc: 0.995993589744\n",
      "Loss: 2.47524\n",
      "epoch 156 \n",
      "Error rate: 0.079827724359\n",
      "Train acc: 0.920172275641\n",
      "Loss: 2.6643\n",
      "epoch 157 \n",
      "Error rate: 0.0101161858974\n",
      "Train acc: 0.989883814103\n",
      "Loss: 2.48814\n",
      "epoch 158 \n",
      "Error rate: 0.0164262820513\n",
      "Train acc: 0.983573717949\n",
      "Loss: 2.51062\n",
      "epoch 159 \n",
      "Error rate: 0.00240384615385\n",
      "Train acc: 0.997596153846\n",
      "Loss: 2.45593\n",
      "epoch 160 \n",
      "Error rate: 0.0501802884615\n",
      "Train acc: 0.949819711538\n",
      "Loss: 2.5726\n",
      "epoch 161 \n",
      "Error rate: 0.00811298076923\n",
      "Train acc: 0.991887019231\n",
      "Loss: 2.459\n",
      "epoch 162 \n",
      "Error rate: 0.072516025641\n",
      "Train acc: 0.927483974359\n",
      "Loss: 2.61954\n",
      "epoch 163 \n",
      "Error rate: 0.0049078525641\n",
      "Train acc: 0.995092147436\n",
      "Loss: 2.44017\n",
      "epoch 164 \n",
      "Error rate: 0.0199318910256\n",
      "Train acc: 0.980068108974\n",
      "Loss: 2.48951\n",
      "epoch 165 \n",
      "Error rate: 0.00220352564103\n",
      "Train acc: 0.997796474359\n",
      "Loss: 2.41939\n",
      "epoch 166 \n",
      "Error rate: 0.0183293269231\n",
      "Train acc: 0.981670673077\n",
      "Loss: 2.47078\n",
      "epoch 167 \n",
      "Error rate: 0.000901442307692\n",
      "Train acc: 0.999098557692\n",
      "Loss: 2.40588\n",
      "epoch 168 \n",
      "Error rate: 0.0309495192308\n",
      "Train acc: 0.969050480769\n",
      "Loss: 2.49278\n",
      "epoch 169 \n",
      "Error rate: 0.00550881410256\n",
      "Train acc: 0.994491185897\n",
      "Loss: 2.41703\n",
      "epoch 170 \n",
      "Error rate: 0.00901442307692\n",
      "Train acc: 0.990985576923\n",
      "Loss: 2.43031\n",
      "epoch 171 \n",
      "Error rate: 0.00130208333333\n",
      "Train acc: 0.998697916667\n",
      "Loss: 2.39159\n",
      "epoch 172 \n",
      "Error rate: 0.0231370192308\n",
      "Train acc: 0.976862980769\n",
      "Loss: 2.45159\n",
      "epoch 173 \n",
      "Error rate: 0.00320512820513\n",
      "Train acc: 0.996794871795\n",
      "Loss: 2.3896\n",
      "epoch 174 \n",
      "Error rate: 0.00530849358974\n",
      "Train acc: 0.99469150641\n",
      "Loss: 2.39686\n",
      "epoch 175 \n",
      "Error rate: 0.00010016025641\n",
      "Train acc: 0.999899839744\n",
      "Loss: 2.364\n",
      "epoch 176 \n",
      "Error rate: 0.00861378205128\n",
      "Train acc: 0.991386217949\n",
      "Loss: 2.39561\n",
      "epoch 177 \n",
      "Error rate: 0.000801282051282\n",
      "Train acc: 0.999198717949\n",
      "Loss: 2.35524\n",
      "epoch 178 \n",
      "Error rate: 0.010016025641\n",
      "Train acc: 0.989983974359\n",
      "Loss: 2.38557\n",
      "epoch 179 \n",
      "Error rate: 0.0078125\n",
      "Train acc: 0.9921875\n",
      "Loss: 2.36534\n",
      "epoch 180 \n",
      "Error rate: 0.0168269230769\n",
      "Train acc: 0.983173076923\n",
      "Loss: 2.39303\n",
      "epoch 181 \n",
      "Error rate: 0.00380608974359\n",
      "Train acc: 0.996193910256\n",
      "Loss: 2.34236\n",
      "epoch 182 \n",
      "Error rate: 0.0365584935897\n",
      "Train acc: 0.96344150641\n",
      "Loss: 2.42854\n",
      "epoch 183 \n",
      "Error rate: 0.0078125\n",
      "Train acc: 0.9921875\n",
      "Loss: 2.34807\n",
      "epoch 184 \n",
      "Error rate: 0.0138221153846\n",
      "Train acc: 0.986177884615\n",
      "Loss: 2.37004\n",
      "epoch 185 \n",
      "Error rate: 0.00180288461538\n",
      "Train acc: 0.998197115385\n",
      "Loss: 2.32123\n",
      "epoch 186 \n",
      "Error rate: 0.104867788462\n",
      "Train acc: 0.895132211538\n",
      "Loss: 2.59291\n",
      "epoch 187 \n",
      "Error rate: 0.00540865384615\n",
      "Train acc: 0.994591346154\n",
      "Loss: 2.32848\n",
      "epoch 188 \n",
      "Error rate: 0.00761217948718\n",
      "Train acc: 0.992387820513\n",
      "Loss: 2.3393\n",
      "epoch 189 \n",
      "Error rate: 0.000500801282051\n",
      "Train acc: 0.999499198718\n",
      "Loss: 2.29632\n",
      "epoch 190 \n",
      "Error rate: 0.00651041666667\n",
      "Train acc: 0.993489583333\n",
      "Loss: 2.31997\n",
      "epoch 191 \n",
      "Error rate: 0.000500801282051\n",
      "Train acc: 0.999499198718\n",
      "Loss: 2.28676\n",
      "epoch 192 \n",
      "Error rate: 0.0447716346154\n",
      "Train acc: 0.955228365385\n",
      "Loss: 2.40298\n",
      "epoch 193 \n",
      "Error rate: 0.00971554487179\n",
      "Train acc: 0.990284455128\n",
      "Loss: 2.31151\n",
      "epoch 194 \n",
      "Error rate: 0.00310496794872\n",
      "Train acc: 0.996895032051\n",
      "Loss: 2.29641\n",
      "epoch 195 \n",
      "Error rate: 0.000300480769231\n",
      "Train acc: 0.999699519231\n",
      "Loss: 2.26984\n",
      "epoch 196 \n",
      "Error rate: 0.0138221153846\n",
      "Train acc: 0.986177884615\n",
      "Loss: 2.31566\n",
      "epoch 197 \n",
      "Error rate: 0.00200320512821\n",
      "Train acc: 0.997996794872\n",
      "Loss: 2.26687\n",
      "epoch 198 \n",
      "Error rate: 0.000701121794872\n",
      "Train acc: 0.999298878205\n",
      "Loss: 2.26499\n",
      "epoch 199 \n",
      "Error rate: 0.0\n",
      "Train acc: 1.0\n",
      "Loss: 2.24702\n",
      "epoch 200 \n",
      "Error rate: 0.00560897435897\n",
      "Train acc: 0.994391025641\n",
      "Loss: 2.27105\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "generic_5_spectral = CNN_Spectral_Param(num_output=10, kernel_size=5, architecture='generic', use_spectral_params=True)\n",
    "generic_5_spectral.train(xtrain, ytrain, batch_size=128, epochs=200)\n",
    "\n",
    "write_error_rate('generic_5_spectral', generic_5_spectral.error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches for training: 78\n",
      "epoch 1 \n",
      "Error rate: 0.726762820513\n",
      "Train acc: 0.273237179487\n",
      "Loss: 3.3316\n",
      "epoch 2 \n",
      "Error rate: 0.606570512821\n",
      "Train acc: 0.393429487179\n",
      "Loss: 2.89676\n",
      "epoch 3 \n",
      "Error rate: 0.544971955128\n",
      "Train acc: 0.455028044872\n",
      "Loss: 2.68731\n",
      "epoch 4 \n",
      "Error rate: 0.536157852564\n",
      "Train acc: 0.463842147436\n",
      "Loss: 2.61096\n",
      "epoch 5 \n",
      "Error rate: 0.487379807692\n",
      "Train acc: 0.512620192308\n",
      "Loss: 2.45398\n",
      "epoch 6 \n",
      "Error rate: 0.475260416667\n",
      "Train acc: 0.524739583333\n",
      "Loss: 2.41888\n",
      "epoch 7 \n",
      "Error rate: 0.433693910256\n",
      "Train acc: 0.566306089744\n",
      "Loss: 2.29908\n",
      "epoch 8 \n",
      "Error rate: 0.444911858974\n",
      "Train acc: 0.555088141026\n",
      "Loss: 2.29821\n",
      "epoch 9 \n",
      "Error rate: 0.411858974359\n",
      "Train acc: 0.588141025641\n",
      "Loss: 2.21133\n",
      "epoch 10 \n",
      "Error rate: 0.414262820513\n",
      "Train acc: 0.585737179487\n",
      "Loss: 2.20448\n",
      "epoch 11 \n",
      "Error rate: 0.379306891026\n",
      "Train acc: 0.620693108974\n",
      "Loss: 2.09959\n",
      "epoch 12 \n",
      "Error rate: 0.400140224359\n",
      "Train acc: 0.599859775641\n",
      "Loss: 2.1398\n",
      "epoch 13 \n",
      "Error rate: 0.361478365385\n",
      "Train acc: 0.638521634615\n",
      "Loss: 2.03539\n",
      "epoch 14 \n",
      "Error rate: 0.380709134615\n",
      "Train acc: 0.619290865385\n",
      "Loss: 2.07122\n",
      "epoch 15 \n",
      "Error rate: 0.347355769231\n",
      "Train acc: 0.652644230769\n",
      "Loss: 1.98116\n",
      "epoch 16 \n",
      "Error rate: 0.36578525641\n",
      "Train acc: 0.63421474359\n",
      "Loss: 2.03279\n",
      "epoch 17 \n",
      "Error rate: 0.323016826923\n",
      "Train acc: 0.676983173077\n",
      "Loss: 1.91204\n",
      "epoch 18 \n",
      "Error rate: 0.349258814103\n",
      "Train acc: 0.650741185897\n",
      "Loss: 1.9735\n",
      "epoch 19 \n",
      "Error rate: 0.315905448718\n",
      "Train acc: 0.684094551282\n",
      "Loss: 1.87085\n",
      "epoch 20 \n",
      "Error rate: 0.335637019231\n",
      "Train acc: 0.664362980769\n",
      "Loss: 1.92275\n",
      "epoch 21 \n",
      "Error rate: 0.297876602564\n",
      "Train acc: 0.702123397436\n",
      "Loss: 1.81269\n",
      "epoch 22 \n",
      "Error rate: 0.311598557692\n",
      "Train acc: 0.688401442308\n",
      "Loss: 1.85352\n",
      "epoch 23 \n",
      "Error rate: 0.27203525641\n",
      "Train acc: 0.72796474359\n",
      "Loss: 1.75311\n",
      "epoch 24 \n",
      "Error rate: 0.335036057692\n",
      "Train acc: 0.664963942308\n",
      "Loss: 1.89096\n",
      "epoch 25 \n",
      "Error rate: 0.288060897436\n",
      "Train acc: 0.711939102564\n",
      "Loss: 1.77619\n",
      "epoch 26 \n",
      "Error rate: 0.307792467949\n",
      "Train acc: 0.692207532051\n",
      "Loss: 1.81438\n",
      "epoch 27 \n",
      "Error rate: 0.26702724359\n",
      "Train acc: 0.73297275641\n",
      "Loss: 1.71507\n",
      "epoch 28 \n",
      "Error rate: 0.29827724359\n",
      "Train acc: 0.70172275641\n",
      "Loss: 1.77249\n",
      "epoch 29 \n",
      "Error rate: 0.250400641026\n",
      "Train acc: 0.749599358974\n",
      "Loss: 1.65428\n",
      "epoch 30 \n",
      "Error rate: 0.289963942308\n",
      "Train acc: 0.710036057692\n",
      "Loss: 1.75671\n",
      "epoch 31 \n",
      "Error rate: 0.240584935897\n",
      "Train acc: 0.759415064103\n",
      "Loss: 1.62334\n",
      "epoch 32 \n",
      "Error rate: 0.266326121795\n",
      "Train acc: 0.733673878205\n",
      "Loss: 1.67744\n",
      "epoch 33 \n",
      "Error rate: 0.252403846154\n",
      "Train acc: 0.747596153846\n",
      "Loss: 1.64478\n",
      "epoch 34 \n",
      "Error rate: 0.271033653846\n",
      "Train acc: 0.728966346154\n",
      "Loss: 1.68888\n",
      "epoch 35 \n",
      "Error rate: 0.233573717949\n",
      "Train acc: 0.766426282051\n",
      "Loss: 1.583\n",
      "epoch 36 \n",
      "Error rate: 0.26702724359\n",
      "Train acc: 0.73297275641\n",
      "Loss: 1.66201\n",
      "epoch 37 \n",
      "Error rate: 0.229667467949\n",
      "Train acc: 0.770332532051\n",
      "Loss: 1.57316\n",
      "epoch 38 \n",
      "Error rate: 0.243189102564\n",
      "Train acc: 0.756810897436\n",
      "Loss: 1.60872\n",
      "epoch 39 \n",
      "Error rate: 0.205729166667\n",
      "Train acc: 0.794270833333\n",
      "Loss: 1.50756\n",
      "epoch 40 \n",
      "Error rate: 0.237680288462\n",
      "Train acc: 0.762319711538\n",
      "Loss: 1.57994\n",
      "epoch 41 \n",
      "Error rate: 0.219150641026\n",
      "Train acc: 0.780849358974\n",
      "Loss: 1.52638\n",
      "epoch 42 \n",
      "Error rate: 0.220352564103\n",
      "Train acc: 0.779647435897\n",
      "Loss: 1.53678\n",
      "epoch 43 \n",
      "Error rate: 0.183693910256\n",
      "Train acc: 0.816306089744\n",
      "Loss: 1.43282\n",
      "epoch 44 \n",
      "Error rate: 0.253004807692\n",
      "Train acc: 0.746995192308\n",
      "Loss: 1.60738\n",
      "epoch 45 \n",
      "Error rate: 0.190905448718\n",
      "Train acc: 0.809094551282\n",
      "Loss: 1.45144\n",
      "epoch 46 \n",
      "Error rate: 0.229567307692\n",
      "Train acc: 0.770432692308\n",
      "Loss: 1.54672\n",
      "epoch 47 \n",
      "Error rate: 0.172576121795\n",
      "Train acc: 0.827423878205\n",
      "Loss: 1.39762\n",
      "epoch 48 \n",
      "Error rate: 0.205028044872\n",
      "Train acc: 0.794971955128\n",
      "Loss: 1.47659\n",
      "epoch 49 \n",
      "Error rate: 0.160256410256\n",
      "Train acc: 0.839743589744\n",
      "Loss: 1.36117\n",
      "epoch 50 \n",
      "Error rate: 0.2109375\n",
      "Train acc: 0.7890625\n",
      "Loss: 1.49108\n",
      "epoch 51 \n",
      "Error rate: 0.144030448718\n",
      "Train acc: 0.855969551282\n",
      "Loss: 1.32751\n",
      "epoch 52 \n",
      "Error rate: 0.215344551282\n",
      "Train acc: 0.784655448718\n",
      "Loss: 1.4953\n",
      "epoch 53 \n",
      "Error rate: 0.160757211538\n",
      "Train acc: 0.839242788462\n",
      "Loss: 1.35283\n",
      "epoch 54 \n",
      "Error rate: 0.205729166667\n",
      "Train acc: 0.794270833333\n",
      "Loss: 1.46028\n",
      "epoch 55 \n",
      "Error rate: 0.13141025641\n",
      "Train acc: 0.86858974359\n",
      "Loss: 1.28682\n",
      "epoch 56 \n",
      "Error rate: 0.200220352564\n",
      "Train acc: 0.799779647436\n",
      "Loss: 1.44053\n",
      "epoch 57 \n",
      "Error rate: 0.125600961538\n",
      "Train acc: 0.874399038462\n",
      "Loss: 1.26494\n",
      "epoch 58 \n",
      "Error rate: 0.178986378205\n",
      "Train acc: 0.821013621795\n",
      "Loss: 1.38803\n",
      "epoch 59 \n",
      "Error rate: 0.110677083333\n",
      "Train acc: 0.889322916667\n",
      "Loss: 1.22531\n",
      "epoch 60 \n",
      "Error rate: 0.191806891026\n",
      "Train acc: 0.808193108974\n",
      "Loss: 1.40641\n",
      "epoch 61 \n",
      "Error rate: 0.129006410256\n",
      "Train acc: 0.870993589744\n",
      "Loss: 1.25715\n",
      "epoch 62 \n",
      "Error rate: 0.161258012821\n",
      "Train acc: 0.838741987179\n",
      "Loss: 1.32613\n",
      "epoch 63 \n",
      "Error rate: 0.120392628205\n",
      "Train acc: 0.879607371795\n",
      "Loss: 1.23263\n",
      "epoch 64 \n",
      "Error rate: 0.156550480769\n",
      "Train acc: 0.843449519231\n",
      "Loss: 1.31752\n",
      "epoch 65 \n",
      "Error rate: 0.117588141026\n",
      "Train acc: 0.882411858974\n",
      "Loss: 1.21897\n",
      "epoch 66 \n",
      "Error rate: 0.137419871795\n",
      "Train acc: 0.862580128205\n",
      "Loss: 1.27375\n",
      "epoch 67 \n",
      "Error rate: 0.103365384615\n",
      "Train acc: 0.896634615385\n",
      "Loss: 1.18948\n",
      "epoch 68 \n",
      "Error rate: 0.147936698718\n",
      "Train acc: 0.852063301282\n",
      "Loss: 1.2925\n",
      "epoch 69 \n",
      "Error rate: 0.0882411858974\n",
      "Train acc: 0.911758814103\n",
      "Loss: 1.15135\n",
      "epoch 70 \n",
      "Error rate: 0.172676282051\n",
      "Train acc: 0.827323717949\n",
      "Loss: 1.33884\n",
      "epoch 71 \n",
      "Error rate: 0.0873397435897\n",
      "Train acc: 0.91266025641\n",
      "Loss: 1.14301\n",
      "epoch 72 \n",
      "Error rate: 0.154246794872\n",
      "Train acc: 0.845753205128\n",
      "Loss: 1.30068\n",
      "epoch 73 \n",
      "Error rate: 0.0761217948718\n",
      "Train acc: 0.923878205128\n",
      "Loss: 1.1201\n",
      "epoch 74 \n",
      "Error rate: 0.126602564103\n",
      "Train acc: 0.873397435897\n",
      "Loss: 1.21734\n",
      "epoch 75 \n",
      "Error rate: 0.0628004807692\n",
      "Train acc: 0.937199519231\n",
      "Loss: 1.08409\n",
      "epoch 76 \n",
      "Error rate: 0.138621794872\n",
      "Train acc: 0.861378205128\n",
      "Loss: 1.24439\n",
      "epoch 77 \n",
      "Error rate: 0.0660056089744\n",
      "Train acc: 0.933994391026\n",
      "Loss: 1.08413\n",
      "epoch 78 \n",
      "Error rate: 0.132411858974\n",
      "Train acc: 0.867588141026\n",
      "Loss: 1.23632\n",
      "epoch 79 \n",
      "Error rate: 0.0600961538462\n",
      "Train acc: 0.939903846154\n",
      "Loss: 1.06604\n",
      "epoch 80 \n",
      "Error rate: 0.125300480769\n",
      "Train acc: 0.874699519231\n",
      "Loss: 1.21063\n",
      "epoch 81 \n",
      "Error rate: 0.0496794871795\n",
      "Train acc: 0.950320512821\n",
      "Loss: 1.0435\n",
      "epoch 82 \n",
      "Error rate: 0.108173076923\n",
      "Train acc: 0.891826923077\n",
      "Loss: 1.16967\n",
      "epoch 83 \n",
      "Error rate: 0.0631009615385\n",
      "Train acc: 0.936899038462\n",
      "Loss: 1.0626\n",
      "epoch 84 \n",
      "Error rate: 0.100060096154\n",
      "Train acc: 0.899939903846\n",
      "Loss: 1.14872\n",
      "epoch 85 \n",
      "Error rate: 0.0445713141026\n",
      "Train acc: 0.955428685897\n",
      "Loss: 1.01832\n",
      "epoch 86 \n",
      "Error rate: 0.0946514423077\n",
      "Train acc: 0.905348557692\n",
      "Loss: 1.12749\n",
      "epoch 87 \n",
      "Error rate: 0.0460737179487\n",
      "Train acc: 0.953926282051\n",
      "Loss: 1.02306\n",
      "epoch 88 \n",
      "Error rate: 0.105568910256\n",
      "Train acc: 0.894431089744\n",
      "Loss: 1.14905\n",
      "epoch 89 \n",
      "Error rate: 0.0304487179487\n",
      "Train acc: 0.969551282051\n",
      "Loss: 0.983242\n",
      "epoch 90 \n",
      "Error rate: 0.0744190705128\n",
      "Train acc: 0.925580929487\n",
      "Loss: 1.08243\n",
      "epoch 91 \n",
      "Error rate: 0.0202323717949\n",
      "Train acc: 0.979767628205\n",
      "Loss: 0.94925\n",
      "epoch 92 \n",
      "Error rate: 0.104467147436\n",
      "Train acc: 0.895532852564\n",
      "Loss: 1.14536\n",
      "epoch 93 \n",
      "Error rate: 0.0450721153846\n",
      "Train acc: 0.954927884615\n",
      "Loss: 1.00251\n",
      "epoch 94 \n",
      "Error rate: 0.0659054487179\n",
      "Train acc: 0.934094551282\n",
      "Loss: 1.05792\n",
      "epoch 95 \n",
      "Error rate: 0.0198317307692\n",
      "Train acc: 0.980168269231\n",
      "Loss: 0.940869\n",
      "epoch 96 \n",
      "Error rate: 0.0780248397436\n",
      "Train acc: 0.921975160256\n",
      "Loss: 1.07816\n",
      "epoch 97 \n",
      "Error rate: 0.0165264423077\n",
      "Train acc: 0.983473557692\n",
      "Loss: 0.934604\n",
      "epoch 98 \n",
      "Error rate: 0.104266826923\n",
      "Train acc: 0.895733173077\n",
      "Loss: 1.12901\n",
      "epoch 99 \n",
      "Error rate: 0.0244391025641\n",
      "Train acc: 0.975560897436\n",
      "Loss: 0.950893\n",
      "epoch 100 \n",
      "Error rate: 0.0882411858974\n",
      "Train acc: 0.911758814103\n",
      "Loss: 1.09347\n",
      "epoch 101 \n",
      "Error rate: 0.0151241987179\n",
      "Train acc: 0.984875801282\n",
      "Loss: 0.925895\n",
      "epoch 102 \n",
      "Error rate: 0.0793269230769\n",
      "Train acc: 0.920673076923\n",
      "Loss: 1.06457\n",
      "epoch 103 \n",
      "Error rate: 0.0192307692308\n",
      "Train acc: 0.980769230769\n",
      "Loss: 0.927925\n",
      "epoch 104 \n",
      "Error rate: 0.0706129807692\n",
      "Train acc: 0.929387019231\n",
      "Loss: 1.04019\n",
      "epoch 105 \n",
      "Error rate: 0.0169270833333\n",
      "Train acc: 0.983072916667\n",
      "Loss: 0.919202\n",
      "epoch 106 \n",
      "Error rate: 0.0639022435897\n",
      "Train acc: 0.93609775641\n",
      "Loss: 1.0226\n",
      "epoch 107 \n",
      "Error rate: 0.0145232371795\n",
      "Train acc: 0.985476762821\n",
      "Loss: 0.908766\n",
      "epoch 108 \n",
      "Error rate: 0.0579927884615\n",
      "Train acc: 0.942007211538\n",
      "Loss: 1.01043\n",
      "epoch 109 \n",
      "Error rate: 0.0161258012821\n",
      "Train acc: 0.983874198718\n",
      "Loss: 0.911195\n",
      "epoch 110 \n",
      "Error rate: 0.0452724358974\n",
      "Train acc: 0.954727564103\n",
      "Loss: 0.983472\n",
      "epoch 111 \n",
      "Error rate: 0.00871394230769\n",
      "Train acc: 0.991286057692\n",
      "Loss: 0.882949\n",
      "epoch 112 \n",
      "Error rate: 0.0578926282051\n",
      "Train acc: 0.942107371795\n",
      "Loss: 0.993953\n",
      "epoch 113 \n",
      "Error rate: 0.00600961538462\n",
      "Train acc: 0.993990384615\n",
      "Loss: 0.873992\n",
      "epoch 114 \n",
      "Error rate: 0.0333533653846\n",
      "Train acc: 0.966646634615\n",
      "Loss: 0.94308\n",
      "epoch 115 \n",
      "Error rate: 0.00400641025641\n",
      "Train acc: 0.995993589744\n",
      "Loss: 0.857623\n",
      "epoch 116 \n",
      "Error rate: 0.0683092948718\n",
      "Train acc: 0.931690705128\n",
      "Loss: 1.01403\n",
      "epoch 117 \n",
      "Error rate: 0.00731169871795\n",
      "Train acc: 0.992688301282\n",
      "Loss: 0.868738\n",
      "epoch 118 \n",
      "Error rate: 0.0952524038462\n",
      "Train acc: 0.904747596154\n",
      "Loss: 1.07457\n",
      "epoch 119 \n",
      "Error rate: 0.0109174679487\n",
      "Train acc: 0.989082532051\n",
      "Loss: 0.87844\n",
      "epoch 120 \n",
      "Error rate: 0.0444711538462\n",
      "Train acc: 0.955528846154\n",
      "Loss: 0.957654\n",
      "epoch 121 \n",
      "Error rate: 0.0150240384615\n",
      "Train acc: 0.984975961538\n",
      "Loss: 0.885403\n",
      "epoch 122 \n",
      "Error rate: 0.0552884615385\n",
      "Train acc: 0.944711538462\n",
      "Loss: 0.979774\n",
      "epoch 123 \n",
      "Error rate: 0.00711137820513\n",
      "Train acc: 0.992888621795\n",
      "Loss: 0.859768\n",
      "epoch 124 \n",
      "Error rate: 0.0513822115385\n",
      "Train acc: 0.948617788462\n",
      "Loss: 0.976901\n",
      "epoch 125 \n",
      "Error rate: 0.00791266025641\n",
      "Train acc: 0.992087339744\n",
      "Loss: 0.857762\n",
      "epoch 126 \n",
      "Error rate: 0.0353565705128\n",
      "Train acc: 0.964643429487\n",
      "Loss: 0.927037\n",
      "epoch 127 \n",
      "Error rate: 0.00440705128205\n",
      "Train acc: 0.995592948718\n",
      "Loss: 0.840612\n",
      "epoch 128 \n",
      "Error rate: 0.0594951923077\n",
      "Train acc: 0.940504807692\n",
      "Loss: 0.977494\n",
      "epoch 129 \n",
      "Error rate: 0.00641025641026\n",
      "Train acc: 0.99358974359\n",
      "Loss: 0.846376\n",
      "epoch 130 \n",
      "Error rate: 0.0555889423077\n",
      "Train acc: 0.944411057692\n",
      "Loss: 0.970008\n",
      "epoch 131 \n",
      "Error rate: 0.00530849358974\n",
      "Train acc: 0.99469150641\n",
      "Loss: 0.840068\n",
      "epoch 132 \n",
      "Error rate: 0.0364583333333\n",
      "Train acc: 0.963541666667\n",
      "Loss: 0.922622\n",
      "epoch 133 \n",
      "Error rate: 0.00300480769231\n",
      "Train acc: 0.996995192308\n",
      "Loss: 0.828546\n",
      "epoch 134 \n",
      "Error rate: 0.0326522435897\n",
      "Train acc: 0.96734775641\n",
      "Loss: 0.910871\n",
      "epoch 135 \n",
      "Error rate: 0.00420673076923\n",
      "Train acc: 0.995793269231\n",
      "Loss: 0.827076\n",
      "epoch 136 \n",
      "Error rate: 0.0339543269231\n",
      "Train acc: 0.966045673077\n",
      "Loss: 0.902687\n",
      "epoch 137 \n",
      "Error rate: 0.00420673076923\n",
      "Train acc: 0.995793269231\n",
      "Loss: 0.822863\n",
      "epoch 138 \n",
      "Error rate: 0.0417668269231\n",
      "Train acc: 0.958233173077\n",
      "Loss: 0.921877\n",
      "epoch 139 \n",
      "Error rate: 0.00270432692308\n",
      "Train acc: 0.997295673077\n",
      "Loss: 0.814458\n",
      "epoch 140 \n",
      "Error rate: 0.0198317307692\n",
      "Train acc: 0.980168269231\n",
      "Loss: 0.869724\n",
      "epoch 141 \n",
      "Error rate: 0.0184294871795\n",
      "Train acc: 0.981570512821\n",
      "Loss: 0.85263\n",
      "epoch 142 \n",
      "Error rate: 0.0631009615385\n",
      "Train acc: 0.936899038462\n",
      "Loss: 0.959373\n",
      "epoch 143 \n",
      "Error rate: 0.00310496794872\n",
      "Train acc: 0.996895032051\n",
      "Loss: 0.812419\n",
      "epoch 144 \n",
      "Error rate: 0.0188301282051\n",
      "Train acc: 0.981169871795\n",
      "Loss: 0.862846\n",
      "epoch 145 \n",
      "Error rate: 0.0112179487179\n",
      "Train acc: 0.988782051282\n",
      "Loss: 0.834286\n",
      "epoch 146 \n",
      "Error rate: 0.0302483974359\n",
      "Train acc: 0.969751602564\n",
      "Loss: 0.882958\n",
      "epoch 147 \n",
      "Error rate: 0.00320512820513\n",
      "Train acc: 0.996794871795\n",
      "Loss: 0.803086\n",
      "epoch 148 \n",
      "Error rate: 0.0509815705128\n",
      "Train acc: 0.949018429487\n",
      "Loss: 0.93075\n",
      "epoch 149 \n",
      "Error rate: 0.00410657051282\n",
      "Train acc: 0.995893429487\n",
      "Loss: 0.803709\n",
      "epoch 150 \n",
      "Error rate: 0.0320512820513\n",
      "Train acc: 0.967948717949\n",
      "Loss: 0.883515\n",
      "epoch 151 \n",
      "Error rate: 0.0129206730769\n",
      "Train acc: 0.987079326923\n",
      "Loss: 0.827613\n",
      "epoch 152 \n",
      "Error rate: 0.0318509615385\n",
      "Train acc: 0.968149038462\n",
      "Loss: 0.879827\n",
      "epoch 153 \n",
      "Error rate: 0.00270432692308\n",
      "Train acc: 0.997295673077\n",
      "Loss: 0.79312\n",
      "epoch 154 \n",
      "Error rate: 0.0180288461538\n",
      "Train acc: 0.981971153846\n",
      "Loss: 0.841988\n",
      "epoch 155 \n",
      "Error rate: 0.00460737179487\n",
      "Train acc: 0.995392628205\n",
      "Loss: 0.799118\n",
      "epoch 156 \n",
      "Error rate: 0.0262419871795\n",
      "Train acc: 0.973758012821\n",
      "Loss: 0.865934\n",
      "epoch 157 \n",
      "Error rate: 0.00220352564103\n",
      "Train acc: 0.997796474359\n",
      "Loss: 0.786102\n",
      "epoch 158 \n",
      "Error rate: 0.0307491987179\n",
      "Train acc: 0.969250801282\n",
      "Loss: 0.868467\n",
      "epoch 159 \n",
      "Error rate: 0.00350560897436\n",
      "Train acc: 0.996494391026\n",
      "Loss: 0.785188\n",
      "epoch 160 \n",
      "Error rate: 0.0172275641026\n",
      "Train acc: 0.982772435897\n",
      "Loss: 0.833093\n",
      "epoch 161 \n",
      "Error rate: 0.00460737179487\n",
      "Train acc: 0.995392628205\n",
      "Loss: 0.788899\n",
      "epoch 162 \n",
      "Error rate: 0.0232371794872\n",
      "Train acc: 0.976762820513\n",
      "Loss: 0.844377\n",
      "epoch 163 \n",
      "Error rate: 0.00520833333333\n",
      "Train acc: 0.994791666667\n",
      "Loss: 0.786146\n",
      "epoch 164 \n",
      "Error rate: 0.0106169871795\n",
      "Train acc: 0.989383012821\n",
      "Loss: 0.808645\n",
      "epoch 165 \n",
      "Error rate: 0.00160256410256\n",
      "Train acc: 0.998397435897\n",
      "Loss: 0.762738\n",
      "epoch 166 \n",
      "Error rate: 0.0143229166667\n",
      "Train acc: 0.985677083333\n",
      "Loss: 0.811243\n",
      "epoch 167 \n",
      "Error rate: 0.0238381410256\n",
      "Train acc: 0.976161858974\n",
      "Loss: 0.832423\n",
      "epoch 168 \n",
      "Error rate: 0.0130208333333\n",
      "Train acc: 0.986979166667\n",
      "Loss: 0.812163\n",
      "epoch 169 \n",
      "Error rate: 0.0010016025641\n",
      "Train acc: 0.998998397436\n",
      "Loss: 0.755467\n",
      "epoch 170 \n",
      "Error rate: 0.0722155448718\n",
      "Train acc: 0.927784455128\n",
      "Loss: 0.946237\n",
      "epoch 171 \n",
      "Error rate: 0.00961538461538\n",
      "Train acc: 0.990384615385\n",
      "Loss: 0.79091\n",
      "epoch 172 \n",
      "Error rate: 0.0578926282051\n",
      "Train acc: 0.942107371795\n",
      "Loss: 0.911264\n",
      "epoch 173 \n",
      "Error rate: 0.00590945512821\n",
      "Train acc: 0.994090544872\n",
      "Loss: 0.779573\n",
      "epoch 174 \n",
      "Error rate: 0.0321514423077\n",
      "Train acc: 0.967848557692\n",
      "Loss: 0.851852\n",
      "epoch 175 \n",
      "Error rate: 0.00500801282051\n",
      "Train acc: 0.994991987179\n",
      "Loss: 0.769405\n",
      "epoch 176 \n",
      "Error rate: 0.010016025641\n",
      "Train acc: 0.989983974359\n",
      "Loss: 0.794924\n",
      "epoch 177 \n",
      "Error rate: 0.0029046474359\n",
      "Train acc: 0.997095352564\n",
      "Loss: 0.763246\n",
      "epoch 178 \n",
      "Error rate: 0.0194310897436\n",
      "Train acc: 0.980568910256\n",
      "Loss: 0.816842\n",
      "epoch 179 \n",
      "Error rate: 0.00110176282051\n",
      "Train acc: 0.998898237179\n",
      "Loss: 0.750476\n",
      "epoch 180 \n",
      "Error rate: 0.0372596153846\n",
      "Train acc: 0.962740384615\n",
      "Loss: 0.849474\n",
      "epoch 181 \n",
      "Error rate: 0.00160256410256\n",
      "Train acc: 0.998397435897\n",
      "Loss: 0.749561\n",
      "epoch 182 \n",
      "Error rate: 0.0123197115385\n",
      "Train acc: 0.987680288462\n",
      "Loss: 0.791996\n",
      "epoch 183 \n",
      "Error rate: 0.00170272435897\n",
      "Train acc: 0.998297275641\n",
      "Loss: 0.741942\n",
      "epoch 184 \n",
      "Error rate: 0.025641025641\n",
      "Train acc: 0.974358974359\n",
      "Loss: 0.817357\n",
      "epoch 185 \n",
      "Error rate: 0.00230368589744\n",
      "Train acc: 0.997696314103\n",
      "Loss: 0.741695\n",
      "epoch 186 \n",
      "Error rate: 0.00821314102564\n",
      "Train acc: 0.991786858974\n",
      "Loss: 0.775898\n",
      "epoch 187 \n",
      "Error rate: 0.000801282051282\n",
      "Train acc: 0.999198717949\n",
      "Loss: 0.727935\n",
      "epoch 188 \n",
      "Error rate: 0.0137219551282\n",
      "Train acc: 0.986278044872\n",
      "Loss: 0.782881\n",
      "epoch 189 \n",
      "Error rate: 0.000600961538462\n",
      "Train acc: 0.999399038462\n",
      "Loss: 0.724042\n",
      "epoch 190 \n",
      "Error rate: 0.00821314102564\n",
      "Train acc: 0.991786858974\n",
      "Loss: 0.759911\n",
      "epoch 191 \n",
      "Error rate: 0.0132211538462\n",
      "Train acc: 0.986778846154\n",
      "Loss: 0.773456\n",
      "epoch 192 \n",
      "Error rate: 0.0458733974359\n",
      "Train acc: 0.954126602564\n",
      "Loss: 0.858681\n",
      "epoch 193 \n",
      "Error rate: 0.010016025641\n",
      "Train acc: 0.989983974359\n",
      "Loss: 0.764936\n",
      "epoch 194 \n",
      "Error rate: 0.0398637820513\n",
      "Train acc: 0.960136217949\n",
      "Loss: 0.84683\n",
      "epoch 195 \n",
      "Error rate: 0.00530849358974\n",
      "Train acc: 0.99469150641\n",
      "Loss: 0.74942\n",
      "epoch 196 \n",
      "Error rate: 0.0107171474359\n",
      "Train acc: 0.989282852564\n",
      "Loss: 0.77319\n",
      "epoch 197 \n",
      "Error rate: 0.00440705128205\n",
      "Train acc: 0.995592948718\n",
      "Loss: 0.745498\n",
      "epoch 198 \n",
      "Error rate: 0.0203325320513\n",
      "Train acc: 0.979667467949\n",
      "Loss: 0.794207\n",
      "epoch 199 \n",
      "Error rate: 0.00480769230769\n",
      "Train acc: 0.995192307692\n",
      "Loss: 0.743576\n",
      "epoch 200 \n",
      "Error rate: 0.0226362179487\n",
      "Train acc: 0.977363782051\n",
      "Loss: 0.795597\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "generic_5_spatial = CNN_Spectral_Param(num_output=10, kernel_size=5, architecture='generic', use_spectral_params=False)\n",
    "generic_5_spatial.train(xtrain, ytrain, batch_size=128, epochs=200)\n",
    "\n",
    "write_error_rate('generic_5_spatial', generic_5_spatial.error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches for training: 78\n",
      "epoch 1 \n",
      "Error rate: 0.840745192308\n",
      "Train acc: 0.159254807692\n",
      "Loss: 3.81159\n",
      "epoch 2 \n",
      "Error rate: 0.785757211538\n",
      "Train acc: 0.214242788462\n",
      "Loss: 3.42643\n",
      "epoch 3 \n",
      "Error rate: 0.755909455128\n",
      "Train acc: 0.244090544872\n",
      "Loss: 3.22364\n",
      "epoch 4 \n",
      "Error rate: 0.723657852564\n",
      "Train acc: 0.276342147436\n",
      "Loss: 3.05234\n",
      "epoch 5 \n",
      "Error rate: 0.708133012821\n",
      "Train acc: 0.291866987179\n",
      "Loss: 2.95316\n",
      "epoch 6 \n",
      "Error rate: 0.698918269231\n",
      "Train acc: 0.301081730769\n",
      "Loss: 2.8978\n",
      "epoch 7 \n",
      "Error rate: 0.676081730769\n",
      "Train acc: 0.323918269231\n",
      "Loss: 2.83186\n",
      "epoch 8 \n",
      "Error rate: 0.671574519231\n",
      "Train acc: 0.328425480769\n",
      "Loss: 2.80416\n",
      "epoch 9 \n",
      "Error rate: 0.649038461538\n",
      "Train acc: 0.350961538462\n",
      "Loss: 2.75614\n",
      "epoch 10 \n",
      "Error rate: 0.644731570513\n",
      "Train acc: 0.355268429487\n",
      "Loss: 2.73787\n",
      "epoch 11 \n",
      "Error rate: 0.620592948718\n",
      "Train acc: 0.379407051282\n",
      "Loss: 2.69025\n",
      "epoch 12 \n",
      "Error rate: 0.625300480769\n",
      "Train acc: 0.374699519231\n",
      "Loss: 2.68768\n",
      "epoch 13 \n",
      "Error rate: 0.61328125\n",
      "Train acc: 0.38671875\n",
      "Loss: 2.65724\n",
      "epoch 14 \n",
      "Error rate: 0.613681891026\n",
      "Train acc: 0.386318108974\n",
      "Loss: 2.64227\n",
      "epoch 15 \n",
      "Error rate: 0.585536858974\n",
      "Train acc: 0.414463141026\n",
      "Loss: 2.5916\n",
      "epoch 16 \n",
      "Error rate: 0.601262019231\n",
      "Train acc: 0.398737980769\n",
      "Loss: 2.60524\n",
      "epoch 17 \n",
      "Error rate: 0.575921474359\n",
      "Train acc: 0.424078525641\n",
      "Loss: 2.55065\n",
      "epoch 18 \n",
      "Error rate: 0.581330128205\n",
      "Train acc: 0.418669871795\n",
      "Loss: 2.54681\n",
      "epoch 19 \n",
      "Error rate: 0.564102564103\n",
      "Train acc: 0.435897435897\n",
      "Loss: 2.51719\n",
      "epoch 20 \n",
      "Error rate: 0.580528846154\n",
      "Train acc: 0.419471153846\n",
      "Loss: 2.5303\n",
      "epoch 21 \n",
      "Error rate: 0.561498397436\n",
      "Train acc: 0.438501602564\n",
      "Loss: 2.49072\n",
      "epoch 22 \n",
      "Error rate: 0.560897435897\n",
      "Train acc: 0.439102564103\n",
      "Loss: 2.49092\n",
      "epoch 23 \n",
      "Error rate: 0.554186698718\n",
      "Train acc: 0.445813301282\n",
      "Loss: 2.46482\n",
      "epoch 24 \n",
      "Error rate: 0.565304487179\n",
      "Train acc: 0.434695512821\n",
      "Loss: 2.47852\n",
      "epoch 25 \n",
      "Error rate: 0.548778044872\n",
      "Train acc: 0.451221955128\n",
      "Loss: 2.43475\n",
      "epoch 26 \n",
      "Error rate: 0.546674679487\n",
      "Train acc: 0.453325320513\n",
      "Loss: 2.4337\n",
      "epoch 27 \n",
      "Error rate: 0.542768429487\n",
      "Train acc: 0.457231570513\n",
      "Loss: 2.40429\n",
      "epoch 28 \n",
      "Error rate: 0.551181891026\n",
      "Train acc: 0.448818108974\n",
      "Loss: 2.41463\n",
      "epoch 29 \n",
      "Error rate: 0.529547275641\n",
      "Train acc: 0.470452724359\n",
      "Loss: 2.37325\n",
      "epoch 30 \n",
      "Error rate: 0.541065705128\n",
      "Train acc: 0.458934294872\n",
      "Loss: 2.38018\n",
      "epoch 31 \n",
      "Error rate: 0.534555288462\n",
      "Train acc: 0.465444711538\n",
      "Loss: 2.37055\n",
      "epoch 32 \n",
      "Error rate: 0.539563301282\n",
      "Train acc: 0.460436698718\n",
      "Loss: 2.36869\n",
      "epoch 33 \n",
      "Error rate: 0.526241987179\n",
      "Train acc: 0.473758012821\n",
      "Loss: 2.34052\n",
      "epoch 34 \n",
      "Error rate: 0.542067307692\n",
      "Train acc: 0.457932692308\n",
      "Loss: 2.3673\n",
      "epoch 35 \n",
      "Error rate: 0.526742788462\n",
      "Train acc: 0.473257211538\n",
      "Loss: 2.32472\n",
      "epoch 36 \n",
      "Error rate: 0.536658653846\n",
      "Train acc: 0.463341346154\n",
      "Loss: 2.32949\n",
      "epoch 37 \n",
      "Error rate: 0.522335737179\n",
      "Train acc: 0.477664262821\n",
      "Loss: 2.30131\n",
      "epoch 38 \n",
      "Error rate: 0.530548878205\n",
      "Train acc: 0.469451121795\n",
      "Loss: 2.32122\n",
      "epoch 39 \n",
      "Error rate: 0.520633012821\n",
      "Train acc: 0.479366987179\n",
      "Loss: 2.28516\n",
      "epoch 40 \n",
      "Error rate: 0.525140224359\n",
      "Train acc: 0.474859775641\n",
      "Loss: 2.28682\n",
      "epoch 41 \n",
      "Error rate: 0.518629807692\n",
      "Train acc: 0.481370192308\n",
      "Loss: 2.27443\n",
      "epoch 42 \n",
      "Error rate: 0.521534455128\n",
      "Train acc: 0.478465544872\n",
      "Loss: 2.28029\n",
      "epoch 43 \n",
      "Error rate: 0.504607371795\n",
      "Train acc: 0.495392628205\n",
      "Loss: 2.24814\n",
      "epoch 44 \n",
      "Error rate: 0.521334134615\n",
      "Train acc: 0.478665865385\n",
      "Loss: 2.27171\n",
      "epoch 45 \n",
      "Error rate: 0.51702724359\n",
      "Train acc: 0.48297275641\n",
      "Loss: 2.25153\n",
      "epoch 46 \n",
      "Error rate: 0.514523237179\n",
      "Train acc: 0.485476762821\n",
      "Loss: 2.24759\n",
      "epoch 47 \n",
      "Error rate: 0.509314903846\n",
      "Train acc: 0.490685096154\n",
      "Loss: 2.22813\n",
      "epoch 48 \n",
      "Error rate: 0.516326121795\n",
      "Train acc: 0.483673878205\n",
      "Loss: 2.23309\n",
      "epoch 49 \n",
      "Error rate: 0.509014423077\n",
      "Train acc: 0.490985576923\n",
      "Loss: 2.21954\n",
      "epoch 50 \n",
      "Error rate: 0.506209935897\n",
      "Train acc: 0.493790064103\n",
      "Loss: 2.21403\n",
      "epoch 51 \n",
      "Error rate: 0.498998397436\n",
      "Train acc: 0.501001602564\n",
      "Loss: 2.19141\n",
      "epoch 52 \n",
      "Error rate: 0.512520032051\n",
      "Train acc: 0.487479967949\n",
      "Loss: 2.20677\n",
      "epoch 53 \n",
      "Error rate: 0.497696314103\n",
      "Train acc: 0.502303685897\n",
      "Loss: 2.18115\n",
      "epoch 54 \n",
      "Error rate: 0.505008012821\n",
      "Train acc: 0.494991987179\n",
      "Loss: 2.2022\n",
      "epoch 55 \n",
      "Error rate: 0.500500801282\n",
      "Train acc: 0.499499198718\n",
      "Loss: 2.17892\n",
      "epoch 56 \n",
      "Error rate: 0.505108173077\n",
      "Train acc: 0.494891826923\n",
      "Loss: 2.18823\n",
      "epoch 57 \n",
      "Error rate: 0.50250400641\n",
      "Train acc: 0.49749599359\n",
      "Loss: 2.17362\n",
      "epoch 58 \n",
      "Error rate: 0.497095352564\n",
      "Train acc: 0.502904647436\n",
      "Loss: 2.16641\n",
      "epoch 59 \n",
      "Error rate: 0.494491185897\n",
      "Train acc: 0.505508814103\n",
      "Loss: 2.15226\n",
      "epoch 60 \n",
      "Error rate: 0.497796474359\n",
      "Train acc: 0.502203525641\n",
      "Loss: 2.16083\n",
      "epoch 61 \n",
      "Error rate: 0.484775641026\n",
      "Train acc: 0.515224358974\n",
      "Loss: 2.12943\n",
      "epoch 62 \n",
      "Error rate: 0.495793269231\n",
      "Train acc: 0.504206730769\n",
      "Loss: 2.14097\n",
      "epoch 63 \n",
      "Error rate: 0.48968349359\n",
      "Train acc: 0.51031650641\n",
      "Loss: 2.1264\n",
      "epoch 64 \n",
      "Error rate: 0.501602564103\n",
      "Train acc: 0.498397435897\n",
      "Loss: 2.16066\n",
      "epoch 65 \n",
      "Error rate: 0.483673878205\n",
      "Train acc: 0.516326121795\n",
      "Loss: 2.12095\n",
      "epoch 66 \n",
      "Error rate: 0.488080929487\n",
      "Train acc: 0.511919070513\n",
      "Loss: 2.12855\n",
      "epoch 67 \n",
      "Error rate: 0.480969551282\n",
      "Train acc: 0.519030448718\n",
      "Loss: 2.1098\n",
      "epoch 68 \n",
      "Error rate: 0.491185897436\n",
      "Train acc: 0.508814102564\n",
      "Loss: 2.1248\n",
      "epoch 69 \n",
      "Error rate: 0.474158653846\n",
      "Train acc: 0.525841346154\n",
      "Loss: 2.09563\n",
      "epoch 70 \n",
      "Error rate: 0.479166666667\n",
      "Train acc: 0.520833333333\n",
      "Loss: 2.10575\n",
      "epoch 71 \n",
      "Error rate: 0.47906650641\n",
      "Train acc: 0.52093349359\n",
      "Loss: 2.08695\n",
      "epoch 72 \n",
      "Error rate: 0.490184294872\n",
      "Train acc: 0.509815705128\n",
      "Loss: 2.10103\n",
      "epoch 73 \n",
      "Error rate: 0.480168269231\n",
      "Train acc: 0.519831730769\n",
      "Loss: 2.08178\n",
      "epoch 74 \n",
      "Error rate: 0.477363782051\n",
      "Train acc: 0.522636217949\n",
      "Loss: 2.08402\n",
      "epoch 75 \n",
      "Error rate: 0.471454326923\n",
      "Train acc: 0.528545673077\n",
      "Loss: 2.06158\n",
      "epoch 76 \n",
      "Error rate: 0.476362179487\n",
      "Train acc: 0.523637820513\n",
      "Loss: 2.08339\n",
      "epoch 77 \n",
      "Error rate: 0.467548076923\n",
      "Train acc: 0.532451923077\n",
      "Loss: 2.05345\n",
      "epoch 78 \n",
      "Error rate: 0.472155448718\n",
      "Train acc: 0.527844551282\n",
      "Loss: 2.06996\n",
      "epoch 79 \n",
      "Error rate: 0.474559294872\n",
      "Train acc: 0.525440705128\n",
      "Loss: 2.05279\n",
      "epoch 80 \n",
      "Error rate: 0.480368589744\n",
      "Train acc: 0.519631410256\n",
      "Loss: 2.06689\n",
      "epoch 81 \n",
      "Error rate: 0.465845352564\n",
      "Train acc: 0.534154647436\n",
      "Loss: 2.04543\n",
      "epoch 82 \n",
      "Error rate: 0.471354166667\n",
      "Train acc: 0.528645833333\n",
      "Loss: 2.06086\n",
      "epoch 83 \n",
      "Error rate: 0.465044070513\n",
      "Train acc: 0.534955929487\n",
      "Loss: 2.03578\n",
      "epoch 84 \n",
      "Error rate: 0.472956730769\n",
      "Train acc: 0.527043269231\n",
      "Loss: 2.05312\n",
      "epoch 85 \n",
      "Error rate: 0.469851762821\n",
      "Train acc: 0.530148237179\n",
      "Loss: 2.03411\n",
      "epoch 86 \n",
      "Error rate: 0.460136217949\n",
      "Train acc: 0.539863782051\n",
      "Loss: 2.03392\n",
      "epoch 87 \n",
      "Error rate: 0.461638621795\n",
      "Train acc: 0.538361378205\n",
      "Loss: 2.01135\n",
      "epoch 88 \n",
      "Error rate: 0.464943910256\n",
      "Train acc: 0.535056089744\n",
      "Loss: 2.03238\n",
      "epoch 89 \n",
      "Error rate: 0.459334935897\n",
      "Train acc: 0.540665064103\n",
      "Loss: 2.02495\n",
      "epoch 90 \n",
      "Error rate: 0.463040865385\n",
      "Train acc: 0.536959134615\n",
      "Loss: 2.0315\n",
      "epoch 91 \n",
      "Error rate: 0.456630608974\n",
      "Train acc: 0.543369391026\n",
      "Loss: 2.00243\n",
      "epoch 92 \n",
      "Error rate: 0.456530448718\n",
      "Train acc: 0.543469551282\n",
      "Loss: 2.02032\n",
      "epoch 93 \n",
      "Error rate: 0.454727564103\n",
      "Train acc: 0.545272435897\n",
      "Loss: 2.00113\n",
      "epoch 94 \n",
      "Error rate: 0.457732371795\n",
      "Train acc: 0.542267628205\n",
      "Loss: 2.00548\n",
      "epoch 95 \n",
      "Error rate: 0.456730769231\n",
      "Train acc: 0.543269230769\n",
      "Loss: 2.00522\n",
      "epoch 96 \n",
      "Error rate: 0.457932692308\n",
      "Train acc: 0.542067307692\n",
      "Loss: 2.00656\n",
      "epoch 97 \n",
      "Error rate: 0.445813301282\n",
      "Train acc: 0.554186698718\n",
      "Loss: 1.98038\n",
      "epoch 98 \n",
      "Error rate: 0.445512820513\n",
      "Train acc: 0.554487179487\n",
      "Loss: 1.98592\n",
      "epoch 99 \n",
      "Error rate: 0.453225160256\n",
      "Train acc: 0.546774839744\n",
      "Loss: 1.99019\n",
      "epoch 100 \n",
      "Error rate: 0.448016826923\n",
      "Train acc: 0.551983173077\n",
      "Loss: 1.98935\n",
      "epoch 101 \n",
      "Error rate: 0.440304487179\n",
      "Train acc: 0.559695512821\n",
      "Loss: 1.96436\n",
      "epoch 102 \n",
      "Error rate: 0.448617788462\n",
      "Train acc: 0.551382211538\n",
      "Loss: 1.9805\n",
      "epoch 103 \n",
      "Error rate: 0.454727564103\n",
      "Train acc: 0.545272435897\n",
      "Loss: 1.98019\n",
      "epoch 104 \n",
      "Error rate: 0.443609775641\n",
      "Train acc: 0.556390224359\n",
      "Loss: 1.97595\n",
      "epoch 105 \n",
      "Error rate: 0.436798878205\n",
      "Train acc: 0.563201121795\n",
      "Loss: 1.95121\n",
      "epoch 106 \n",
      "Error rate: 0.447015224359\n",
      "Train acc: 0.552984775641\n",
      "Loss: 1.97439\n",
      "epoch 107 \n",
      "Error rate: 0.44000400641\n",
      "Train acc: 0.55999599359\n",
      "Loss: 1.9574\n",
      "epoch 108 \n",
      "Error rate: 0.44000400641\n",
      "Train acc: 0.55999599359\n",
      "Loss: 1.96056\n",
      "epoch 109 \n",
      "Error rate: 0.43499599359\n",
      "Train acc: 0.56500400641\n",
      "Loss: 1.94641\n",
      "epoch 110 \n",
      "Error rate: 0.434595352564\n",
      "Train acc: 0.565404647436\n",
      "Loss: 1.93985\n",
      "epoch 111 \n",
      "Error rate: 0.426382211538\n",
      "Train acc: 0.573617788462\n",
      "Loss: 1.92202\n",
      "epoch 112 \n",
      "Error rate: 0.433693910256\n",
      "Train acc: 0.566306089744\n",
      "Loss: 1.94283\n",
      "epoch 113 \n",
      "Error rate: 0.429186698718\n",
      "Train acc: 0.570813301282\n",
      "Loss: 1.93323\n",
      "epoch 114 \n",
      "Error rate: 0.437099358974\n",
      "Train acc: 0.562900641026\n",
      "Loss: 1.94811\n",
      "epoch 115 \n",
      "Error rate: 0.420673076923\n",
      "Train acc: 0.579326923077\n",
      "Loss: 1.90743\n",
      "epoch 116 \n",
      "Error rate: 0.434895833333\n",
      "Train acc: 0.565104166667\n",
      "Loss: 1.94219\n",
      "epoch 117 \n",
      "Error rate: 0.423377403846\n",
      "Train acc: 0.576622596154\n",
      "Loss: 1.91769\n",
      "epoch 118 \n",
      "Error rate: 0.423177083333\n",
      "Train acc: 0.576822916667\n",
      "Loss: 1.91749\n",
      "epoch 119 \n",
      "Error rate: 0.435296474359\n",
      "Train acc: 0.564703525641\n",
      "Loss: 1.92631\n",
      "epoch 120 \n",
      "Error rate: 0.427483974359\n",
      "Train acc: 0.572516025641\n",
      "Loss: 1.92444\n",
      "epoch 121 \n",
      "Error rate: 0.426081730769\n",
      "Train acc: 0.573918269231\n",
      "Loss: 1.91402\n",
      "epoch 122 \n",
      "Error rate: 0.425981570513\n",
      "Train acc: 0.574018429487\n",
      "Loss: 1.92132\n",
      "epoch 123 \n",
      "Error rate: 0.419270833333\n",
      "Train acc: 0.580729166667\n",
      "Loss: 1.89049\n",
      "epoch 124 \n",
      "Error rate: 0.419671474359\n",
      "Train acc: 0.580328525641\n",
      "Loss: 1.90565\n",
      "epoch 125 \n",
      "Error rate: 0.416165865385\n",
      "Train acc: 0.583834134615\n",
      "Loss: 1.88935\n",
      "epoch 126 \n",
      "Error rate: 0.422676282051\n",
      "Train acc: 0.577323717949\n",
      "Loss: 1.90367\n",
      "epoch 127 \n",
      "Error rate: 0.413862179487\n",
      "Train acc: 0.586137820513\n",
      "Loss: 1.8765\n",
      "epoch 128 \n",
      "Error rate: 0.424579326923\n",
      "Train acc: 0.575420673077\n",
      "Loss: 1.91936\n",
      "epoch 129 \n",
      "Error rate: 0.416967147436\n",
      "Train acc: 0.583032852564\n",
      "Loss: 1.89081\n",
      "epoch 130 \n",
      "Error rate: 0.423076923077\n",
      "Train acc: 0.576923076923\n",
      "Loss: 1.90191\n",
      "epoch 131 \n",
      "Error rate: 0.409354967949\n",
      "Train acc: 0.590645032051\n",
      "Loss: 1.86223\n",
      "epoch 132 \n",
      "Error rate: 0.416165865385\n",
      "Train acc: 0.583834134615\n",
      "Loss: 1.88481\n",
      "epoch 133 \n",
      "Error rate: 0.413461538462\n",
      "Train acc: 0.586538461538\n",
      "Loss: 1.87455\n",
      "epoch 134 \n",
      "Error rate: 0.420973557692\n",
      "Train acc: 0.579026442308\n",
      "Loss: 1.89947\n",
      "epoch 135 \n",
      "Error rate: 0.403445512821\n",
      "Train acc: 0.596554487179\n",
      "Loss: 1.86353\n",
      "epoch 136 \n",
      "Error rate: 0.416165865385\n",
      "Train acc: 0.583834134615\n",
      "Loss: 1.88898\n",
      "epoch 137 \n",
      "Error rate: 0.411858974359\n",
      "Train acc: 0.588141025641\n",
      "Loss: 1.86321\n",
      "epoch 138 \n",
      "Error rate: 0.426582532051\n",
      "Train acc: 0.573417467949\n",
      "Loss: 1.9003\n",
      "epoch 139 \n",
      "Error rate: 0.405749198718\n",
      "Train acc: 0.594250801282\n",
      "Loss: 1.85168\n",
      "epoch 140 \n",
      "Error rate: 0.415564903846\n",
      "Train acc: 0.584435096154\n",
      "Loss: 1.87555\n",
      "epoch 141 \n",
      "Error rate: 0.406850961538\n",
      "Train acc: 0.593149038462\n",
      "Loss: 1.85575\n",
      "epoch 142 \n",
      "Error rate: 0.410556891026\n",
      "Train acc: 0.589443108974\n",
      "Loss: 1.87107\n",
      "epoch 143 \n",
      "Error rate: 0.411157852564\n",
      "Train acc: 0.588842147436\n",
      "Loss: 1.86651\n",
      "epoch 144 \n",
      "Error rate: 0.410556891026\n",
      "Train acc: 0.589443108974\n",
      "Loss: 1.86386\n",
      "epoch 145 \n",
      "Error rate: 0.403846153846\n",
      "Train acc: 0.596153846154\n",
      "Loss: 1.84944\n",
      "epoch 146 \n",
      "Error rate: 0.408653846154\n",
      "Train acc: 0.591346153846\n",
      "Loss: 1.87762\n",
      "epoch 147 \n",
      "Error rate: 0.395633012821\n",
      "Train acc: 0.604366987179\n",
      "Loss: 1.82696\n",
      "epoch 148 \n",
      "Error rate: 0.410657051282\n",
      "Train acc: 0.589342948718\n",
      "Loss: 1.86566\n",
      "epoch 149 \n",
      "Error rate: 0.395232371795\n",
      "Train acc: 0.604767628205\n",
      "Loss: 1.82647\n",
      "epoch 150 \n",
      "Error rate: 0.403946314103\n",
      "Train acc: 0.596053685897\n",
      "Loss: 1.85706\n",
      "epoch 151 \n",
      "Error rate: 0.406450320513\n",
      "Train acc: 0.593549679487\n",
      "Loss: 1.83639\n",
      "epoch 152 \n",
      "Error rate: 0.409555288462\n",
      "Train acc: 0.590444711538\n",
      "Loss: 1.86126\n",
      "epoch 153 \n",
      "Error rate: 0.398938301282\n",
      "Train acc: 0.601061698718\n",
      "Loss: 1.82609\n",
      "epoch 154 \n",
      "Error rate: 0.407151442308\n",
      "Train acc: 0.592848557692\n",
      "Loss: 1.85641\n",
      "epoch 155 \n",
      "Error rate: 0.399238782051\n",
      "Train acc: 0.600761217949\n",
      "Loss: 1.8324\n",
      "epoch 156 \n",
      "Error rate: 0.41155849359\n",
      "Train acc: 0.58844150641\n",
      "Loss: 1.86069\n",
      "epoch 157 \n",
      "Error rate: 0.396734775641\n",
      "Train acc: 0.603265224359\n",
      "Loss: 1.82527\n",
      "epoch 158 \n",
      "Error rate: 0.401342147436\n",
      "Train acc: 0.598657852564\n",
      "Loss: 1.83463\n",
      "epoch 159 \n",
      "Error rate: 0.394731570513\n",
      "Train acc: 0.605268429487\n",
      "Loss: 1.82229\n",
      "epoch 160 \n",
      "Error rate: 0.39983974359\n",
      "Train acc: 0.60016025641\n",
      "Loss: 1.83989\n",
      "epoch 161 \n",
      "Error rate: 0.399338942308\n",
      "Train acc: 0.600661057692\n",
      "Loss: 1.82911\n",
      "epoch 162 \n",
      "Error rate: 0.399639423077\n",
      "Train acc: 0.600360576923\n",
      "Loss: 1.83535\n",
      "epoch 163 \n",
      "Error rate: 0.389623397436\n",
      "Train acc: 0.610376602564\n",
      "Loss: 1.80901\n",
      "epoch 164 \n",
      "Error rate: 0.396734775641\n",
      "Train acc: 0.603265224359\n",
      "Loss: 1.82481\n",
      "epoch 165 \n",
      "Error rate: 0.392127403846\n",
      "Train acc: 0.607872596154\n",
      "Loss: 1.81751\n",
      "epoch 166 \n",
      "Error rate: 0.39202724359\n",
      "Train acc: 0.60797275641\n",
      "Loss: 1.81729\n",
      "epoch 167 \n",
      "Error rate: 0.391326121795\n",
      "Train acc: 0.608673878205\n",
      "Loss: 1.81177\n",
      "epoch 168 \n",
      "Error rate: 0.399439102564\n",
      "Train acc: 0.600560897436\n",
      "Loss: 1.82649\n",
      "epoch 169 \n",
      "Error rate: 0.385216346154\n",
      "Train acc: 0.614783653846\n",
      "Loss: 1.80419\n",
      "epoch 170 \n",
      "Error rate: 0.399038461538\n",
      "Train acc: 0.600961538462\n",
      "Loss: 1.82781\n",
      "epoch 171 \n",
      "Error rate: 0.390524839744\n",
      "Train acc: 0.609475160256\n",
      "Loss: 1.81202\n",
      "epoch 172 \n",
      "Error rate: 0.394230769231\n",
      "Train acc: 0.605769230769\n",
      "Loss: 1.82223\n",
      "epoch 173 \n",
      "Error rate: 0.385616987179\n",
      "Train acc: 0.614383012821\n",
      "Loss: 1.79196\n",
      "epoch 174 \n",
      "Error rate: 0.392227564103\n",
      "Train acc: 0.607772435897\n",
      "Loss: 1.80987\n",
      "epoch 175 \n",
      "Error rate: 0.385016025641\n",
      "Train acc: 0.614983974359\n",
      "Loss: 1.79785\n",
      "epoch 176 \n",
      "Error rate: 0.394230769231\n",
      "Train acc: 0.605769230769\n",
      "Loss: 1.80695\n",
      "epoch 177 \n",
      "Error rate: 0.383613782051\n",
      "Train acc: 0.616386217949\n",
      "Loss: 1.78422\n",
      "epoch 178 \n",
      "Error rate: 0.396834935897\n",
      "Train acc: 0.603165064103\n",
      "Loss: 1.81992\n",
      "epoch 179 \n",
      "Error rate: 0.384615384615\n",
      "Train acc: 0.615384615385\n",
      "Loss: 1.78351\n",
      "epoch 180 \n",
      "Error rate: 0.391125801282\n",
      "Train acc: 0.608874198718\n",
      "Loss: 1.80444\n",
      "epoch 181 \n",
      "Error rate: 0.387119391026\n",
      "Train acc: 0.612880608974\n",
      "Loss: 1.79062\n",
      "epoch 182 \n",
      "Error rate: 0.392528044872\n",
      "Train acc: 0.607471955128\n",
      "Loss: 1.80439\n",
      "epoch 183 \n",
      "Error rate: 0.386217948718\n",
      "Train acc: 0.613782051282\n",
      "Loss: 1.78484\n",
      "epoch 184 \n",
      "Error rate: 0.39593349359\n",
      "Train acc: 0.60406650641\n",
      "Loss: 1.80444\n",
      "epoch 185 \n",
      "Error rate: 0.38922275641\n",
      "Train acc: 0.61077724359\n",
      "Loss: 1.79055\n",
      "epoch 186 \n",
      "Error rate: 0.395232371795\n",
      "Train acc: 0.604767628205\n",
      "Loss: 1.80781\n",
      "epoch 187 \n",
      "Error rate: 0.386518429487\n",
      "Train acc: 0.613481570513\n",
      "Loss: 1.77998\n",
      "epoch 188 \n",
      "Error rate: 0.388221153846\n",
      "Train acc: 0.611778846154\n",
      "Loss: 1.79169\n",
      "epoch 189 \n",
      "Error rate: 0.374799679487\n",
      "Train acc: 0.625200320513\n",
      "Loss: 1.76793\n",
      "epoch 190 \n",
      "Error rate: 0.396434294872\n",
      "Train acc: 0.603565705128\n",
      "Loss: 1.80391\n",
      "epoch 191 \n",
      "Error rate: 0.381610576923\n",
      "Train acc: 0.618389423077\n",
      "Loss: 1.77438\n",
      "epoch 192 \n",
      "Error rate: 0.389022435897\n",
      "Train acc: 0.610977564103\n",
      "Loss: 1.78829\n",
      "epoch 193 \n",
      "Error rate: 0.375\n",
      "Train acc: 0.625\n",
      "Loss: 1.76274\n",
      "epoch 194 \n",
      "Error rate: 0.391726762821\n",
      "Train acc: 0.608273237179\n",
      "Loss: 1.81109\n",
      "epoch 195 \n",
      "Error rate: 0.376802884615\n",
      "Train acc: 0.623197115385\n",
      "Loss: 1.75896\n",
      "epoch 196 \n",
      "Error rate: 0.387520032051\n",
      "Train acc: 0.612479967949\n",
      "Loss: 1.79216\n",
      "epoch 197 \n",
      "Error rate: 0.376201923077\n",
      "Train acc: 0.623798076923\n",
      "Loss: 1.75747\n",
      "epoch 198 \n",
      "Error rate: 0.390224358974\n",
      "Train acc: 0.609775641026\n",
      "Loss: 1.79166\n",
      "epoch 199 \n",
      "Error rate: 0.375300480769\n",
      "Train acc: 0.624699519231\n",
      "Loss: 1.75565\n",
      "epoch 200 \n",
      "Error rate: 0.39312900641\n",
      "Train acc: 0.60687099359\n",
      "Loss: 1.79841\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "deep_3_spatial = CNN_Spectral_Param(num_output=10, kernel_size=3, architecture='deep',\n",
    "                                    use_spectral_params=False)\n",
    "deep_3_spatial.train(xtrain, ytrain, batch_size=128, epochs=200)\n",
    "\n",
    "write_error_rate('deep_3_spatial', deep_3_spatial.error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches for training: 78\n",
      "epoch 1 \n",
      "Error rate: 0.886017628205\n",
      "Train acc: 0.113982371795\n",
      "Loss: 7.62281\n",
      "epoch 2 \n",
      "Error rate: 0.852063301282\n",
      "Train acc: 0.147936698718\n",
      "Loss: 6.97475\n",
      "epoch 3 \n",
      "Error rate: 0.832431891026\n",
      "Train acc: 0.167568108974\n",
      "Loss: 6.86513\n",
      "epoch 4 \n",
      "Error rate: 0.771834935897\n",
      "Train acc: 0.228165064103\n",
      "Loss: 6.7281\n",
      "epoch 5 \n",
      "Error rate: 0.731670673077\n",
      "Train acc: 0.268329326923\n",
      "Loss: 6.59094\n",
      "epoch 6 \n",
      "Error rate: 0.681991185897\n",
      "Train acc: 0.318008814103\n",
      "Loss: 6.36598\n",
      "epoch 7 \n",
      "Error rate: 0.633012820513\n",
      "Train acc: 0.366987179487\n",
      "Loss: 6.13694\n",
      "epoch 8 \n",
      "Error rate: 0.624499198718\n",
      "Train acc: 0.375500801282\n",
      "Loss: 6.02982\n",
      "epoch 9 \n",
      "Error rate: 0.571814903846\n",
      "Train acc: 0.428185096154\n",
      "Loss: 5.86919\n",
      "epoch 10 \n",
      "Error rate: 0.557592147436\n",
      "Train acc: 0.442407852564\n",
      "Loss: 5.76926\n",
      "epoch 11 \n",
      "Error rate: 0.529947916667\n",
      "Train acc: 0.470052083333\n",
      "Loss: 5.65218\n",
      "epoch 12 \n",
      "Error rate: 0.542568108974\n",
      "Train acc: 0.457431891026\n",
      "Loss: 5.62905\n",
      "epoch 13 \n",
      "Error rate: 0.513020833333\n",
      "Train acc: 0.486979166667\n",
      "Loss: 5.50807\n",
      "epoch 14 \n",
      "Error rate: 0.504306891026\n",
      "Train acc: 0.495693108974\n",
      "Loss: 5.46093\n",
      "epoch 15 \n",
      "Error rate: 0.493689903846\n",
      "Train acc: 0.506310096154\n",
      "Loss: 5.3853\n",
      "epoch 16 \n",
      "Error rate: 0.490885416667\n",
      "Train acc: 0.509114583333\n",
      "Loss: 5.34046\n",
      "epoch 17 \n",
      "Error rate: 0.465544871795\n",
      "Train acc: 0.534455128205\n",
      "Loss: 5.24783\n",
      "epoch 18 \n",
      "Error rate: 0.471554487179\n",
      "Train acc: 0.528445512821\n",
      "Loss: 5.23005\n",
      "epoch 19 \n",
      "Error rate: 0.456830929487\n",
      "Train acc: 0.543169070513\n",
      "Loss: 5.16631\n",
      "epoch 20 \n",
      "Error rate: 0.476762820513\n",
      "Train acc: 0.523237179487\n",
      "Loss: 5.15945\n",
      "epoch 21 \n",
      "Error rate: 0.446915064103\n",
      "Train acc: 0.553084935897\n",
      "Loss: 5.07274\n",
      "epoch 22 \n",
      "Error rate: 0.453225160256\n",
      "Train acc: 0.546774839744\n",
      "Loss: 5.06173\n",
      "epoch 23 \n",
      "Error rate: 0.433193108974\n",
      "Train acc: 0.566806891026\n",
      "Loss: 4.98112\n",
      "epoch 24 \n",
      "Error rate: 0.444611378205\n",
      "Train acc: 0.555388621795\n",
      "Loss: 4.989\n",
      "epoch 25 \n",
      "Error rate: 0.42828525641\n",
      "Train acc: 0.57171474359\n",
      "Loss: 4.90704\n",
      "epoch 26 \n",
      "Error rate: 0.429186698718\n",
      "Train acc: 0.570813301282\n",
      "Loss: 4.90067\n",
      "epoch 27 \n",
      "Error rate: 0.415264423077\n",
      "Train acc: 0.584735576923\n",
      "Loss: 4.83299\n",
      "epoch 28 \n",
      "Error rate: 0.429487179487\n",
      "Train acc: 0.570512820513\n",
      "Loss: 4.84743\n",
      "epoch 29 \n",
      "Error rate: 0.39983974359\n",
      "Train acc: 0.60016025641\n",
      "Loss: 4.76435\n",
      "epoch 30 \n",
      "Error rate: 0.417467948718\n",
      "Train acc: 0.582532051282\n",
      "Loss: 4.78844\n",
      "epoch 31 \n",
      "Error rate: 0.392828525641\n",
      "Train acc: 0.607171474359\n",
      "Loss: 4.70071\n",
      "epoch 32 \n",
      "Error rate: 0.409555288462\n",
      "Train acc: 0.590444711538\n",
      "Loss: 4.71766\n",
      "epoch 33 \n",
      "Error rate: 0.384815705128\n",
      "Train acc: 0.615184294872\n",
      "Loss: 4.6444\n",
      "epoch 34 \n",
      "Error rate: 0.406350160256\n",
      "Train acc: 0.593649839744\n",
      "Loss: 4.68718\n",
      "epoch 35 \n",
      "Error rate: 0.397135416667\n",
      "Train acc: 0.602864583333\n",
      "Loss: 4.62965\n",
      "epoch 36 \n",
      "Error rate: 0.398537660256\n",
      "Train acc: 0.601462339744\n",
      "Loss: 4.61584\n",
      "epoch 37 \n",
      "Error rate: 0.383914262821\n",
      "Train acc: 0.616085737179\n",
      "Loss: 4.57434\n",
      "epoch 38 \n",
      "Error rate: 0.391225961538\n",
      "Train acc: 0.608774038462\n",
      "Loss: 4.57739\n",
      "epoch 39 \n",
      "Error rate: 0.372195512821\n",
      "Train acc: 0.627804487179\n",
      "Loss: 4.50955\n",
      "epoch 40 \n",
      "Error rate: 0.383313301282\n",
      "Train acc: 0.616686698718\n",
      "Loss: 4.52467\n",
      "epoch 41 \n",
      "Error rate: 0.368189102564\n",
      "Train acc: 0.631810897436\n",
      "Loss: 4.47299\n",
      "epoch 42 \n",
      "Error rate: 0.37890625\n",
      "Train acc: 0.62109375\n",
      "Loss: 4.48028\n",
      "epoch 43 \n",
      "Error rate: 0.362379807692\n",
      "Train acc: 0.637620192308\n",
      "Loss: 4.42512\n",
      "epoch 44 \n",
      "Error rate: 0.370993589744\n",
      "Train acc: 0.629006410256\n",
      "Loss: 4.44028\n",
      "epoch 45 \n",
      "Error rate: 0.356169871795\n",
      "Train acc: 0.643830128205\n",
      "Loss: 4.38783\n",
      "epoch 46 \n",
      "Error rate: 0.36578525641\n",
      "Train acc: 0.63421474359\n",
      "Loss: 4.40611\n",
      "epoch 47 \n",
      "Error rate: 0.353064903846\n",
      "Train acc: 0.646935096154\n",
      "Loss: 4.35322\n",
      "epoch 48 \n",
      "Error rate: 0.361578525641\n",
      "Train acc: 0.638421474359\n",
      "Loss: 4.36298\n",
      "epoch 49 \n",
      "Error rate: 0.342047275641\n",
      "Train acc: 0.657952724359\n",
      "Loss: 4.30253\n",
      "epoch 50 \n",
      "Error rate: 0.359274839744\n",
      "Train acc: 0.640725160256\n",
      "Loss: 4.33637\n",
      "epoch 51 \n",
      "Error rate: 0.332932692308\n",
      "Train acc: 0.667067307692\n",
      "Loss: 4.26394\n",
      "epoch 52 \n",
      "Error rate: 0.35016025641\n",
      "Train acc: 0.64983974359\n",
      "Loss: 4.29857\n",
      "epoch 53 \n",
      "Error rate: 0.327123397436\n",
      "Train acc: 0.672876602564\n",
      "Loss: 4.23227\n",
      "epoch 54 \n",
      "Error rate: 0.355969551282\n",
      "Train acc: 0.644030448718\n",
      "Loss: 4.29335\n",
      "epoch 55 \n",
      "Error rate: 0.319010416667\n",
      "Train acc: 0.680989583333\n",
      "Loss: 4.19844\n",
      "epoch 56 \n",
      "Error rate: 0.342848557692\n",
      "Train acc: 0.657151442308\n",
      "Loss: 4.23209\n",
      "epoch 57 \n",
      "Error rate: 0.332632211538\n",
      "Train acc: 0.667367788462\n",
      "Loss: 4.20997\n",
      "epoch 58 \n",
      "Error rate: 0.335236378205\n",
      "Train acc: 0.664763621795\n",
      "Loss: 4.19766\n",
      "epoch 59 \n",
      "Error rate: 0.318810096154\n",
      "Train acc: 0.681189903846\n",
      "Loss: 4.14374\n",
      "epoch 60 \n",
      "Error rate: 0.332131410256\n",
      "Train acc: 0.667868589744\n",
      "Loss: 4.1795\n",
      "epoch 61 \n",
      "Error rate: 0.333233173077\n",
      "Train acc: 0.666766826923\n",
      "Loss: 4.16404\n",
      "epoch 62 \n",
      "Error rate: 0.342247596154\n",
      "Train acc: 0.657752403846\n",
      "Loss: 4.18544\n",
      "epoch 63 \n",
      "Error rate: 0.313501602564\n",
      "Train acc: 0.686498397436\n",
      "Loss: 4.09046\n",
      "epoch 64 \n",
      "Error rate: 0.323317307692\n",
      "Train acc: 0.676682692308\n",
      "Loss: 4.11528\n",
      "epoch 65 \n",
      "Error rate: 0.310496794872\n",
      "Train acc: 0.689503205128\n",
      "Loss: 4.07182\n",
      "epoch 66 \n",
      "Error rate: 0.33062900641\n",
      "Train acc: 0.66937099359\n",
      "Loss: 4.12704\n",
      "epoch 67 \n",
      "Error rate: 0.325721153846\n",
      "Train acc: 0.674278846154\n",
      "Loss: 4.09389\n",
      "epoch 68 \n",
      "Error rate: 0.335036057692\n",
      "Train acc: 0.664963942308\n",
      "Loss: 4.10692\n",
      "epoch 69 \n",
      "Error rate: 0.300580929487\n",
      "Train acc: 0.699419070513\n",
      "Loss: 4.02595\n",
      "epoch 70 \n",
      "Error rate: 0.317908653846\n",
      "Train acc: 0.682091346154\n",
      "Loss: 4.05381\n",
      "epoch 71 \n",
      "Error rate: 0.286358173077\n",
      "Train acc: 0.713641826923\n",
      "Loss: 3.98792\n",
      "epoch 72 \n",
      "Error rate: 0.31640625\n",
      "Train acc: 0.68359375\n",
      "Loss: 4.02115\n",
      "epoch 73 \n",
      "Error rate: 0.307491987179\n",
      "Train acc: 0.692508012821\n",
      "Loss: 4.01351\n",
      "epoch 74 \n",
      "Error rate: 0.310596955128\n",
      "Train acc: 0.689403044872\n",
      "Loss: 4.00619\n",
      "epoch 75 \n",
      "Error rate: 0.310797275641\n",
      "Train acc: 0.689202724359\n",
      "Loss: 4.00273\n",
      "epoch 76 \n",
      "Error rate: 0.305588942308\n",
      "Train acc: 0.694411057692\n",
      "Loss: 3.98612\n",
      "epoch 77 \n",
      "Error rate: 0.302984775641\n",
      "Train acc: 0.697015224359\n",
      "Loss: 3.9674\n",
      "epoch 78 \n",
      "Error rate: 0.298177083333\n",
      "Train acc: 0.701822916667\n",
      "Loss: 3.95823\n",
      "epoch 79 \n",
      "Error rate: 0.282151442308\n",
      "Train acc: 0.717848557692\n",
      "Loss: 3.90846\n",
      "epoch 80 \n",
      "Error rate: 0.315304487179\n",
      "Train acc: 0.684695512821\n",
      "Loss: 3.98322\n",
      "epoch 81 \n",
      "Error rate: 0.274138621795\n",
      "Train acc: 0.725861378205\n",
      "Loss: 3.88597\n",
      "epoch 82 \n",
      "Error rate: 0.316005608974\n",
      "Train acc: 0.683994391026\n",
      "Loss: 3.96559\n",
      "epoch 83 \n",
      "Error rate: 0.275340544872\n",
      "Train acc: 0.724659455128\n",
      "Loss: 3.86848\n",
      "epoch 84 \n",
      "Error rate: 0.293369391026\n",
      "Train acc: 0.706630608974\n",
      "Loss: 3.8989\n",
      "epoch 85 \n",
      "Error rate: 0.267427884615\n",
      "Train acc: 0.732572115385\n",
      "Loss: 3.83999\n",
      "epoch 86 \n",
      "Error rate: 0.311498397436\n",
      "Train acc: 0.688501602564\n",
      "Loss: 3.94258\n",
      "epoch 87 \n",
      "Error rate: 0.284855769231\n",
      "Train acc: 0.715144230769\n",
      "Loss: 3.87042\n",
      "epoch 88 \n",
      "Error rate: 0.30218349359\n",
      "Train acc: 0.69781650641\n",
      "Loss: 3.89998\n",
      "epoch 89 \n",
      "Error rate: 0.262820512821\n",
      "Train acc: 0.737179487179\n",
      "Loss: 3.80781\n",
      "epoch 90 \n",
      "Error rate: 0.285957532051\n",
      "Train acc: 0.714042467949\n",
      "Loss: 3.8563\n",
      "epoch 91 \n",
      "Error rate: 0.287159455128\n",
      "Train acc: 0.712840544872\n",
      "Loss: 3.85299\n",
      "epoch 92 \n",
      "Error rate: 0.289563301282\n",
      "Train acc: 0.710436698718\n",
      "Loss: 3.85236\n",
      "epoch 93 \n",
      "Error rate: 0.280548878205\n",
      "Train acc: 0.719451121795\n",
      "Loss: 3.82335\n",
      "epoch 94 \n",
      "Error rate: 0.274238782051\n",
      "Train acc: 0.725761217949\n",
      "Loss: 3.8159\n",
      "epoch 95 \n",
      "Error rate: 0.254306891026\n",
      "Train acc: 0.745693108974\n",
      "Loss: 3.7532\n",
      "epoch 96 \n",
      "Error rate: 0.298778044872\n",
      "Train acc: 0.701221955128\n",
      "Loss: 3.84892\n",
      "epoch 97 \n",
      "Error rate: 0.270733173077\n",
      "Train acc: 0.729266826923\n",
      "Loss: 3.78121\n",
      "epoch 98 \n",
      "Error rate: 0.290264423077\n",
      "Train acc: 0.709735576923\n",
      "Loss: 3.82124\n",
      "epoch 99 \n",
      "Error rate: 0.255108173077\n",
      "Train acc: 0.744891826923\n",
      "Loss: 3.73125\n",
      "epoch 100 \n",
      "Error rate: 0.285556891026\n",
      "Train acc: 0.714443108974\n",
      "Loss: 3.8022\n",
      "epoch 101 \n",
      "Error rate: 0.250200320513\n",
      "Train acc: 0.749799679487\n",
      "Loss: 3.71946\n",
      "epoch 102 \n",
      "Error rate: 0.269030448718\n",
      "Train acc: 0.730969551282\n",
      "Loss: 3.75359\n",
      "epoch 103 \n",
      "Error rate: 0.244791666667\n",
      "Train acc: 0.755208333333\n",
      "Loss: 3.69411\n",
      "epoch 104 \n",
      "Error rate: 0.287560096154\n",
      "Train acc: 0.712439903846\n",
      "Loss: 3.78227\n",
      "epoch 105 \n",
      "Error rate: 0.260016025641\n",
      "Train acc: 0.739983974359\n",
      "Loss: 3.71747\n",
      "epoch 106 \n",
      "Error rate: 0.267127403846\n",
      "Train acc: 0.732872596154\n",
      "Loss: 3.72908\n",
      "epoch 107 \n",
      "Error rate: 0.240284455128\n",
      "Train acc: 0.759715544872\n",
      "Loss: 3.66698\n",
      "epoch 108 \n",
      "Error rate: 0.275240384615\n",
      "Train acc: 0.724759615385\n",
      "Loss: 3.73947\n",
      "epoch 109 \n",
      "Error rate: 0.254106570513\n",
      "Train acc: 0.745893429487\n",
      "Loss: 3.69249\n",
      "epoch 110 \n",
      "Error rate: 0.260917467949\n",
      "Train acc: 0.739082532051\n",
      "Loss: 3.70087\n",
      "epoch 111 \n",
      "Error rate: 0.243289262821\n",
      "Train acc: 0.756710737179\n",
      "Loss: 3.64601\n",
      "epoch 112 \n",
      "Error rate: 0.273337339744\n",
      "Train acc: 0.726662660256\n",
      "Loss: 3.71101\n",
      "epoch 113 \n",
      "Error rate: 0.237079326923\n",
      "Train acc: 0.762920673077\n",
      "Loss: 3.62894\n",
      "epoch 114 \n",
      "Error rate: 0.269831730769\n",
      "Train acc: 0.730168269231\n",
      "Loss: 3.70238\n",
      "epoch 115 \n",
      "Error rate: 0.237379807692\n",
      "Train acc: 0.762620192308\n",
      "Loss: 3.61586\n",
      "epoch 116 \n",
      "Error rate: 0.258914262821\n",
      "Train acc: 0.741085737179\n",
      "Loss: 3.65554\n",
      "epoch 117 \n",
      "Error rate: 0.228866185897\n",
      "Train acc: 0.771133814103\n",
      "Loss: 3.58255\n",
      "epoch 118 \n",
      "Error rate: 0.271033653846\n",
      "Train acc: 0.728966346154\n",
      "Loss: 3.68016\n",
      "epoch 119 \n",
      "Error rate: 0.250901442308\n",
      "Train acc: 0.749098557692\n",
      "Loss: 3.63206\n",
      "epoch 120 \n",
      "Error rate: 0.249899839744\n",
      "Train acc: 0.750100160256\n",
      "Loss: 3.62881\n",
      "epoch 121 \n",
      "Error rate: 0.240284455128\n",
      "Train acc: 0.759715544872\n",
      "Loss: 3.60446\n",
      "epoch 122 \n",
      "Error rate: 0.261518429487\n",
      "Train acc: 0.738481570513\n",
      "Loss: 3.64472\n",
      "epoch 123 \n",
      "Error rate: 0.234375\n",
      "Train acc: 0.765625\n",
      "Loss: 3.58516\n",
      "epoch 124 \n",
      "Error rate: 0.257612179487\n",
      "Train acc: 0.742387820513\n",
      "Loss: 3.63223\n",
      "epoch 125 \n",
      "Error rate: 0.227063301282\n",
      "Train acc: 0.772936698718\n",
      "Loss: 3.55757\n",
      "epoch 126 \n",
      "Error rate: 0.243790064103\n",
      "Train acc: 0.756209935897\n",
      "Loss: 3.586\n",
      "epoch 127 \n",
      "Error rate: 0.231169871795\n",
      "Train acc: 0.768830128205\n",
      "Loss: 3.55615\n",
      "epoch 128 \n",
      "Error rate: 0.247896634615\n",
      "Train acc: 0.752103365385\n",
      "Loss: 3.59579\n",
      "epoch 129 \n",
      "Error rate: 0.22516025641\n",
      "Train acc: 0.77483974359\n",
      "Loss: 3.52866\n",
      "epoch 130 \n",
      "Error rate: 0.249499198718\n",
      "Train acc: 0.750500801282\n",
      "Loss: 3.59096\n",
      "epoch 131 \n",
      "Error rate: 0.210136217949\n",
      "Train acc: 0.789863782051\n",
      "Loss: 3.49573\n",
      "epoch 132 \n",
      "Error rate: 0.250600961538\n",
      "Train acc: 0.749399038462\n",
      "Loss: 3.57496\n",
      "epoch 133 \n",
      "Error rate: 0.23046875\n",
      "Train acc: 0.76953125\n",
      "Loss: 3.52148\n",
      "epoch 134 \n",
      "Error rate: 0.246294070513\n",
      "Train acc: 0.753705929487\n",
      "Loss: 3.56492\n",
      "epoch 135 \n",
      "Error rate: 0.218048878205\n",
      "Train acc: 0.781951121795\n",
      "Loss: 3.4964\n",
      "epoch 136 \n",
      "Error rate: 0.241185897436\n",
      "Train acc: 0.758814102564\n",
      "Loss: 3.53615\n",
      "epoch 137 \n",
      "Error rate: 0.22125400641\n",
      "Train acc: 0.77874599359\n",
      "Loss: 3.49477\n",
      "epoch 138 \n",
      "Error rate: 0.237580128205\n",
      "Train acc: 0.762419871795\n",
      "Loss: 3.52507\n",
      "epoch 139 \n",
      "Error rate: 0.21875\n",
      "Train acc: 0.78125\n",
      "Loss: 3.47854\n",
      "epoch 140 \n",
      "Error rate: 0.244391025641\n",
      "Train acc: 0.755608974359\n",
      "Loss: 3.53376\n",
      "epoch 141 \n",
      "Error rate: 0.22125400641\n",
      "Train acc: 0.77874599359\n",
      "Loss: 3.4778\n",
      "epoch 142 \n",
      "Error rate: 0.233874198718\n",
      "Train acc: 0.766125801282\n",
      "Loss: 3.50495\n",
      "epoch 143 \n",
      "Error rate: 0.218549679487\n",
      "Train acc: 0.781450320513\n",
      "Loss: 3.46036\n",
      "epoch 144 \n",
      "Error rate: 0.234775641026\n",
      "Train acc: 0.765224358974\n",
      "Loss: 3.49754\n",
      "epoch 145 \n",
      "Error rate: 0.208333333333\n",
      "Train acc: 0.791666666667\n",
      "Loss: 3.43834\n",
      "epoch 146 \n",
      "Error rate: 0.231670673077\n",
      "Train acc: 0.768329326923\n",
      "Loss: 3.48411\n",
      "epoch 147 \n",
      "Error rate: 0.203926282051\n",
      "Train acc: 0.796073717949\n",
      "Loss: 3.41146\n",
      "epoch 148 \n",
      "Error rate: 0.237179487179\n",
      "Train acc: 0.762820512821\n",
      "Loss: 3.48775\n",
      "epoch 149 \n",
      "Error rate: 0.212439903846\n",
      "Train acc: 0.787560096154\n",
      "Loss: 3.43022\n",
      "epoch 150 \n",
      "Error rate: 0.228866185897\n",
      "Train acc: 0.771133814103\n",
      "Loss: 3.46365\n",
      "epoch 151 \n",
      "Error rate: 0.195112179487\n",
      "Train acc: 0.804887820513\n",
      "Loss: 3.38474\n",
      "epoch 152 \n",
      "Error rate: 0.223557692308\n",
      "Train acc: 0.776442307692\n",
      "Loss: 3.44562\n",
      "epoch 153 \n",
      "Error rate: 0.215645032051\n",
      "Train acc: 0.784354967949\n",
      "Loss: 3.42595\n",
      "epoch 154 \n",
      "Error rate: 0.230969551282\n",
      "Train acc: 0.769030448718\n",
      "Loss: 3.45766\n",
      "epoch 155 \n",
      "Error rate: 0.191306089744\n",
      "Train acc: 0.808693910256\n",
      "Loss: 3.36868\n",
      "epoch 156 \n",
      "Error rate: 0.223858173077\n",
      "Train acc: 0.776141826923\n",
      "Loss: 3.43748\n",
      "epoch 157 \n",
      "Error rate: 0.192608173077\n",
      "Train acc: 0.807391826923\n",
      "Loss: 3.3607\n",
      "epoch 158 \n",
      "Error rate: 0.226963141026\n",
      "Train acc: 0.773036858974\n",
      "Loss: 3.4347\n",
      "epoch 159 \n",
      "Error rate: 0.202123397436\n",
      "Train acc: 0.797876602564\n",
      "Loss: 3.37288\n",
      "epoch 160 \n",
      "Error rate: 0.217648237179\n",
      "Train acc: 0.782351762821\n",
      "Loss: 3.40865\n",
      "epoch 161 \n",
      "Error rate: 0.187199519231\n",
      "Train acc: 0.812800480769\n",
      "Loss: 3.33653\n",
      "epoch 162 \n",
      "Error rate: 0.210737179487\n",
      "Train acc: 0.789262820513\n",
      "Loss: 3.39106\n",
      "epoch 163 \n",
      "Error rate: 0.177584134615\n",
      "Train acc: 0.822415865385\n",
      "Loss: 3.31143\n",
      "epoch 164 \n",
      "Error rate: 0.206229967949\n",
      "Train acc: 0.793770032051\n",
      "Loss: 3.36592\n",
      "epoch 165 \n",
      "Error rate: 0.204427083333\n",
      "Train acc: 0.795572916667\n",
      "Loss: 3.35654\n",
      "epoch 166 \n",
      "Error rate: 0.207832532051\n",
      "Train acc: 0.792167467949\n",
      "Loss: 3.36994\n",
      "epoch 167 \n",
      "Error rate: 0.20452724359\n",
      "Train acc: 0.79547275641\n",
      "Loss: 3.34853\n",
      "epoch 168 \n",
      "Error rate: 0.207732371795\n",
      "Train acc: 0.792267628205\n",
      "Loss: 3.35403\n",
      "epoch 169 \n",
      "Error rate: 0.19921875\n",
      "Train acc: 0.80078125\n",
      "Loss: 3.33801\n",
      "epoch 170 \n",
      "Error rate: 0.209334935897\n",
      "Train acc: 0.790665064103\n",
      "Loss: 3.35823\n",
      "epoch 171 \n",
      "Error rate: 0.203725961538\n",
      "Train acc: 0.796274038462\n",
      "Loss: 3.3309\n",
      "epoch 172 \n",
      "Error rate: 0.198617788462\n",
      "Train acc: 0.801382211538\n",
      "Loss: 3.33087\n",
      "epoch 173 \n",
      "Error rate: 0.178084935897\n",
      "Train acc: 0.821915064103\n",
      "Loss: 3.27438\n",
      "epoch 174 \n",
      "Error rate: 0.201522435897\n",
      "Train acc: 0.798477564103\n",
      "Loss: 3.32668\n",
      "epoch 175 \n",
      "Error rate: 0.199318910256\n",
      "Train acc: 0.800681089744\n",
      "Loss: 3.31514\n",
      "epoch 176 \n",
      "Error rate: 0.224659455128\n",
      "Train acc: 0.775340544872\n",
      "Loss: 3.36581\n",
      "epoch 177 \n",
      "Error rate: 0.190204326923\n",
      "Train acc: 0.809795673077\n",
      "Loss: 3.29195\n",
      "epoch 178 \n",
      "Error rate: 0.207431891026\n",
      "Train acc: 0.792568108974\n",
      "Loss: 3.33461\n",
      "epoch 179 \n",
      "Error rate: 0.178886217949\n",
      "Train acc: 0.821113782051\n",
      "Loss: 3.26798\n",
      "epoch 180 \n",
      "Error rate: 0.201422275641\n",
      "Train acc: 0.798577724359\n",
      "Loss: 3.30758\n",
      "epoch 181 \n",
      "Error rate: 0.176282051282\n",
      "Train acc: 0.823717948718\n",
      "Loss: 3.251\n",
      "epoch 182 \n",
      "Error rate: 0.194811698718\n",
      "Train acc: 0.805188301282\n",
      "Loss: 3.28911\n",
      "epoch 183 \n",
      "Error rate: 0.182091346154\n",
      "Train acc: 0.817908653846\n",
      "Loss: 3.26135\n",
      "epoch 184 \n",
      "Error rate: 0.205729166667\n",
      "Train acc: 0.794270833333\n",
      "Loss: 3.30375\n",
      "epoch 185 \n",
      "Error rate: 0.173778044872\n",
      "Train acc: 0.826221955128\n",
      "Loss: 3.23793\n",
      "epoch 186 \n",
      "Error rate: 0.19140625\n",
      "Train acc: 0.80859375\n",
      "Loss: 3.2731\n",
      "epoch 187 \n",
      "Error rate: 0.171274038462\n",
      "Train acc: 0.828725961538\n",
      "Loss: 3.21816\n",
      "epoch 188 \n",
      "Error rate: 0.206229967949\n",
      "Train acc: 0.793770032051\n",
      "Loss: 3.29714\n",
      "epoch 189 \n",
      "Error rate: 0.189603365385\n",
      "Train acc: 0.810396634615\n",
      "Loss: 3.24727\n",
      "epoch 190 \n",
      "Error rate: 0.194711538462\n",
      "Train acc: 0.805288461538\n",
      "Loss: 3.26772\n",
      "epoch 191 \n",
      "Error rate: 0.175180288462\n",
      "Train acc: 0.824819711538\n",
      "Loss: 3.22089\n",
      "epoch 192 \n",
      "Error rate: 0.19391025641\n",
      "Train acc: 0.80608974359\n",
      "Loss: 3.26079\n",
      "epoch 193 \n",
      "Error rate: 0.16937099359\n",
      "Train acc: 0.83062900641\n",
      "Loss: 3.20561\n",
      "epoch 194 \n",
      "Error rate: 0.192708333333\n",
      "Train acc: 0.807291666667\n",
      "Loss: 3.24677\n",
      "epoch 195 \n",
      "Error rate: 0.178786057692\n",
      "Train acc: 0.821213942308\n",
      "Loss: 3.21103\n",
      "epoch 196 \n",
      "Error rate: 0.189302884615\n",
      "Train acc: 0.810697115385\n",
      "Loss: 3.23776\n",
      "epoch 197 \n",
      "Error rate: 0.155148237179\n",
      "Train acc: 0.844851762821\n",
      "Loss: 3.16741\n",
      "epoch 198 \n",
      "Error rate: 0.202223557692\n",
      "Train acc: 0.797776442308\n",
      "Loss: 3.27087\n",
      "epoch 199 \n",
      "Error rate: 0.166766826923\n",
      "Train acc: 0.833233173077\n",
      "Loss: 3.17944\n",
      "epoch 200 \n",
      "Error rate: 0.189503205128\n",
      "Train acc: 0.810496794872\n",
      "Loss: 3.23577\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "deep_3_spectral = CNN_Spectral_Param(num_output=10, kernel_size=3, architecture='deep',\n",
    "                                     use_spectral_params=True)\n",
    "deep_3_spectral.train(xtrain, ytrain, batch_size=128, epochs=200)\n",
    "\n",
    "write_error_rate('deep_3_spectral', deep_3_spectral.error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches for training: 78\n",
      "epoch 1 \n",
      "Error rate: 0.814603365385\n",
      "Train acc: 0.185396634615\n",
      "Loss: 2.29736\n",
      "epoch 2 \n",
      "Error rate: 0.713641826923\n",
      "Train acc: 0.286358173077\n",
      "Loss: 2.03314\n",
      "epoch 3 \n",
      "Error rate: 0.665665064103\n",
      "Train acc: 0.334334935897\n",
      "Loss: 1.90106\n",
      "epoch 4 \n",
      "Error rate: 0.642528044872\n",
      "Train acc: 0.357471955128\n",
      "Loss: 1.85707\n",
      "epoch 5 \n",
      "Error rate: 0.610376602564\n",
      "Train acc: 0.389623397436\n",
      "Loss: 1.78645\n",
      "epoch 6 \n",
      "Error rate: 0.600861378205\n",
      "Train acc: 0.399138621795\n",
      "Loss: 1.76559\n",
      "epoch 7 \n",
      "Error rate: 0.574519230769\n",
      "Train acc: 0.425480769231\n",
      "Loss: 1.70132\n",
      "epoch 8 \n",
      "Error rate: 0.565204326923\n",
      "Train acc: 0.434795673077\n",
      "Loss: 1.67783\n",
      "epoch 9 \n",
      "Error rate: 0.538161057692\n",
      "Train acc: 0.461838942308\n",
      "Loss: 1.60769\n",
      "epoch 10 \n",
      "Error rate: 0.529947916667\n",
      "Train acc: 0.470052083333\n",
      "Loss: 1.59591\n",
      "epoch 11 \n",
      "Error rate: 0.502103365385\n",
      "Train acc: 0.497896634615\n",
      "Loss: 1.52552\n",
      "epoch 12 \n",
      "Error rate: 0.500300480769\n",
      "Train acc: 0.499699519231\n",
      "Loss: 1.51296\n",
      "epoch 13 \n",
      "Error rate: 0.475460737179\n",
      "Train acc: 0.524539262821\n",
      "Loss: 1.45152\n",
      "epoch 14 \n",
      "Error rate: 0.474659455128\n",
      "Train acc: 0.525340544872\n",
      "Loss: 1.45418\n",
      "epoch 15 \n",
      "Error rate: 0.453325320513\n",
      "Train acc: 0.546674679487\n",
      "Loss: 1.39239\n",
      "epoch 16 \n",
      "Error rate: 0.440104166667\n",
      "Train acc: 0.559895833333\n",
      "Loss: 1.3756\n",
      "epoch 17 \n",
      "Error rate: 0.431790865385\n",
      "Train acc: 0.568209134615\n",
      "Loss: 1.33839\n",
      "epoch 18 \n",
      "Error rate: 0.434194711538\n",
      "Train acc: 0.565805288462\n",
      "Loss: 1.35375\n",
      "epoch 19 \n",
      "Error rate: 0.410757211538\n",
      "Train acc: 0.589242788462\n",
      "Loss: 1.29799\n",
      "epoch 20 \n",
      "Error rate: 0.412259615385\n",
      "Train acc: 0.587740384615\n",
      "Loss: 1.2971\n",
      "epoch 21 \n",
      "Error rate: 0.411758814103\n",
      "Train acc: 0.588241185897\n",
      "Loss: 1.29482\n",
      "epoch 22 \n",
      "Error rate: 0.401742788462\n",
      "Train acc: 0.598257211538\n",
      "Loss: 1.27241\n",
      "epoch 23 \n",
      "Error rate: 0.394230769231\n",
      "Train acc: 0.605769230769\n",
      "Loss: 1.23023\n",
      "epoch 24 \n",
      "Error rate: 0.394631410256\n",
      "Train acc: 0.605368589744\n",
      "Loss: 1.23591\n",
      "epoch 25 \n",
      "Error rate: 0.381009615385\n",
      "Train acc: 0.618990384615\n",
      "Loss: 1.2049\n",
      "epoch 26 \n",
      "Error rate: 0.389122596154\n",
      "Train acc: 0.610877403846\n",
      "Loss: 1.21974\n",
      "epoch 27 \n",
      "Error rate: 0.366987179487\n",
      "Train acc: 0.633012820513\n",
      "Loss: 1.16584\n",
      "epoch 28 \n",
      "Error rate: 0.371294070513\n",
      "Train acc: 0.628705929487\n",
      "Loss: 1.18623\n",
      "epoch 29 \n",
      "Error rate: 0.359575320513\n",
      "Train acc: 0.640424679487\n",
      "Loss: 1.1482\n",
      "epoch 30 \n",
      "Error rate: 0.366586538462\n",
      "Train acc: 0.633413461538\n",
      "Loss: 1.16924\n",
      "epoch 31 \n",
      "Error rate: 0.351662660256\n",
      "Train acc: 0.648337339744\n",
      "Loss: 1.12301\n",
      "epoch 32 \n",
      "Error rate: 0.352864583333\n",
      "Train acc: 0.647135416667\n",
      "Loss: 1.13352\n",
      "epoch 33 \n",
      "Error rate: 0.340044070513\n",
      "Train acc: 0.659955929487\n",
      "Loss: 1.1004\n",
      "epoch 34 \n",
      "Error rate: 0.354166666667\n",
      "Train acc: 0.645833333333\n",
      "Loss: 1.1342\n",
      "epoch 35 \n",
      "Error rate: 0.337139423077\n",
      "Train acc: 0.662860576923\n",
      "Loss: 1.09828\n",
      "epoch 36 \n",
      "Error rate: 0.337139423077\n",
      "Train acc: 0.662860576923\n",
      "Loss: 1.10082\n",
      "epoch 37 \n",
      "Error rate: 0.321814903846\n",
      "Train acc: 0.678185096154\n",
      "Loss: 1.04612\n",
      "epoch 38 \n",
      "Error rate: 0.336939102564\n",
      "Train acc: 0.663060897436\n",
      "Loss: 1.09838\n",
      "epoch 39 \n",
      "Error rate: 0.316306089744\n",
      "Train acc: 0.683693910256\n",
      "Loss: 1.0408\n",
      "epoch 40 \n",
      "Error rate: 0.319811698718\n",
      "Train acc: 0.680188301282\n",
      "Loss: 1.05142\n",
      "epoch 41 \n",
      "Error rate: 0.312800480769\n",
      "Train acc: 0.687199519231\n",
      "Loss: 1.02983\n",
      "epoch 42 \n",
      "Error rate: 0.311197916667\n",
      "Train acc: 0.688802083333\n",
      "Loss: 1.02869\n",
      "epoch 43 \n",
      "Error rate: 0.316105769231\n",
      "Train acc: 0.683894230769\n",
      "Loss: 1.03028\n",
      "epoch 44 \n",
      "Error rate: 0.308994391026\n",
      "Train acc: 0.691005608974\n",
      "Loss: 1.01788\n",
      "epoch 45 \n",
      "Error rate: 0.304086538462\n",
      "Train acc: 0.695913461538\n",
      "Loss: 1.00738\n",
      "epoch 46 \n",
      "Error rate: 0.315905448718\n",
      "Train acc: 0.684094551282\n",
      "Loss: 1.02594\n",
      "epoch 47 \n",
      "Error rate: 0.288561698718\n",
      "Train acc: 0.711438301282\n",
      "Loss: 0.959899\n",
      "epoch 48 \n",
      "Error rate: 0.299579326923\n",
      "Train acc: 0.700420673077\n",
      "Loss: 0.985159\n",
      "epoch 49 \n",
      "Error rate: 0.283153044872\n",
      "Train acc: 0.716846955128\n",
      "Loss: 0.943549\n",
      "epoch 50 \n",
      "Error rate: 0.302283653846\n",
      "Train acc: 0.697716346154\n",
      "Loss: 0.995214\n",
      "epoch 51 \n",
      "Error rate: 0.287860576923\n",
      "Train acc: 0.712139423077\n",
      "Loss: 0.956201\n",
      "epoch 52 \n",
      "Error rate: 0.281450320513\n",
      "Train acc: 0.718549679487\n",
      "Loss: 0.957445\n",
      "epoch 53 \n",
      "Error rate: 0.281750801282\n",
      "Train acc: 0.718249198718\n",
      "Loss: 0.92706\n",
      "epoch 54 \n",
      "Error rate: 0.287860576923\n",
      "Train acc: 0.712139423077\n",
      "Loss: 0.955125\n",
      "epoch 55 \n",
      "Error rate: 0.26422275641\n",
      "Train acc: 0.73577724359\n",
      "Loss: 0.900443\n",
      "epoch 56 \n",
      "Error rate: 0.277744391026\n",
      "Train acc: 0.722255608974\n",
      "Loss: 0.928112\n",
      "epoch 57 \n",
      "Error rate: 0.266326121795\n",
      "Train acc: 0.733673878205\n",
      "Loss: 0.901989\n",
      "epoch 58 \n",
      "Error rate: 0.277744391026\n",
      "Train acc: 0.722255608974\n",
      "Loss: 0.929607\n",
      "epoch 59 \n",
      "Error rate: 0.253205128205\n",
      "Train acc: 0.746794871795\n",
      "Loss: 0.864037\n",
      "epoch 60 \n",
      "Error rate: 0.259715544872\n",
      "Train acc: 0.740284455128\n",
      "Loss: 0.893542\n",
      "epoch 61 \n",
      "Error rate: 0.253405448718\n",
      "Train acc: 0.746594551282\n",
      "Loss: 0.872407\n",
      "epoch 62 \n",
      "Error rate: 0.267227564103\n",
      "Train acc: 0.732772435897\n",
      "Loss: 0.910504\n",
      "epoch 63 \n",
      "Error rate: 0.249799679487\n",
      "Train acc: 0.750200320513\n",
      "Loss: 0.857385\n",
      "epoch 64 \n",
      "Error rate: 0.258012820513\n",
      "Train acc: 0.741987179487\n",
      "Loss: 0.870917\n",
      "epoch 65 \n",
      "Error rate: 0.239583333333\n",
      "Train acc: 0.760416666667\n",
      "Loss: 0.831864\n",
      "epoch 66 \n",
      "Error rate: 0.25\n",
      "Train acc: 0.75\n",
      "Loss: 0.861469\n",
      "epoch 67 \n",
      "Error rate: 0.239783653846\n",
      "Train acc: 0.760216346154\n",
      "Loss: 0.818469\n",
      "epoch 68 \n",
      "Error rate: 0.246594551282\n",
      "Train acc: 0.753405448718\n",
      "Loss: 0.839901\n",
      "epoch 69 \n",
      "Error rate: 0.238181089744\n",
      "Train acc: 0.761818910256\n",
      "Loss: 0.807743\n",
      "epoch 70 \n",
      "Error rate: 0.247395833333\n",
      "Train acc: 0.752604166667\n",
      "Loss: 0.833297\n",
      "epoch 71 \n",
      "Error rate: 0.229166666667\n",
      "Train acc: 0.770833333333\n",
      "Loss: 0.790311\n",
      "epoch 72 \n",
      "Error rate: 0.241486378205\n",
      "Train acc: 0.758513621795\n",
      "Loss: 0.822925\n",
      "epoch 73 \n",
      "Error rate: 0.219751602564\n",
      "Train acc: 0.780248397436\n",
      "Loss: 0.760595\n",
      "epoch 74 \n",
      "Error rate: 0.233673878205\n",
      "Train acc: 0.766326121795\n",
      "Loss: 0.810591\n",
      "epoch 75 \n",
      "Error rate: 0.21624599359\n",
      "Train acc: 0.78375400641\n",
      "Loss: 0.754045\n",
      "epoch 76 \n",
      "Error rate: 0.218549679487\n",
      "Train acc: 0.781450320513\n",
      "Loss: 0.767368\n",
      "epoch 77 \n",
      "Error rate: 0.20562900641\n",
      "Train acc: 0.79437099359\n",
      "Loss: 0.728978\n",
      "epoch 78 \n",
      "Error rate: 0.229667467949\n",
      "Train acc: 0.770332532051\n",
      "Loss: 0.786222\n",
      "epoch 79 \n",
      "Error rate: 0.206730769231\n",
      "Train acc: 0.793269230769\n",
      "Loss: 0.727175\n",
      "epoch 80 \n",
      "Error rate: 0.221454326923\n",
      "Train acc: 0.778545673077\n",
      "Loss: 0.76015\n",
      "epoch 81 \n",
      "Error rate: 0.204126602564\n",
      "Train acc: 0.795873397436\n",
      "Loss: 0.726819\n",
      "epoch 82 \n",
      "Error rate: 0.214142628205\n",
      "Train acc: 0.785857371795\n",
      "Loss: 0.754591\n",
      "epoch 83 \n",
      "Error rate: 0.191806891026\n",
      "Train acc: 0.808193108974\n",
      "Loss: 0.693234\n",
      "epoch 84 \n",
      "Error rate: 0.210737179487\n",
      "Train acc: 0.789262820513\n",
      "Loss: 0.738289\n",
      "epoch 85 \n",
      "Error rate: 0.191306089744\n",
      "Train acc: 0.808693910256\n",
      "Loss: 0.692776\n",
      "epoch 86 \n",
      "Error rate: 0.200520833333\n",
      "Train acc: 0.799479166667\n",
      "Loss: 0.71334\n",
      "epoch 87 \n",
      "Error rate: 0.183493589744\n",
      "Train acc: 0.816506410256\n",
      "Loss: 0.683529\n",
      "epoch 88 \n",
      "Error rate: 0.198617788462\n",
      "Train acc: 0.801382211538\n",
      "Loss: 0.707834\n",
      "epoch 89 \n",
      "Error rate: 0.177984775641\n",
      "Train acc: 0.822015224359\n",
      "Loss: 0.659738\n",
      "epoch 90 \n",
      "Error rate: 0.195913461538\n",
      "Train acc: 0.804086538462\n",
      "Loss: 0.708375\n",
      "epoch 91 \n",
      "Error rate: 0.180588942308\n",
      "Train acc: 0.819411057692\n",
      "Loss: 0.659185\n",
      "epoch 92 \n",
      "Error rate: 0.196514423077\n",
      "Train acc: 0.803485576923\n",
      "Loss: 0.693941\n",
      "epoch 93 \n",
      "Error rate: 0.17578125\n",
      "Train acc: 0.82421875\n",
      "Loss: 0.643974\n",
      "epoch 94 \n",
      "Error rate: 0.18108974359\n",
      "Train acc: 0.81891025641\n",
      "Loss: 0.672609\n",
      "epoch 95 \n",
      "Error rate: 0.162560096154\n",
      "Train acc: 0.837439903846\n",
      "Loss: 0.610715\n",
      "epoch 96 \n",
      "Error rate: 0.188601762821\n",
      "Train acc: 0.811398237179\n",
      "Loss: 0.682448\n",
      "epoch 97 \n",
      "Error rate: 0.166666666667\n",
      "Train acc: 0.833333333333\n",
      "Loss: 0.623634\n",
      "epoch 98 \n",
      "Error rate: 0.175280448718\n",
      "Train acc: 0.824719551282\n",
      "Loss: 0.646699\n",
      "epoch 99 \n",
      "Error rate: 0.159254807692\n",
      "Train acc: 0.840745192308\n",
      "Loss: 0.596433\n",
      "epoch 100 \n",
      "Error rate: 0.176482371795\n",
      "Train acc: 0.823517628205\n",
      "Loss: 0.642345\n",
      "epoch 101 \n",
      "Error rate: 0.155949519231\n",
      "Train acc: 0.844050480769\n",
      "Loss: 0.583883\n",
      "epoch 102 \n",
      "Error rate: 0.170172275641\n",
      "Train acc: 0.829827724359\n",
      "Loss: 0.639077\n",
      "epoch 103 \n",
      "Error rate: 0.147235576923\n",
      "Train acc: 0.852764423077\n",
      "Loss: 0.570482\n",
      "epoch 104 \n",
      "Error rate: 0.161358173077\n",
      "Train acc: 0.838641826923\n",
      "Loss: 0.6001\n",
      "epoch 105 \n",
      "Error rate: 0.152844551282\n",
      "Train acc: 0.847155448718\n",
      "Loss: 0.580214\n",
      "epoch 106 \n",
      "Error rate: 0.163060897436\n",
      "Train acc: 0.836939102564\n",
      "Loss: 0.60955\n",
      "epoch 107 \n",
      "Error rate: 0.148938301282\n",
      "Train acc: 0.851061698718\n",
      "Loss: 0.56431\n",
      "epoch 108 \n",
      "Error rate: 0.161057692308\n",
      "Train acc: 0.838942307692\n",
      "Loss: 0.595206\n",
      "epoch 109 \n",
      "Error rate: 0.13922275641\n",
      "Train acc: 0.86077724359\n",
      "Loss: 0.546874\n",
      "epoch 110 \n",
      "Error rate: 0.151141826923\n",
      "Train acc: 0.848858173077\n",
      "Loss: 0.575939\n",
      "epoch 111 \n",
      "Error rate: 0.140024038462\n",
      "Train acc: 0.859975961538\n",
      "Loss: 0.549705\n",
      "epoch 112 \n",
      "Error rate: 0.151842948718\n",
      "Train acc: 0.848157051282\n",
      "Loss: 0.574792\n",
      "epoch 113 \n",
      "Error rate: 0.132712339744\n",
      "Train acc: 0.867287660256\n",
      "Loss: 0.52593\n",
      "epoch 114 \n",
      "Error rate: 0.143830128205\n",
      "Train acc: 0.856169871795\n",
      "Loss: 0.556754\n",
      "epoch 115 \n",
      "Error rate: 0.129707532051\n",
      "Train acc: 0.870292467949\n",
      "Loss: 0.520086\n",
      "epoch 116 \n",
      "Error rate: 0.137920673077\n",
      "Train acc: 0.862079326923\n",
      "Loss: 0.545119\n",
      "epoch 117 \n",
      "Error rate: 0.12359775641\n",
      "Train acc: 0.87640224359\n",
      "Loss: 0.502288\n",
      "epoch 118 \n",
      "Error rate: 0.128104967949\n",
      "Train acc: 0.871895032051\n",
      "Loss: 0.517035\n",
      "epoch 119 \n",
      "Error rate: 0.125500801282\n",
      "Train acc: 0.874499198718\n",
      "Loss: 0.508675\n",
      "epoch 120 \n",
      "Error rate: 0.129407051282\n",
      "Train acc: 0.870592948718\n",
      "Loss: 0.523528\n",
      "epoch 121 \n",
      "Error rate: 0.10687099359\n",
      "Train acc: 0.89312900641\n",
      "Loss: 0.457503\n",
      "epoch 122 \n",
      "Error rate: 0.146935096154\n",
      "Train acc: 0.853064903846\n",
      "Loss: 0.563142\n",
      "epoch 123 \n",
      "Error rate: 0.110176282051\n",
      "Train acc: 0.889823717949\n",
      "Loss: 0.470556\n",
      "epoch 124 \n",
      "Error rate: 0.132411858974\n",
      "Train acc: 0.867588141026\n",
      "Loss: 0.524283\n",
      "epoch 125 \n",
      "Error rate: 0.102664262821\n",
      "Train acc: 0.897335737179\n",
      "Loss: 0.444769\n",
      "epoch 126 \n",
      "Error rate: 0.12359775641\n",
      "Train acc: 0.87640224359\n",
      "Loss: 0.49194\n",
      "epoch 127 \n",
      "Error rate: 0.101061698718\n",
      "Train acc: 0.898938301282\n",
      "Loss: 0.437607\n",
      "epoch 128 \n",
      "Error rate: 0.109174679487\n",
      "Train acc: 0.890825320513\n",
      "Loss: 0.463836\n",
      "epoch 129 \n",
      "Error rate: 0.118890224359\n",
      "Train acc: 0.881109775641\n",
      "Loss: 0.483493\n",
      "epoch 130 \n",
      "Error rate: 0.125500801282\n",
      "Train acc: 0.874499198718\n",
      "Loss: 0.505292\n",
      "epoch 131 \n",
      "Error rate: 0.100360576923\n",
      "Train acc: 0.899639423077\n",
      "Loss: 0.445505\n",
      "epoch 132 \n",
      "Error rate: 0.118489583333\n",
      "Train acc: 0.881510416667\n",
      "Loss: 0.483919\n",
      "epoch 133 \n",
      "Error rate: 0.0909455128205\n",
      "Train acc: 0.909054487179\n",
      "Loss: 0.410102\n",
      "epoch 134 \n",
      "Error rate: 0.106570512821\n",
      "Train acc: 0.893429487179\n",
      "Loss: 0.449279\n",
      "epoch 135 \n",
      "Error rate: 0.0806290064103\n",
      "Train acc: 0.91937099359\n",
      "Loss: 0.393514\n",
      "epoch 136 \n",
      "Error rate: 0.110677083333\n",
      "Train acc: 0.889322916667\n",
      "Loss: 0.453159\n",
      "epoch 137 \n",
      "Error rate: 0.0836338141026\n",
      "Train acc: 0.916366185897\n",
      "Loss: 0.396115\n",
      "epoch 138 \n",
      "Error rate: 0.0921474358974\n",
      "Train acc: 0.907852564103\n",
      "Loss: 0.418153\n",
      "epoch 139 \n",
      "Error rate: 0.0749198717949\n",
      "Train acc: 0.925080128205\n",
      "Loss: 0.381443\n",
      "epoch 140 \n",
      "Error rate: 0.0956530448718\n",
      "Train acc: 0.904346955128\n",
      "Loss: 0.42163\n",
      "epoch 141 \n",
      "Error rate: 0.0760216346154\n",
      "Train acc: 0.923978365385\n",
      "Loss: 0.369977\n",
      "epoch 142 \n",
      "Error rate: 0.116185897436\n",
      "Train acc: 0.883814102564\n",
      "Loss: 0.469472\n",
      "epoch 143 \n",
      "Error rate: 0.0730168269231\n",
      "Train acc: 0.926983173077\n",
      "Loss: 0.361463\n",
      "epoch 144 \n",
      "Error rate: 0.0905448717949\n",
      "Train acc: 0.909455128205\n",
      "Loss: 0.405523\n",
      "epoch 145 \n",
      "Error rate: 0.0638020833333\n",
      "Train acc: 0.936197916667\n",
      "Loss: 0.337271\n",
      "epoch 146 \n",
      "Error rate: 0.0849358974359\n",
      "Train acc: 0.915064102564\n",
      "Loss: 0.399008\n",
      "epoch 147 \n",
      "Error rate: 0.0922475961538\n",
      "Train acc: 0.907752403846\n",
      "Loss: 0.410064\n",
      "epoch 148 \n",
      "Error rate: 0.102163461538\n",
      "Train acc: 0.897836538462\n",
      "Loss: 0.428473\n",
      "epoch 149 \n",
      "Error rate: 0.0578926282051\n",
      "Train acc: 0.942107371795\n",
      "Loss: 0.328492\n",
      "epoch 150 \n",
      "Error rate: 0.0728165064103\n",
      "Train acc: 0.92718349359\n",
      "Loss: 0.361377\n",
      "epoch 151 \n",
      "Error rate: 0.0812299679487\n",
      "Train acc: 0.918770032051\n",
      "Loss: 0.383598\n",
      "epoch 152 \n",
      "Error rate: 0.0753205128205\n",
      "Train acc: 0.924679487179\n",
      "Loss: 0.364779\n",
      "epoch 153 \n",
      "Error rate: 0.052984775641\n",
      "Train acc: 0.947015224359\n",
      "Loss: 0.312026\n",
      "epoch 154 \n",
      "Error rate: 0.0987580128205\n",
      "Train acc: 0.901241987179\n",
      "Loss: 0.41599\n",
      "epoch 155 \n",
      "Error rate: 0.0544871794872\n",
      "Train acc: 0.945512820513\n",
      "Loss: 0.312535\n",
      "epoch 156 \n",
      "Error rate: 0.0921474358974\n",
      "Train acc: 0.907852564103\n",
      "Loss: 0.406535\n",
      "epoch 157 \n",
      "Error rate: 0.06640625\n",
      "Train acc: 0.93359375\n",
      "Loss: 0.337694\n",
      "epoch 158 \n",
      "Error rate: 0.0706129807692\n",
      "Train acc: 0.929387019231\n",
      "Loss: 0.356775\n",
      "epoch 159 \n",
      "Error rate: 0.0656049679487\n",
      "Train acc: 0.934395032051\n",
      "Loss: 0.334193\n",
      "epoch 160 \n",
      "Error rate: 0.0865384615385\n",
      "Train acc: 0.913461538462\n",
      "Loss: 0.38967\n",
      "epoch 161 \n",
      "Error rate: 0.0606971153846\n",
      "Train acc: 0.939302884615\n",
      "Loss: 0.33119\n",
      "epoch 162 \n",
      "Error rate: 0.068108974359\n",
      "Train acc: 0.931891025641\n",
      "Loss: 0.343493\n",
      "epoch 163 \n",
      "Error rate: 0.0460737179487\n",
      "Train acc: 0.953926282051\n",
      "Loss: 0.29264\n",
      "epoch 164 \n",
      "Error rate: 0.0666065705128\n",
      "Train acc: 0.933393429487\n",
      "Loss: 0.333406\n",
      "epoch 165 \n",
      "Error rate: 0.0533854166667\n",
      "Train acc: 0.946614583333\n",
      "Loss: 0.309821\n",
      "epoch 166 \n",
      "Error rate: 0.0692107371795\n",
      "Train acc: 0.930789262821\n",
      "Loss: 0.348777\n",
      "epoch 167 \n",
      "Error rate: 0.0397636217949\n",
      "Train acc: 0.960236378205\n",
      "Loss: 0.268495\n",
      "epoch 168 \n",
      "Error rate: 0.0552884615385\n",
      "Train acc: 0.944711538462\n",
      "Loss: 0.307089\n",
      "epoch 169 \n",
      "Error rate: 0.05859375\n",
      "Train acc: 0.94140625\n",
      "Loss: 0.306468\n",
      "epoch 170 \n",
      "Error rate: 0.0572916666667\n",
      "Train acc: 0.942708333333\n",
      "Loss: 0.312061\n",
      "epoch 171 \n",
      "Error rate: 0.0461738782051\n",
      "Train acc: 0.953826121795\n",
      "Loss: 0.281459\n",
      "epoch 172 \n",
      "Error rate: 0.0474759615385\n",
      "Train acc: 0.952524038462\n",
      "Loss: 0.292618\n",
      "epoch 173 \n",
      "Error rate: 0.0261418269231\n",
      "Train acc: 0.973858173077\n",
      "Loss: 0.239638\n",
      "epoch 174 \n",
      "Error rate: 0.0486778846154\n",
      "Train acc: 0.951322115385\n",
      "Loss: 0.286691\n",
      "epoch 175 \n",
      "Error rate: 0.0262419871795\n",
      "Train acc: 0.973758012821\n",
      "Loss: 0.236944\n",
      "epoch 176 \n",
      "Error rate: 0.0875400641026\n",
      "Train acc: 0.912459935897\n",
      "Loss: 0.386675\n",
      "epoch 177 \n",
      "Error rate: 0.029547275641\n",
      "Train acc: 0.970452724359\n",
      "Loss: 0.244739\n",
      "epoch 178 \n",
      "Error rate: 0.0356570512821\n",
      "Train acc: 0.964342948718\n",
      "Loss: 0.259621\n",
      "epoch 179 \n",
      "Error rate: 0.0191306089744\n",
      "Train acc: 0.980869391026\n",
      "Loss: 0.21707\n",
      "epoch 180 \n",
      "Error rate: 0.0531850961538\n",
      "Train acc: 0.946814903846\n",
      "Loss: 0.297895\n",
      "epoch 181 \n",
      "Error rate: 0.0531850961538\n",
      "Train acc: 0.946814903846\n",
      "Loss: 0.296041\n",
      "epoch 182 \n",
      "Error rate: 0.0616987179487\n",
      "Train acc: 0.938301282051\n",
      "Loss: 0.314549\n",
      "epoch 183 \n",
      "Error rate: 0.0200320512821\n",
      "Train acc: 0.979967948718\n",
      "Loss: 0.221507\n",
      "epoch 184 \n",
      "Error rate: 0.072015224359\n",
      "Train acc: 0.927984775641\n",
      "Loss: 0.353848\n",
      "epoch 185 \n",
      "Error rate: 0.0194310897436\n",
      "Train acc: 0.980568910256\n",
      "Loss: 0.222662\n",
      "epoch 186 \n",
      "Error rate: 0.0456730769231\n",
      "Train acc: 0.954326923077\n",
      "Loss: 0.281066\n",
      "epoch 187 \n",
      "Error rate: 0.0366586538462\n",
      "Train acc: 0.963341346154\n",
      "Loss: 0.258995\n",
      "epoch 188 \n",
      "Error rate: 0.0370592948718\n",
      "Train acc: 0.962940705128\n",
      "Loss: 0.259256\n",
      "epoch 189 \n",
      "Error rate: 0.0405649038462\n",
      "Train acc: 0.959435096154\n",
      "Loss: 0.272056\n",
      "epoch 190 \n",
      "Error rate: 0.0544871794872\n",
      "Train acc: 0.945512820513\n",
      "Loss: 0.296246\n",
      "epoch 191 \n",
      "Error rate: 0.0274439102564\n",
      "Train acc: 0.972556089744\n",
      "Loss: 0.238231\n",
      "epoch 192 \n",
      "Error rate: 0.0418669871795\n",
      "Train acc: 0.958133012821\n",
      "Loss: 0.265395\n",
      "epoch 193 \n",
      "Error rate: 0.0101161858974\n",
      "Train acc: 0.989883814103\n",
      "Loss: 0.195676\n",
      "epoch 194 \n",
      "Error rate: 0.0322516025641\n",
      "Train acc: 0.967748397436\n",
      "Loss: 0.242497\n",
      "epoch 195 \n",
      "Error rate: 0.0161258012821\n",
      "Train acc: 0.983874198718\n",
      "Loss: 0.203056\n",
      "epoch 196 \n",
      "Error rate: 0.0237379807692\n",
      "Train acc: 0.976262019231\n",
      "Loss: 0.221174\n",
      "epoch 197 \n",
      "Error rate: 0.0109174679487\n",
      "Train acc: 0.989082532051\n",
      "Loss: 0.1903\n",
      "epoch 198 \n",
      "Error rate: 0.0572916666667\n",
      "Train acc: 0.942708333333\n",
      "Loss: 0.304253\n",
      "epoch 199 \n",
      "Error rate: 0.0143229166667\n",
      "Train acc: 0.985677083333\n",
      "Loss: 0.203224\n",
      "epoch 200 \n",
      "Error rate: 0.0266426282051\n",
      "Train acc: 0.973357371795\n",
      "Loss: 0.228718\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "deep_5_spatial = CNN_Spectral_Param(num_output=10, kernel_size=5, architecture='deep',\n",
    "                                    use_spectral_params=False)\n",
    "deep_5_spatial.train(xtrain, ytrain, batch_size=128, epochs=200)\n",
    "\n",
    "write_error_rate('deep_5_spatial', deep_5_spatial.error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches for training: 78\n",
      "epoch 1 \n",
      "Error rate: 0.867387820513\n",
      "Train acc: 0.132612179487\n",
      "Loss: 8.14792\n",
      "epoch 2 \n",
      "Error rate: 0.830128205128\n",
      "Train acc: 0.169871794872\n",
      "Loss: 2.45957\n",
      "epoch 3 \n",
      "Error rate: 0.802584134615\n",
      "Train acc: 0.197415865385\n",
      "Loss: 2.41944\n",
      "epoch 4 \n",
      "Error rate: 0.790264423077\n",
      "Train acc: 0.209735576923\n",
      "Loss: 2.40512\n",
      "epoch 5 \n",
      "Error rate: 0.769431089744\n",
      "Train acc: 0.230568910256\n",
      "Loss: 2.35663\n",
      "epoch 6 \n",
      "Error rate: 0.756310096154\n",
      "Train acc: 0.243689903846\n",
      "Loss: 2.32989\n",
      "epoch 7 \n",
      "Error rate: 0.717447916667\n",
      "Train acc: 0.282552083333\n",
      "Loss: 2.25747\n",
      "epoch 8 \n",
      "Error rate: 0.704727564103\n",
      "Train acc: 0.295272435897\n",
      "Loss: 2.18027\n",
      "epoch 9 \n",
      "Error rate: 0.658854166667\n",
      "Train acc: 0.341145833333\n",
      "Loss: 2.02711\n",
      "epoch 10 \n",
      "Error rate: 0.64202724359\n",
      "Train acc: 0.35797275641\n",
      "Loss: 1.99195\n",
      "epoch 11 \n",
      "Error rate: 0.602263621795\n",
      "Train acc: 0.397736378205\n",
      "Loss: 1.87752\n",
      "epoch 12 \n",
      "Error rate: 0.598157051282\n",
      "Train acc: 0.401842948718\n",
      "Loss: 1.8601\n",
      "epoch 13 \n",
      "Error rate: 0.552083333333\n",
      "Train acc: 0.447916666667\n",
      "Loss: 1.75453\n",
      "epoch 14 \n",
      "Error rate: 0.564102564103\n",
      "Train acc: 0.435897435897\n",
      "Loss: 1.77131\n",
      "epoch 15 \n",
      "Error rate: 0.522335737179\n",
      "Train acc: 0.477664262821\n",
      "Loss: 1.66424\n",
      "epoch 16 \n",
      "Error rate: 0.540665064103\n",
      "Train acc: 0.459334935897\n",
      "Loss: 1.69719\n",
      "epoch 17 \n",
      "Error rate: 0.491686698718\n",
      "Train acc: 0.508313301282\n",
      "Loss: 1.59055\n",
      "epoch 18 \n",
      "Error rate: 0.514322916667\n",
      "Train acc: 0.485677083333\n",
      "Loss: 1.6258\n",
      "epoch 19 \n",
      "Error rate: 0.462239583333\n",
      "Train acc: 0.537760416667\n",
      "Loss: 1.51776\n",
      "epoch 20 \n",
      "Error rate: 0.492688301282\n",
      "Train acc: 0.507311698718\n",
      "Loss: 1.57468\n",
      "epoch 21 \n",
      "Error rate: 0.439403044872\n",
      "Train acc: 0.560596955128\n",
      "Loss: 1.44918\n",
      "epoch 22 \n",
      "Error rate: 0.489883814103\n",
      "Train acc: 0.510116185897\n",
      "Loss: 1.57319\n",
      "epoch 23 \n",
      "Error rate: 0.417467948718\n",
      "Train acc: 0.582532051282\n",
      "Loss: 1.38078\n",
      "epoch 24 \n",
      "Error rate: 0.468449519231\n",
      "Train acc: 0.531550480769\n",
      "Loss: 1.50952\n",
      "epoch 25 \n",
      "Error rate: 0.395733173077\n",
      "Train acc: 0.604266826923\n",
      "Loss: 1.32495\n",
      "epoch 26 \n",
      "Error rate: 0.444310897436\n",
      "Train acc: 0.555689102564\n",
      "Loss: 1.44771\n",
      "epoch 27 \n",
      "Error rate: 0.373397435897\n",
      "Train acc: 0.626602564103\n",
      "Loss: 1.27139\n",
      "epoch 28 \n",
      "Error rate: 0.454727564103\n",
      "Train acc: 0.545272435897\n",
      "Loss: 1.45818\n",
      "epoch 29 \n",
      "Error rate: 0.437199519231\n",
      "Train acc: 0.562800480769\n",
      "Loss: 1.43017\n",
      "epoch 30 \n",
      "Error rate: 0.419971955128\n",
      "Train acc: 0.580028044872\n",
      "Loss: 1.36794\n",
      "epoch 31 \n",
      "Error rate: 0.420572916667\n",
      "Train acc: 0.579427083333\n",
      "Loss: 1.38356\n",
      "epoch 32 \n",
      "Error rate: 0.418970352564\n",
      "Train acc: 0.581029647436\n",
      "Loss: 1.36268\n",
      "epoch 33 \n",
      "Error rate: 0.402744391026\n",
      "Train acc: 0.597255608974\n",
      "Loss: 1.32199\n",
      "epoch 34 \n",
      "Error rate: 0.391225961538\n",
      "Train acc: 0.608774038462\n",
      "Loss: 1.30319\n",
      "epoch 35 \n",
      "Error rate: 0.368790064103\n",
      "Train acc: 0.631209935897\n",
      "Loss: 1.25082\n",
      "epoch 36 \n",
      "Error rate: 0.379206730769\n",
      "Train acc: 0.620793269231\n",
      "Loss: 1.26963\n",
      "epoch 37 \n",
      "Error rate: 0.330929487179\n",
      "Train acc: 0.669070512821\n",
      "Loss: 1.13056\n",
      "epoch 38 \n",
      "Error rate: 0.401943108974\n",
      "Train acc: 0.598056891026\n",
      "Loss: 1.32252\n",
      "epoch 39 \n",
      "Error rate: 0.359375\n",
      "Train acc: 0.640625\n",
      "Loss: 1.19885\n",
      "epoch 40 \n",
      "Error rate: 0.385616987179\n",
      "Train acc: 0.614383012821\n",
      "Loss: 1.25395\n",
      "epoch 41 \n",
      "Error rate: 0.336939102564\n",
      "Train acc: 0.663060897436\n",
      "Loss: 1.13769\n",
      "epoch 42 \n",
      "Error rate: 0.353966346154\n",
      "Train acc: 0.646033653846\n",
      "Loss: 1.19863\n",
      "epoch 43 \n",
      "Error rate: 0.319310897436\n",
      "Train acc: 0.680689102564\n",
      "Loss: 1.09909\n",
      "epoch 44 \n",
      "Error rate: 0.355268429487\n",
      "Train acc: 0.644731570513\n",
      "Loss: 1.19386\n",
      "epoch 45 \n",
      "Error rate: 0.296774839744\n",
      "Train acc: 0.703225160256\n",
      "Loss: 1.0493\n",
      "epoch 46 \n",
      "Error rate: 0.329026442308\n",
      "Train acc: 0.670973557692\n",
      "Loss: 1.11614\n",
      "epoch 47 \n",
      "Error rate: 0.27874599359\n",
      "Train acc: 0.72125400641\n",
      "Loss: 0.992497\n",
      "epoch 48 \n",
      "Error rate: 0.32281650641\n",
      "Train acc: 0.67718349359\n",
      "Loss: 1.10263\n",
      "epoch 49 \n",
      "Error rate: 0.310596955128\n",
      "Train acc: 0.689403044872\n",
      "Loss: 1.06965\n",
      "epoch 50 \n",
      "Error rate: 0.355769230769\n",
      "Train acc: 0.644230769231\n",
      "Loss: 1.18757\n",
      "epoch 51 \n",
      "Error rate: 0.270833333333\n",
      "Train acc: 0.729166666667\n",
      "Loss: 0.988184\n",
      "epoch 52 \n",
      "Error rate: 0.327724358974\n",
      "Train acc: 0.672275641026\n",
      "Loss: 1.10902\n",
      "epoch 53 \n",
      "Error rate: 0.2578125\n",
      "Train acc: 0.7421875\n",
      "Loss: 0.946042\n",
      "epoch 54 \n",
      "Error rate: 0.317207532051\n",
      "Train acc: 0.682792467949\n",
      "Loss: 1.08009\n",
      "epoch 55 \n",
      "Error rate: 0.264322916667\n",
      "Train acc: 0.735677083333\n",
      "Loss: 0.953454\n",
      "epoch 56 \n",
      "Error rate: 0.304487179487\n",
      "Train acc: 0.695512820513\n",
      "Loss: 1.04644\n",
      "epoch 57 \n",
      "Error rate: 0.244791666667\n",
      "Train acc: 0.755208333333\n",
      "Loss: 0.903455\n",
      "epoch 58 \n",
      "Error rate: 0.288461538462\n",
      "Train acc: 0.711538461538\n",
      "Loss: 1.01428\n",
      "epoch 59 \n",
      "Error rate: 0.238982371795\n",
      "Train acc: 0.761017628205\n",
      "Loss: 0.889313\n",
      "epoch 60 \n",
      "Error rate: 0.280448717949\n",
      "Train acc: 0.719551282051\n",
      "Loss: 0.987578\n",
      "epoch 61 \n",
      "Error rate: 0.21624599359\n",
      "Train acc: 0.78375400641\n",
      "Loss: 0.831965\n",
      "epoch 62 \n",
      "Error rate: 0.270232371795\n",
      "Train acc: 0.729767628205\n",
      "Loss: 0.96276\n",
      "epoch 63 \n",
      "Error rate: 0.203525641026\n",
      "Train acc: 0.796474358974\n",
      "Loss: 0.800954\n",
      "epoch 64 \n",
      "Error rate: 0.275340544872\n",
      "Train acc: 0.724659455128\n",
      "Loss: 0.975367\n",
      "epoch 65 \n",
      "Error rate: 0.228465544872\n",
      "Train acc: 0.771534455128\n",
      "Loss: 0.856824\n",
      "epoch 66 \n",
      "Error rate: 0.252904647436\n",
      "Train acc: 0.747095352564\n",
      "Loss: 0.917194\n",
      "epoch 67 \n",
      "Error rate: 0.204026442308\n",
      "Train acc: 0.795973557692\n",
      "Loss: 0.806112\n",
      "epoch 68 \n",
      "Error rate: 0.251602564103\n",
      "Train acc: 0.748397435897\n",
      "Loss: 0.904011\n",
      "epoch 69 \n",
      "Error rate: 0.199318910256\n",
      "Train acc: 0.800681089744\n",
      "Loss: 0.78101\n",
      "epoch 70 \n",
      "Error rate: 0.275340544872\n",
      "Train acc: 0.724659455128\n",
      "Loss: 0.968043\n",
      "epoch 71 \n",
      "Error rate: 0.18108974359\n",
      "Train acc: 0.81891025641\n",
      "Loss: 0.741259\n",
      "epoch 72 \n",
      "Error rate: 0.241887019231\n",
      "Train acc: 0.758112980769\n",
      "Loss: 0.884915\n",
      "epoch 73 \n",
      "Error rate: 0.186999198718\n",
      "Train acc: 0.813000801282\n",
      "Loss: 0.766854\n",
      "epoch 74 \n",
      "Error rate: 0.240384615385\n",
      "Train acc: 0.759615384615\n",
      "Loss: 0.886631\n",
      "epoch 75 \n",
      "Error rate: 0.155749198718\n",
      "Train acc: 0.844250801282\n",
      "Loss: 0.684454\n",
      "epoch 76 \n",
      "Error rate: 0.216346153846\n",
      "Train acc: 0.783653846154\n",
      "Loss: 0.820935\n",
      "epoch 77 \n",
      "Error rate: 0.156450320513\n",
      "Train acc: 0.843549679487\n",
      "Loss: 0.676398\n",
      "epoch 78 \n",
      "Error rate: 0.230669070513\n",
      "Train acc: 0.769330929487\n",
      "Loss: 0.847988\n",
      "epoch 79 \n",
      "Error rate: 0.172475961538\n",
      "Train acc: 0.827524038462\n",
      "Loss: 0.715741\n",
      "epoch 80 \n",
      "Error rate: 0.192007211538\n",
      "Train acc: 0.807992788462\n",
      "Loss: 0.765182\n",
      "epoch 81 \n",
      "Error rate: 0.154447115385\n",
      "Train acc: 0.845552884615\n",
      "Loss: 0.668451\n",
      "epoch 82 \n",
      "Error rate: 0.208333333333\n",
      "Train acc: 0.791666666667\n",
      "Loss: 0.789326\n",
      "epoch 83 \n",
      "Error rate: 0.132612179487\n",
      "Train acc: 0.867387820513\n",
      "Loss: 0.627026\n",
      "epoch 84 \n",
      "Error rate: 0.236478365385\n",
      "Train acc: 0.763521634615\n",
      "Loss: 0.85751\n",
      "epoch 85 \n",
      "Error rate: 0.156550480769\n",
      "Train acc: 0.843449519231\n",
      "Loss: 0.671371\n",
      "epoch 86 \n",
      "Error rate: 0.178084935897\n",
      "Train acc: 0.821915064103\n",
      "Loss: 0.717668\n",
      "epoch 87 \n",
      "Error rate: 0.120492788462\n",
      "Train acc: 0.879507211538\n",
      "Loss: 0.591437\n",
      "epoch 88 \n",
      "Error rate: 0.175080128205\n",
      "Train acc: 0.824919871795\n",
      "Loss: 0.71777\n",
      "epoch 89 \n",
      "Error rate: 0.115885416667\n",
      "Train acc: 0.884114583333\n",
      "Loss: 0.575987\n",
      "epoch 90 \n",
      "Error rate: 0.208233173077\n",
      "Train acc: 0.791766826923\n",
      "Loss: 0.789159\n",
      "epoch 91 \n",
      "Error rate: 0.100260416667\n",
      "Train acc: 0.899739583333\n",
      "Loss: 0.54182\n",
      "epoch 92 \n",
      "Error rate: 0.170673076923\n",
      "Train acc: 0.829326923077\n",
      "Loss: 0.701259\n",
      "epoch 93 \n",
      "Error rate: 0.0960536858974\n",
      "Train acc: 0.903946314103\n",
      "Loss: 0.524316\n",
      "epoch 94 \n",
      "Error rate: 0.196013621795\n",
      "Train acc: 0.803986378205\n",
      "Loss: 0.74869\n",
      "epoch 95 \n",
      "Error rate: 0.146534455128\n",
      "Train acc: 0.853465544872\n",
      "Loss: 0.637299\n",
      "epoch 96 \n",
      "Error rate: 0.154947916667\n",
      "Train acc: 0.845052083333\n",
      "Loss: 0.654302\n",
      "epoch 97 \n",
      "Error rate: 0.121294070513\n",
      "Train acc: 0.878705929487\n",
      "Loss: 0.576479\n",
      "epoch 98 \n",
      "Error rate: 0.176282051282\n",
      "Train acc: 0.823717948718\n",
      "Loss: 0.704109\n",
      "epoch 99 \n",
      "Error rate: 0.116386217949\n",
      "Train acc: 0.883613782051\n",
      "Loss: 0.560466\n",
      "epoch 100 \n",
      "Error rate: 0.126903044872\n",
      "Train acc: 0.873096955128\n",
      "Loss: 0.596019\n",
      "epoch 101 \n",
      "Error rate: 0.088141025641\n",
      "Train acc: 0.911858974359\n",
      "Loss: 0.500101\n",
      "epoch 102 \n",
      "Error rate: 0.153044871795\n",
      "Train acc: 0.846955128205\n",
      "Loss: 0.656071\n",
      "epoch 103 \n",
      "Error rate: 0.0723157051282\n",
      "Train acc: 0.927684294872\n",
      "Loss: 0.465574\n",
      "epoch 104 \n",
      "Error rate: 0.19671474359\n",
      "Train acc: 0.80328525641\n",
      "Loss: 0.732351\n",
      "epoch 105 \n",
      "Error rate: 0.0708133012821\n",
      "Train acc: 0.929186698718\n",
      "Loss: 0.455071\n",
      "epoch 106 \n",
      "Error rate: 0.141526442308\n",
      "Train acc: 0.858473557692\n",
      "Loss: 0.608532\n",
      "epoch 107 \n",
      "Error rate: 0.113381410256\n",
      "Train acc: 0.886618589744\n",
      "Loss: 0.549832\n",
      "epoch 108 \n",
      "Error rate: 0.167868589744\n",
      "Train acc: 0.832131410256\n",
      "Loss: 0.66853\n",
      "epoch 109 \n",
      "Error rate: 0.0547876602564\n",
      "Train acc: 0.945212339744\n",
      "Loss: 0.420655\n",
      "epoch 110 \n",
      "Error rate: 0.178585737179\n",
      "Train acc: 0.821414262821\n",
      "Loss: 0.687895\n",
      "epoch 111 \n",
      "Error rate: 0.0986578525641\n",
      "Train acc: 0.901342147436\n",
      "Loss: 0.513882\n",
      "epoch 112 \n",
      "Error rate: 0.119891826923\n",
      "Train acc: 0.880108173077\n",
      "Loss: 0.559068\n",
      "epoch 113 \n",
      "Error rate: 0.0549879807692\n",
      "Train acc: 0.945012019231\n",
      "Loss: 0.412946\n",
      "epoch 114 \n",
      "Error rate: 0.114983974359\n",
      "Train acc: 0.885016025641\n",
      "Loss: 0.551193\n",
      "epoch 115 \n",
      "Error rate: 0.0843349358974\n",
      "Train acc: 0.915665064103\n",
      "Loss: 0.477866\n",
      "epoch 116 \n",
      "Error rate: 0.145432692308\n",
      "Train acc: 0.854567307692\n",
      "Loss: 0.614075\n",
      "epoch 117 \n",
      "Error rate: 0.0787259615385\n",
      "Train acc: 0.921274038462\n",
      "Loss: 0.466723\n",
      "epoch 118 \n",
      "Error rate: 0.129206730769\n",
      "Train acc: 0.870793269231\n",
      "Loss: 0.580037\n",
      "epoch 119 \n",
      "Error rate: 0.0493790064103\n",
      "Train acc: 0.95062099359\n",
      "Loss: 0.396163\n",
      "epoch 120 \n",
      "Error rate: 0.134915865385\n",
      "Train acc: 0.865084134615\n",
      "Loss: 0.586908\n",
      "epoch 121 \n",
      "Error rate: 0.0382612179487\n",
      "Train acc: 0.961738782051\n",
      "Loss: 0.370609\n",
      "epoch 122 \n",
      "Error rate: 0.118489583333\n",
      "Train acc: 0.881510416667\n",
      "Loss: 0.550204\n",
      "epoch 123 \n",
      "Error rate: 0.0765224358974\n",
      "Train acc: 0.923477564103\n",
      "Loss: 0.45357\n",
      "epoch 124 \n",
      "Error rate: 0.115885416667\n",
      "Train acc: 0.884114583333\n",
      "Loss: 0.538809\n",
      "epoch 125 \n",
      "Error rate: 0.0361578525641\n",
      "Train acc: 0.963842147436\n",
      "Loss: 0.358367\n",
      "epoch 126 \n",
      "Error rate: 0.102063301282\n",
      "Train acc: 0.897936698718\n",
      "Loss: 0.505912\n",
      "epoch 127 \n",
      "Error rate: 0.0267427884615\n",
      "Train acc: 0.973257211538\n",
      "Loss: 0.334446\n",
      "epoch 128 \n",
      "Error rate: 0.0905448717949\n",
      "Train acc: 0.909455128205\n",
      "Loss: 0.485042\n",
      "epoch 129 \n",
      "Error rate: 0.0682091346154\n",
      "Train acc: 0.931790865385\n",
      "Loss: 0.427453\n",
      "epoch 130 \n",
      "Error rate: 0.104366987179\n",
      "Train acc: 0.895633012821\n",
      "Loss: 0.511609\n",
      "epoch 131 \n",
      "Error rate: 0.0474759615385\n",
      "Train acc: 0.952524038462\n",
      "Loss: 0.386098\n",
      "epoch 132 \n",
      "Error rate: 0.0879407051282\n",
      "Train acc: 0.912059294872\n",
      "Loss: 0.473124\n",
      "epoch 133 \n",
      "Error rate: 0.0432692307692\n",
      "Train acc: 0.956730769231\n",
      "Loss: 0.37431\n",
      "epoch 134 \n",
      "Error rate: 0.0782251602564\n",
      "Train acc: 0.921774839744\n",
      "Loss: 0.455546\n",
      "epoch 135 \n",
      "Error rate: 0.0386618589744\n",
      "Train acc: 0.961338141026\n",
      "Loss: 0.358406\n",
      "epoch 136 \n",
      "Error rate: 0.0827323717949\n",
      "Train acc: 0.917267628205\n",
      "Loss: 0.458972\n",
      "epoch 137 \n",
      "Error rate: 0.0320512820513\n",
      "Train acc: 0.967948717949\n",
      "Loss: 0.344278\n",
      "epoch 138 \n",
      "Error rate: 0.0670072115385\n",
      "Train acc: 0.932992788462\n",
      "Loss: 0.425189\n",
      "epoch 139 \n",
      "Error rate: 0.0236378205128\n",
      "Train acc: 0.976362179487\n",
      "Loss: 0.317183\n",
      "epoch 140 \n",
      "Error rate: 0.0666065705128\n",
      "Train acc: 0.933393429487\n",
      "Loss: 0.421397\n",
      "epoch 141 \n",
      "Error rate: 0.0216346153846\n",
      "Train acc: 0.978365384615\n",
      "Loss: 0.310193\n",
      "epoch 142 \n",
      "Error rate: 0.0583934294872\n",
      "Train acc: 0.941606570513\n",
      "Loss: 0.395967\n",
      "epoch 143 \n",
      "Error rate: 0.0205328525641\n",
      "Train acc: 0.979467147436\n",
      "Loss: 0.306299\n",
      "epoch 144 \n",
      "Error rate: 0.0616987179487\n",
      "Train acc: 0.938301282051\n",
      "Loss: 0.406122\n",
      "epoch 145 \n",
      "Error rate: 0.0150240384615\n",
      "Train acc: 0.984975961538\n",
      "Loss: 0.291863\n",
      "epoch 146 \n",
      "Error rate: 0.0933493589744\n",
      "Train acc: 0.906650641026\n",
      "Loss: 0.463173\n",
      "epoch 147 \n",
      "Error rate: 0.029547275641\n",
      "Train acc: 0.970452724359\n",
      "Loss: 0.320817\n",
      "epoch 148 \n",
      "Error rate: 0.0433693910256\n",
      "Train acc: 0.956630608974\n",
      "Loss: 0.3648\n",
      "epoch 149 \n",
      "Error rate: 0.0232371794872\n",
      "Train acc: 0.976762820513\n",
      "Loss: 0.298797\n",
      "epoch 150 \n",
      "Error rate: 0.0682091346154\n",
      "Train acc: 0.931790865385\n",
      "Loss: 0.407048\n",
      "epoch 151 \n",
      "Error rate: 0.0192307692308\n",
      "Train acc: 0.980769230769\n",
      "Loss: 0.294962\n",
      "epoch 152 \n",
      "Error rate: 0.0901442307692\n",
      "Train acc: 0.909855769231\n",
      "Loss: 0.456772\n",
      "epoch 153 \n",
      "Error rate: 0.0160256410256\n",
      "Train acc: 0.983974358974\n",
      "Loss: 0.287031\n",
      "epoch 154 \n",
      "Error rate: 0.0459735576923\n",
      "Train acc: 0.954026442308\n",
      "Loss: 0.362505\n",
      "epoch 155 \n",
      "Error rate: 0.0185296474359\n",
      "Train acc: 0.981470352564\n",
      "Loss: 0.284657\n",
      "epoch 156 \n",
      "Error rate: 0.0751201923077\n",
      "Train acc: 0.924879807692\n",
      "Loss: 0.413368\n",
      "epoch 157 \n",
      "Error rate: 0.00901442307692\n",
      "Train acc: 0.990985576923\n",
      "Loss: 0.263692\n",
      "epoch 158 \n",
      "Error rate: 0.0690104166667\n",
      "Train acc: 0.930989583333\n",
      "Loss: 0.403697\n",
      "epoch 159 \n",
      "Error rate: 0.0159254807692\n",
      "Train acc: 0.984074519231\n",
      "Loss: 0.279157\n",
      "epoch 160 \n",
      "Error rate: 0.0548878205128\n",
      "Train acc: 0.945112179487\n",
      "Loss: 0.374309\n",
      "epoch 161 \n",
      "Error rate: 0.00761217948718\n",
      "Train acc: 0.992387820513\n",
      "Loss: 0.256077\n",
      "epoch 162 \n",
      "Error rate: 0.0483774038462\n",
      "Train acc: 0.951622596154\n",
      "Loss: 0.359011\n",
      "epoch 163 \n",
      "Error rate: 0.00691105769231\n",
      "Train acc: 0.993088942308\n",
      "Loss: 0.248758\n",
      "epoch 164 \n",
      "Error rate: 0.0422676282051\n",
      "Train acc: 0.957732371795\n",
      "Loss: 0.339949\n",
      "epoch 165 \n",
      "Error rate: 0.00400641025641\n",
      "Train acc: 0.995993589744\n",
      "Loss: 0.238497\n",
      "epoch 166 \n",
      "Error rate: 0.0398637820513\n",
      "Train acc: 0.960136217949\n",
      "Loss: 0.338084\n",
      "epoch 167 \n",
      "Error rate: 0.00480769230769\n",
      "Train acc: 0.995192307692\n",
      "Loss: 0.234035\n",
      "epoch 168 \n",
      "Error rate: 0.0321514423077\n",
      "Train acc: 0.967848557692\n",
      "Loss: 0.321112\n",
      "epoch 169 \n",
      "Error rate: 0.0164262820513\n",
      "Train acc: 0.983573717949\n",
      "Loss: 0.266848\n",
      "epoch 170 \n",
      "Error rate: 0.0271434294872\n",
      "Train acc: 0.972856570513\n",
      "Loss: 0.310746\n",
      "epoch 171 \n",
      "Error rate: 0.00370592948718\n",
      "Train acc: 0.996294070513\n",
      "Loss: 0.230598\n",
      "epoch 172 \n",
      "Error rate: 0.0457732371795\n",
      "Train acc: 0.954226762821\n",
      "Loss: 0.340464\n",
      "epoch 173 \n",
      "Error rate: 0.0103165064103\n",
      "Train acc: 0.98968349359\n",
      "Loss: 0.251298\n",
      "epoch 174 \n",
      "Error rate: 0.0202323717949\n",
      "Train acc: 0.979767628205\n",
      "Loss: 0.287822\n",
      "epoch 175 \n",
      "Error rate: 0.00460737179487\n",
      "Train acc: 0.995392628205\n",
      "Loss: 0.230895\n",
      "epoch 176 \n",
      "Error rate: 0.021734775641\n",
      "Train acc: 0.978265224359\n",
      "Loss: 0.292903\n",
      "epoch 177 \n",
      "Error rate: 0.00610977564103\n",
      "Train acc: 0.993890224359\n",
      "Loss: 0.233665\n",
      "epoch 178 \n",
      "Error rate: 0.0526842948718\n",
      "Train acc: 0.947315705128\n",
      "Loss: 0.349409\n",
      "epoch 179 \n",
      "Error rate: 0.00921474358974\n",
      "Train acc: 0.99078525641\n",
      "Loss: 0.24055\n",
      "epoch 180 \n",
      "Error rate: 0.0147235576923\n",
      "Train acc: 0.985276442308\n",
      "Loss: 0.271861\n",
      "epoch 181 \n",
      "Error rate: 0.00280448717949\n",
      "Train acc: 0.997195512821\n",
      "Loss: 0.218095\n",
      "epoch 182 \n",
      "Error rate: 0.0154246794872\n",
      "Train acc: 0.984575320513\n",
      "Loss: 0.263276\n",
      "epoch 183 \n",
      "Error rate: 0.00230368589744\n",
      "Train acc: 0.997696314103\n",
      "Loss: 0.214859\n",
      "epoch 184 \n",
      "Error rate: 0.0343549679487\n",
      "Train acc: 0.965645032051\n",
      "Loss: 0.315732\n",
      "epoch 185 \n",
      "Error rate: 0.00330528846154\n",
      "Train acc: 0.996694711538\n",
      "Loss: 0.222848\n",
      "epoch 186 \n",
      "Error rate: 0.0306490384615\n",
      "Train acc: 0.969350961538\n",
      "Loss: 0.298001\n",
      "epoch 187 \n",
      "Error rate: 0.00140224358974\n",
      "Train acc: 0.99859775641\n",
      "Loss: 0.212688\n",
      "epoch 188 \n",
      "Error rate: 0.0168269230769\n",
      "Train acc: 0.983173076923\n",
      "Loss: 0.268345\n",
      "epoch 189 \n",
      "Error rate: 0.00110176282051\n",
      "Train acc: 0.998898237179\n",
      "Loss: 0.207046\n",
      "epoch 190 \n",
      "Error rate: 0.0174278846154\n",
      "Train acc: 0.982572115385\n",
      "Loss: 0.264724\n",
      "epoch 191 \n",
      "Error rate: 0.00380608974359\n",
      "Train acc: 0.996193910256\n",
      "Loss: 0.218386\n",
      "epoch 192 \n",
      "Error rate: 0.017327724359\n",
      "Train acc: 0.982672275641\n",
      "Loss: 0.267959\n",
      "epoch 193 \n",
      "Error rate: 0.00170272435897\n",
      "Train acc: 0.998297275641\n",
      "Loss: 0.209916\n",
      "epoch 194 \n",
      "Error rate: 0.0508814102564\n",
      "Train acc: 0.949118589744\n",
      "Loss: 0.33431\n",
      "epoch 195 \n",
      "Error rate: 0.00210336538462\n",
      "Train acc: 0.997896634615\n",
      "Loss: 0.208404\n",
      "epoch 196 \n",
      "Error rate: 0.00701121794872\n",
      "Train acc: 0.992988782051\n",
      "Loss: 0.237028\n",
      "epoch 197 \n",
      "Error rate: 0.000801282051282\n",
      "Train acc: 0.999198717949\n",
      "Loss: 0.198991\n",
      "epoch 198 \n",
      "Error rate: 0.0141225961538\n",
      "Train acc: 0.985877403846\n",
      "Loss: 0.246903\n",
      "epoch 199 \n",
      "Error rate: 0.000400641025641\n",
      "Train acc: 0.999599358974\n",
      "Loss: 0.196695\n",
      "epoch 200 \n",
      "Error rate: 0.0215344551282\n",
      "Train acc: 0.978465544872\n",
      "Loss: 0.276148\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "deep_5_spectral = CNN_Spectral_Param(num_output=10, kernel_size=5, architecture='deep',\n",
    "                                     use_spectral_params=True)\n",
    "deep_5_spectral.train(xtrain, ytrain, batch_size=128, epochs=200)\n",
    "\n",
    "write_error_rate('deep_5_spectral', deep_5_spectral.error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Pooling Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already downloaded..\n",
      "getting batch 1\n"
     ]
    }
   ],
   "source": [
    "# Just using 1 batch from CIFAR10 to save time (these models are extremely computationally intensive)\n",
    "xtrain_NCHW, ytrain_NCHW, xtest_NCHW, ytest_NCHW = load_cifar10(1, channels_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tf graph...\n",
      "Adding conv layer 1 | Input size: 32 | Input channels: 3 | #filters: 128 | filter size: 3\n",
      "Adding spectral pool layer 1 | Input size: 32 | filter size: (16,16) | Freq Dropout Bounds: (2.25,9.0)\n",
      "Adding conv layer 2 | Input size: 16 | Input channels: 128 | #filters: 160 | filter size: 3\n",
      "Adding spectral pool layer 2 | Input size: 16 | filter size: (8,8) | Freq Dropout Bounds: (1.0,5.0)\n",
      "Adding conv layer 3 | Input size: 8 | Input channels: 160 | #filters: 192 | filter size: 3\n",
      "Adding spectral pool layer 3 | Input size: 8 | filter size: (4,4) | Freq Dropout Bounds: (0.44999999999999996,3.0)\n",
      "Adding conv layer 4 | Input size: 4 | Input channels: 192 | #filters: 192 | filter size: 1\n",
      "Adding conv layer 5 | Input size: 4 | Input channels: 192 | #filters: 10 | filter size: 1\n",
      "Adding final softmax layer using global averaging\n",
      "(?, 10)\n",
      "number of batches for training: 78 validation: 78\n",
      "training epoch 1 \n",
      "training epoch 2 \n",
      "training epoch 3 \n",
      "training epoch 4 \n",
      "training epoch 5 \n",
      "training epoch 6 \n",
      "training epoch 7 \n",
      "training epoch 8 \n",
      "training epoch 9 \n",
      "training epoch 10 \n",
      "training epoch 11 \n",
      "training epoch 12 \n",
      "training epoch 13 \n",
      "training epoch 14 \n",
      "training epoch 15 \n",
      "training epoch 16 \n",
      "training epoch 17 \n",
      "training epoch 18 \n",
      "training epoch 19 \n",
      "training epoch 20 \n",
      "training epoch 21 \n",
      "training epoch 22 \n",
      "training epoch 23 \n",
      "training epoch 24 \n",
      "training epoch 25 \n",
      "training epoch 26 \n",
      "training epoch 27 \n",
      "training epoch 28 \n",
      "training epoch 29 \n",
      "training epoch 30 \n",
      "training epoch 31 \n",
      "training epoch 32 \n",
      "training epoch 33 \n",
      "training epoch 34 \n",
      "training epoch 35 \n",
      "training epoch 36 \n",
      "training epoch 37 \n",
      "training epoch 38 \n",
      "training epoch 39 \n",
      "training epoch 40 \n",
      "training epoch 41 \n",
      "training epoch 42 \n",
      "training epoch 43 \n",
      "training epoch 44 \n",
      "training epoch 45 \n",
      "training epoch 46 \n",
      "training epoch 47 \n",
      "training epoch 48 \n",
      "training epoch 49 \n",
      "training epoch 50 \n",
      "training epoch 51 \n",
      "training epoch 52 \n",
      "training epoch 53 \n",
      "training epoch 54 \n",
      "training epoch 55 \n",
      "training epoch 56 \n",
      "training epoch 57 \n",
      "training epoch 58 \n",
      "training epoch 59 \n",
      "training epoch 60 \n",
      "training epoch 61 \n",
      "training epoch 62 \n",
      "training epoch 63 \n",
      "training epoch 64 \n",
      "training epoch 65 \n",
      "training epoch 66 \n",
      "training epoch 67 \n",
      "training epoch 68 \n",
      "training epoch 69 \n",
      "training epoch 70 \n",
      "training epoch 71 \n",
      "training epoch 72 \n",
      "training epoch 73 \n",
      "training epoch 74 \n",
      "training epoch 75 \n",
      "training epoch 76 \n",
      "training epoch 77 \n",
      "training epoch 78 \n",
      "training epoch 79 \n",
      "training epoch 80 \n",
      "training epoch 81 \n",
      "training epoch 82 \n",
      "training epoch 83 \n",
      "training epoch 84 \n",
      "training epoch 85 \n",
      "training epoch 86 \n",
      "training epoch 87 \n",
      "training epoch 88 \n",
      "training epoch 89 \n",
      "training epoch 90 \n",
      "training epoch 91 \n",
      "training epoch 92 \n",
      "training epoch 93 \n",
      "training epoch 94 \n",
      "training epoch 95 \n",
      "training epoch 96 \n",
      "training epoch 97 \n",
      "training epoch 98 \n",
      "training epoch 99 \n",
      "training epoch 100 \n",
      "\tLearning rate reduced to 8.8000e-04 at epoch 100\n",
      "training epoch 101 \n",
      "training epoch 102 \n",
      "training epoch 103 \n",
      "training epoch 104 \n",
      "training epoch 105 \n",
      "training epoch 106 \n",
      "training epoch 107 \n",
      "training epoch 108 \n",
      "training epoch 109 \n",
      "training epoch 110 \n",
      "training epoch 111 \n",
      "training epoch 112 \n",
      "training epoch 113 \n",
      "training epoch 114 \n",
      "training epoch 115 \n",
      "training epoch 116 \n",
      "training epoch 117 \n",
      "training epoch 118 \n",
      "training epoch 119 \n",
      "training epoch 120 \n",
      "training epoch 121 \n",
      "training epoch 122 \n",
      "training epoch 123 \n",
      "training epoch 124 \n",
      "training epoch 125 \n",
      "training epoch 126 \n",
      "training epoch 127 \n",
      "training epoch 128 \n",
      "training epoch 129 \n",
      "training epoch 130 \n",
      "training epoch 131 \n",
      "training epoch 132 \n",
      "training epoch 133 \n",
      "training epoch 134 \n",
      "training epoch 135 \n",
      "training epoch 136 \n",
      "training epoch 137 \n",
      "training epoch 138 \n",
      "training epoch 139 \n",
      "training epoch 140 \n",
      "\tLearning rate reduced to 8.8000e-05 at epoch 140\n",
      "training epoch 141 \n",
      "training epoch 142 \n",
      "training epoch 143 \n",
      "training epoch 144 \n",
      "training epoch 145 \n",
      "training epoch 146 \n",
      "training epoch 147 \n",
      "training epoch 148 \n",
      "training epoch 149 \n",
      "training epoch 150 \n",
      "9984/10000 loss: 0.08562255650758743 | training accuracy: 99.740% | validation accuracy : 73.407%\n",
      "\n",
      "\tBest validation accuracy! iteration:11700 accuracy: 73.40745192307692%\n",
      "\n",
      "Best validation accuracy: 73.407%; Model name: 'test/test_1513546225.1058774'.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "spectral_pool_3_spectral = CNN_Spectral_Pool(M=3, gamma=.5, conv_filter_size=3,\n",
    "                                             use_spectral_parameterization=True, verbose=True)\n",
    "\n",
    "spectral_pool_3_spectral.train(xtrain_NCHW,\n",
    "                                ytrain_NCHW,\n",
    "                                xtest_NCHW,\n",
    "                                ytest_NCHW,\n",
    "                                batch_size=128,\n",
    "                                epochs=150,\n",
    "                                val_test_frq=150,\n",
    "                                extra_conv_layer=True,\n",
    "                                use_global_averaging=True)\n",
    "\n",
    "write_error_rate('spectral_pool_3_spectral', [(100 - acc) / 100 for acc in spectral_pool_3_spectral.train_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tf graph...\n",
      "Adding conv layer 1 | Input size: 32 | Input channels: 3 | #filters: 128 | filter size: 3\n",
      "Adding spectral pool layer 1 | Input size: 32 | filter size: (16,16) | Freq Dropout Bounds: (2.25,9.0)\n",
      "Adding conv layer 2 | Input size: 16 | Input channels: 128 | #filters: 160 | filter size: 3\n",
      "Adding spectral pool layer 2 | Input size: 16 | filter size: (8,8) | Freq Dropout Bounds: (1.0,5.0)\n",
      "Adding conv layer 3 | Input size: 8 | Input channels: 160 | #filters: 192 | filter size: 3\n",
      "Adding spectral pool layer 3 | Input size: 8 | filter size: (4,4) | Freq Dropout Bounds: (0.44999999999999996,3.0)\n",
      "Adding conv layer 4 | Input size: 4 | Input channels: 192 | #filters: 192 | filter size: 1\n",
      "Adding conv layer 5 | Input size: 4 | Input channels: 192 | #filters: 10 | filter size: 1\n",
      "Adding final softmax layer using global averaging\n",
      "(?, 10)\n",
      "number of batches for training: 78 validation: 78\n",
      "training epoch 1 \n",
      "training epoch 2 \n",
      "training epoch 3 \n",
      "training epoch 4 \n",
      "training epoch 5 \n",
      "training epoch 6 \n",
      "training epoch 7 \n",
      "training epoch 8 \n",
      "training epoch 9 \n",
      "training epoch 10 \n",
      "training epoch 11 \n",
      "training epoch 12 \n",
      "training epoch 13 \n",
      "training epoch 14 \n",
      "training epoch 15 \n",
      "training epoch 16 \n",
      "training epoch 17 \n",
      "training epoch 18 \n",
      "training epoch 19 \n",
      "training epoch 20 \n",
      "training epoch 21 \n",
      "training epoch 22 \n",
      "training epoch 23 \n",
      "training epoch 24 \n",
      "training epoch 25 \n",
      "training epoch 26 \n",
      "training epoch 27 \n",
      "training epoch 28 \n",
      "training epoch 29 \n",
      "training epoch 30 \n",
      "training epoch 31 \n",
      "training epoch 32 \n",
      "training epoch 33 \n",
      "training epoch 34 \n",
      "training epoch 35 \n",
      "training epoch 36 \n",
      "training epoch 37 \n",
      "training epoch 38 \n",
      "training epoch 39 \n",
      "training epoch 40 \n",
      "training epoch 41 \n",
      "training epoch 42 \n",
      "training epoch 43 \n",
      "training epoch 44 \n",
      "training epoch 45 \n",
      "training epoch 46 \n",
      "training epoch 47 \n",
      "training epoch 48 \n",
      "training epoch 49 \n",
      "training epoch 50 \n",
      "training epoch 51 \n",
      "training epoch 52 \n",
      "training epoch 53 \n",
      "training epoch 54 \n",
      "training epoch 55 \n",
      "training epoch 56 \n",
      "training epoch 57 \n",
      "training epoch 58 \n",
      "training epoch 59 \n",
      "training epoch 60 \n",
      "training epoch 61 \n",
      "training epoch 62 \n",
      "training epoch 63 \n",
      "training epoch 64 \n",
      "training epoch 65 \n",
      "training epoch 66 \n",
      "training epoch 67 \n",
      "training epoch 68 \n",
      "training epoch 69 \n",
      "training epoch 70 \n",
      "training epoch 71 \n",
      "training epoch 72 \n",
      "training epoch 73 \n",
      "training epoch 74 \n",
      "training epoch 75 \n",
      "training epoch 76 \n",
      "training epoch 77 \n",
      "training epoch 78 \n",
      "training epoch 79 \n",
      "training epoch 80 \n",
      "training epoch 81 \n",
      "training epoch 82 \n",
      "training epoch 83 \n",
      "training epoch 84 \n",
      "training epoch 85 \n",
      "training epoch 86 \n",
      "training epoch 87 \n",
      "training epoch 88 \n",
      "training epoch 89 \n",
      "training epoch 90 \n",
      "training epoch 91 \n",
      "training epoch 92 \n",
      "training epoch 93 \n",
      "training epoch 94 \n",
      "training epoch 95 \n",
      "training epoch 96 \n",
      "training epoch 97 \n",
      "training epoch 98 \n",
      "training epoch 99 \n",
      "training epoch 100 \n",
      "\tLearning rate reduced to 8.8000e-04 at epoch 100\n",
      "training epoch 101 \n",
      "training epoch 102 \n",
      "training epoch 103 \n",
      "training epoch 104 \n",
      "training epoch 105 \n",
      "training epoch 106 \n",
      "training epoch 107 \n",
      "training epoch 108 \n",
      "training epoch 109 \n",
      "training epoch 110 \n",
      "training epoch 111 \n",
      "training epoch 112 \n",
      "training epoch 113 \n",
      "training epoch 114 \n",
      "training epoch 115 \n",
      "training epoch 116 \n",
      "training epoch 117 \n",
      "training epoch 118 \n",
      "training epoch 119 \n",
      "training epoch 120 \n",
      "training epoch 121 \n",
      "training epoch 122 \n",
      "training epoch 123 \n",
      "training epoch 124 \n",
      "training epoch 125 \n",
      "training epoch 126 \n",
      "training epoch 127 \n",
      "training epoch 128 \n",
      "training epoch 129 \n",
      "training epoch 130 \n",
      "training epoch 131 \n",
      "training epoch 132 \n",
      "training epoch 133 \n",
      "training epoch 134 \n",
      "training epoch 135 \n",
      "training epoch 136 \n",
      "training epoch 137 \n",
      "training epoch 138 \n",
      "training epoch 139 \n",
      "training epoch 140 \n",
      "\tLearning rate reduced to 8.8000e-05 at epoch 140\n",
      "training epoch 141 \n",
      "training epoch 142 \n",
      "training epoch 143 \n",
      "training epoch 144 \n",
      "training epoch 145 \n",
      "training epoch 146 \n",
      "training epoch 147 \n",
      "training epoch 148 \n",
      "training epoch 149 \n",
      "training epoch 150 \n",
      "9984/10000 loss: 1.298862338066101 | training accuracy: 52.935% | validation accuracy : 50.050%\n",
      "\n",
      "\tBest validation accuracy! iteration:11700 accuracy: 50.050080128205124%\n",
      "\n",
      "Best validation accuracy: 50.050%; Model name: 'test/test_1513550280.1117535'.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "spectral_pool_3_spatial = CNN_Spectral_Pool(M=3, gamma=.5, conv_filter_size=3,\n",
    "                                             use_spectral_parameterization=False, verbose=True)\n",
    "\n",
    "spectral_pool_3_spatial.train(xtrain_NCHW,\n",
    "                              ytrain_NCHW,\n",
    "                              xtest_NCHW,\n",
    "                              ytest_NCHW,\n",
    "                              batch_size=128,\n",
    "                              epochs=150,\n",
    "                              val_test_frq=150,\n",
    "                              extra_conv_layer=True,\n",
    "                              use_global_averaging=True)\n",
    "\n",
    "write_error_rate('spectral_pool_3_spatial', [(100 - acc) / 100 for acc in spectral_pool_3_spatial.train_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tf graph...\n",
      "Adding conv layer 1 | Input size: 32 | Input channels: 3 | #filters: 128 | filter size: 5\n",
      "Adding spectral pool layer 1 | Input size: 32 | filter size: (16,16) | Freq Dropout Bounds: (2.25,9.0)\n",
      "Adding conv layer 2 | Input size: 16 | Input channels: 128 | #filters: 160 | filter size: 5\n",
      "Adding spectral pool layer 2 | Input size: 16 | filter size: (8,8) | Freq Dropout Bounds: (1.0,5.0)\n",
      "Adding conv layer 3 | Input size: 8 | Input channels: 160 | #filters: 192 | filter size: 5\n",
      "Adding spectral pool layer 3 | Input size: 8 | filter size: (4,4) | Freq Dropout Bounds: (0.44999999999999996,3.0)\n",
      "Adding conv layer 4 | Input size: 4 | Input channels: 192 | #filters: 192 | filter size: 1\n",
      "Adding conv layer 5 | Input size: 4 | Input channels: 192 | #filters: 10 | filter size: 1\n",
      "Adding final softmax layer using global averaging\n",
      "(?, 10)\n",
      "number of batches for training: 78 validation: 78\n",
      "training epoch 1 \n",
      "training epoch 2 \n",
      "training epoch 3 \n",
      "training epoch 4 \n",
      "training epoch 5 \n",
      "training epoch 6 \n",
      "training epoch 7 \n",
      "training epoch 8 \n",
      "training epoch 9 \n",
      "training epoch 10 \n",
      "training epoch 11 \n",
      "training epoch 12 \n",
      "training epoch 13 \n",
      "training epoch 14 \n",
      "training epoch 15 \n",
      "training epoch 16 \n",
      "training epoch 17 \n",
      "training epoch 18 \n",
      "training epoch 19 \n",
      "training epoch 20 \n",
      "training epoch 21 \n",
      "training epoch 22 \n",
      "training epoch 23 \n",
      "training epoch 24 \n",
      "training epoch 25 \n",
      "training epoch 26 \n",
      "training epoch 27 \n",
      "training epoch 28 \n",
      "training epoch 29 \n",
      "training epoch 30 \n",
      "training epoch 31 \n",
      "training epoch 32 \n",
      "training epoch 33 \n",
      "training epoch 34 \n",
      "training epoch 35 \n",
      "training epoch 36 \n",
      "training epoch 37 \n",
      "training epoch 38 \n",
      "training epoch 39 \n",
      "training epoch 40 \n",
      "training epoch 41 \n",
      "training epoch 42 \n",
      "training epoch 43 \n",
      "training epoch 44 \n",
      "training epoch 45 \n",
      "training epoch 46 \n",
      "training epoch 47 \n",
      "training epoch 48 \n",
      "training epoch 49 \n",
      "training epoch 50 \n",
      "training epoch 51 \n",
      "training epoch 52 \n",
      "training epoch 53 \n",
      "training epoch 54 \n",
      "training epoch 55 \n",
      "training epoch 56 \n",
      "training epoch 57 \n",
      "training epoch 58 \n",
      "training epoch 59 \n",
      "training epoch 60 \n",
      "training epoch 61 \n",
      "training epoch 62 \n",
      "training epoch 63 \n",
      "training epoch 64 \n",
      "training epoch 65 \n",
      "training epoch 66 \n",
      "training epoch 67 \n",
      "training epoch 68 \n",
      "training epoch 69 \n",
      "training epoch 70 \n",
      "training epoch 71 \n",
      "training epoch 72 \n",
      "training epoch 73 \n",
      "training epoch 74 \n",
      "training epoch 75 \n",
      "training epoch 76 \n",
      "training epoch 77 \n",
      "training epoch 78 \n",
      "training epoch 79 \n",
      "training epoch 80 \n",
      "training epoch 81 \n",
      "training epoch 82 \n",
      "training epoch 83 \n",
      "training epoch 84 \n",
      "training epoch 85 \n",
      "training epoch 86 \n",
      "training epoch 87 \n",
      "training epoch 88 \n",
      "training epoch 89 \n",
      "training epoch 90 \n",
      "training epoch 91 \n",
      "training epoch 92 \n",
      "training epoch 93 \n",
      "training epoch 94 \n",
      "training epoch 95 \n",
      "training epoch 96 \n",
      "training epoch 97 \n",
      "training epoch 98 \n",
      "training epoch 99 \n",
      "training epoch 100 \n",
      "\tLearning rate reduced to 8.8000e-04 at epoch 100\n",
      "training epoch 101 \n",
      "training epoch 102 \n",
      "training epoch 103 \n",
      "training epoch 104 \n",
      "training epoch 105 \n",
      "training epoch 106 \n",
      "training epoch 107 \n",
      "training epoch 108 \n",
      "training epoch 109 \n",
      "training epoch 110 \n",
      "training epoch 111 \n",
      "training epoch 112 \n",
      "training epoch 113 \n",
      "training epoch 114 \n",
      "training epoch 115 \n",
      "training epoch 116 \n",
      "training epoch 117 \n",
      "training epoch 118 \n",
      "training epoch 119 \n",
      "training epoch 120 \n",
      "training epoch 121 \n",
      "training epoch 122 \n",
      "training epoch 123 \n",
      "training epoch 124 \n",
      "training epoch 125 \n",
      "training epoch 126 \n",
      "training epoch 127 \n",
      "training epoch 128 \n",
      "training epoch 129 \n",
      "training epoch 130 \n",
      "training epoch 131 \n",
      "training epoch 132 \n",
      "training epoch 133 \n",
      "training epoch 134 \n",
      "training epoch 135 \n",
      "training epoch 136 \n",
      "training epoch 137 \n",
      "training epoch 138 \n",
      "training epoch 139 \n",
      "training epoch 140 \n",
      "\tLearning rate reduced to 8.8000e-05 at epoch 140\n",
      "training epoch 141 \n",
      "training epoch 142 \n",
      "training epoch 143 \n",
      "training epoch 144 \n",
      "training epoch 145 \n",
      "training epoch 146 \n",
      "training epoch 147 \n",
      "training epoch 148 \n",
      "training epoch 149 \n",
      "training epoch 150 \n",
      "9984/10000 loss: 0.1254291832447052 | training accuracy: 99.970% | validation accuracy : 70.463%\n",
      "\n",
      "\tBest validation accuracy! iteration:11700 accuracy: 70.46274038461539%\n",
      "\n",
      "Best validation accuracy: 70.463%; Model name: 'test/test_1513554307.859525'.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "spectral_pool_5_spectral = CNN_Spectral_Pool(M=3, gamma=.5, conv_filter_size=5,\n",
    "                                             use_spectral_parameterization=True, verbose=True)\n",
    "\n",
    "spectral_pool_5_spectral.train(xtrain_NCHW,\n",
    "                              ytrain_NCHW,\n",
    "                              xtest_NCHW,\n",
    "                              ytest_NCHW,\n",
    "                              batch_size=128,\n",
    "                              epochs=150,\n",
    "                              val_test_frq=150,\n",
    "                              extra_conv_layer=True,\n",
    "                              use_global_averaging=True)\n",
    "\n",
    "write_error_rate('spectral_pool_5_spectral', [(100 - acc) / 100 for acc in spectral_pool_5_spectral.train_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tf graph...\n",
      "Adding conv layer 1 | Input size: 32 | Input channels: 3 | #filters: 128 | filter size: 5\n",
      "Adding spectral pool layer 1 | Input size: 32 | filter size: (16,16) | Freq Dropout Bounds: (2.25,9.0)\n",
      "Adding conv layer 2 | Input size: 16 | Input channels: 128 | #filters: 160 | filter size: 5\n",
      "Adding spectral pool layer 2 | Input size: 16 | filter size: (8,8) | Freq Dropout Bounds: (1.0,5.0)\n",
      "Adding conv layer 3 | Input size: 8 | Input channels: 160 | #filters: 192 | filter size: 5\n",
      "Adding spectral pool layer 3 | Input size: 8 | filter size: (4,4) | Freq Dropout Bounds: (0.44999999999999996,3.0)\n",
      "Adding conv layer 4 | Input size: 4 | Input channels: 192 | #filters: 192 | filter size: 1\n",
      "Adding conv layer 5 | Input size: 4 | Input channels: 192 | #filters: 10 | filter size: 1\n",
      "Adding final softmax layer using global averaging\n",
      "(?, 10)\n",
      "number of batches for training: 78 validation: 78\n",
      "training epoch 1 \n",
      "training epoch 2 \n",
      "training epoch 3 \n",
      "training epoch 4 \n",
      "training epoch 5 \n",
      "training epoch 6 \n",
      "training epoch 7 \n",
      "training epoch 8 \n",
      "training epoch 9 \n",
      "training epoch 10 \n",
      "training epoch 11 \n",
      "training epoch 12 \n",
      "training epoch 13 \n",
      "training epoch 14 \n",
      "training epoch 15 \n",
      "training epoch 16 \n",
      "training epoch 17 \n",
      "training epoch 18 \n",
      "training epoch 19 \n",
      "training epoch 20 \n",
      "training epoch 21 \n",
      "training epoch 22 \n",
      "training epoch 23 \n",
      "training epoch 24 \n",
      "training epoch 25 \n",
      "training epoch 26 \n",
      "training epoch 27 \n",
      "training epoch 28 \n",
      "training epoch 29 \n",
      "training epoch 30 \n",
      "training epoch 31 \n",
      "training epoch 32 \n",
      "training epoch 33 \n",
      "training epoch 34 \n",
      "training epoch 35 \n",
      "training epoch 36 \n",
      "training epoch 37 \n",
      "training epoch 38 \n",
      "training epoch 39 \n",
      "training epoch 40 \n",
      "training epoch 41 \n",
      "training epoch 42 \n",
      "training epoch 43 \n",
      "training epoch 44 \n",
      "training epoch 45 \n",
      "training epoch 46 \n",
      "training epoch 47 \n",
      "training epoch 48 \n",
      "training epoch 49 \n",
      "training epoch 50 \n",
      "training epoch 51 \n",
      "training epoch 52 \n",
      "training epoch 53 \n",
      "training epoch 54 \n",
      "training epoch 55 \n",
      "training epoch 56 \n",
      "training epoch 57 \n",
      "training epoch 58 \n",
      "training epoch 59 \n",
      "training epoch 60 \n",
      "training epoch 61 \n",
      "training epoch 62 \n",
      "training epoch 63 \n",
      "training epoch 64 \n",
      "training epoch 65 \n",
      "training epoch 66 \n",
      "training epoch 67 \n",
      "training epoch 68 \n",
      "training epoch 69 \n",
      "training epoch 70 \n",
      "training epoch 71 \n",
      "training epoch 72 \n",
      "training epoch 73 \n",
      "training epoch 74 \n",
      "training epoch 75 \n",
      "training epoch 76 \n",
      "training epoch 77 \n",
      "training epoch 78 \n",
      "training epoch 79 \n",
      "training epoch 80 \n",
      "training epoch 81 \n",
      "training epoch 82 \n",
      "training epoch 83 \n",
      "training epoch 84 \n",
      "training epoch 85 \n",
      "training epoch 86 \n",
      "training epoch 87 \n",
      "training epoch 88 \n",
      "training epoch 89 \n",
      "training epoch 90 \n",
      "training epoch 91 \n",
      "training epoch 92 \n",
      "training epoch 93 \n",
      "training epoch 94 \n",
      "training epoch 95 \n",
      "training epoch 96 \n",
      "training epoch 97 \n",
      "training epoch 98 \n",
      "training epoch 99 \n",
      "training epoch 100 \n",
      "\tLearning rate reduced to 8.8000e-04 at epoch 100\n",
      "training epoch 101 \n",
      "training epoch 102 \n",
      "training epoch 103 \n",
      "training epoch 104 \n",
      "training epoch 105 \n",
      "training epoch 106 \n",
      "training epoch 107 \n",
      "training epoch 108 \n",
      "training epoch 109 \n",
      "training epoch 110 \n",
      "training epoch 111 \n",
      "training epoch 112 \n",
      "training epoch 113 \n",
      "training epoch 114 \n",
      "training epoch 115 \n",
      "training epoch 116 \n",
      "training epoch 117 \n",
      "training epoch 118 \n",
      "training epoch 119 \n",
      "training epoch 120 \n",
      "training epoch 121 \n",
      "training epoch 122 \n",
      "training epoch 123 \n",
      "training epoch 124 \n",
      "training epoch 125 \n",
      "training epoch 126 \n",
      "training epoch 127 \n",
      "training epoch 128 \n",
      "training epoch 129 \n",
      "training epoch 130 \n",
      "training epoch 131 \n",
      "training epoch 132 \n",
      "training epoch 133 \n",
      "training epoch 134 \n",
      "training epoch 135 \n",
      "training epoch 136 \n",
      "training epoch 137 \n",
      "training epoch 138 \n",
      "training epoch 139 \n",
      "training epoch 140 \n",
      "\tLearning rate reduced to 8.8000e-05 at epoch 140\n",
      "training epoch 141 \n",
      "training epoch 142 \n",
      "training epoch 143 \n",
      "training epoch 144 \n",
      "training epoch 145 \n",
      "training epoch 146 \n",
      "training epoch 147 \n",
      "training epoch 148 \n",
      "training epoch 149 \n",
      "training epoch 150 \n",
      "9984/10000 loss: 1.2048288583755493 | training accuracy: 57.762% | validation accuracy : 47.556%\n",
      "\n",
      "\tBest validation accuracy! iteration:11700 accuracy: 47.556089743589745%\n",
      "\n",
      "Best validation accuracy: 47.556%; Model name: 'test/test_1513558492.7173586'.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "spectral_pool_5_spatial = CNN_Spectral_Pool(M=3, gamma=.5, conv_filter_size=5,\n",
    "                                             use_spectral_parameterization=False, verbose=True)\n",
    "\n",
    "spectral_pool_5_spatial.train(xtrain_NCHW,\n",
    "                              ytrain_NCHW,\n",
    "                              xtest_NCHW,\n",
    "                              ytest_NCHW,\n",
    "                              batch_size=128,\n",
    "                              epochs=150,\n",
    "                              val_test_frq=150,\n",
    "                              extra_conv_layer=True,\n",
    "                              use_global_averaging=True)\n",
    "\n",
    "write_error_rate('spectral_pool_5_spatial', [(100 - acc) / 100 for acc in spectral_pool_5_spatial.train_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreate graph from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def read_error_rates(name):\n",
    "    error_rates = []\n",
    "    with open('error_rates/' + name + '.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            error_rates.append(float(line))\n",
    "            \n",
    "    return error_rates\n",
    "\n",
    "def get_smooth_curve(error_rates, epochs):    \n",
    "    def exp_func(x, a, b, c):\n",
    "        return a * np.exp(-b * x) + c\n",
    "    \n",
    "    popt, _ = curve_fit(exp_func, epochs, error_rates)\n",
    "    return exp_func(epochs, *popt)\n",
    "\n",
    "def find_intersection(smooth_curve, value):\n",
    "    return np.abs(smooth_curve-value).argmin() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/home/ecbm4040/miniconda2/envs/dlenv/lib/python3.5/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in multiply\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep 3 Speed Up: 5.40540540541\n",
      "Deep 5 Speed Up: 1.32450331126\n",
      "Spectral Pool 3 Speed Up: 18.75\n",
      "Spectral Pool 5 Speed Up: 16.6666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxwAAAHvCAYAAADentmWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x/2sGCbNS7FegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2816dbf6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "for ax_list in axes:\n",
    "    for ax in ax_list:\n",
    "        ax.set_ylim([0, .8])\n",
    "        \n",
    "spatial_patch = mpatches.Patch(color='red', label='Spatial')\n",
    "spectral_patch = mpatches.Patch(color='blue', label='Spectral')\n",
    "plt.legend(handles=[spatial_patch, spectral_patch])\n",
    "\n",
    "pad = 50\n",
    "axes[0,0].annotate('Size 5', xy=(0, .5), xytext=(-axes[0,0].yaxis.labelpad - pad, 0),\n",
    "                xycoords=axes[0,0].yaxis.label, textcoords='offset points',\n",
    "                size='large', ha='center', va='center')\n",
    "axes[1,0].annotate('Size 3', xy=(0, .5), xytext=(-axes[1,0].yaxis.labelpad - pad, 0),\n",
    "                xycoords=axes[1,0].yaxis.label, textcoords='offset points',\n",
    "                size='large', ha='center', va='center')\n",
    "\n",
    "axes[0,0].annotate('Deep', xy=(0.5, 1), xytext=(0, 5),\n",
    "                xycoords='axes fraction', textcoords='offset points',\n",
    "                size='large', ha='center', va='baseline')\n",
    "axes[0,1].annotate('Generic', xy=(0.5, 1), xytext=(0, 5),\n",
    "                xycoords='axes fraction', textcoords='offset points',\n",
    "                size='large', ha='center', va='baseline')\n",
    "axes[0,2].annotate('Spectral Pool', xy=(0.5, 1), xytext=(0, 5),\n",
    "                xycoords='axes fraction', textcoords='offset points',\n",
    "                size='large', ha='center', va='baseline')\n",
    "\n",
    "axes[0,0].set_ylabel('Error Rate')\n",
    "axes[1,0].set_ylabel('Error Rate')\n",
    "\n",
    "axes[1,0].set_xlabel('Epochs')\n",
    "axes[1,1].set_xlabel('Epochs')\n",
    "axes[1,2].set_xlabel('Epochs')\n",
    "\n",
    "epoch_200 = np.arange(200) + 1\n",
    "epoch_150 = np.arange(150) + 1\n",
    "\n",
    "# Generic Size 5\n",
    "smooth_generic_5_spectral = get_smooth_curve(read_error_rates('generic_5_spectral'), epoch_200)\n",
    "smooth_generic_5_spatial = get_smooth_curve(read_error_rates('generic_5_spatial'), epoch_200)\n",
    "\n",
    "axes[0,1].plot(epoch_200, smooth_generic_5_spectral, linewidth=2, color='blue', label='Spectral')\n",
    "axes[0,1].plot(epoch_200, smooth_generic_5_spatial, linewidth=2, color='red', label='Spatial')\n",
    "\n",
    "# Generic Size 3\n",
    "smooth_generic_3_spectral = get_smooth_curve(read_error_rates('generic_3_spectral'), epoch_200)\n",
    "smooth_generic_3_spatial = get_smooth_curve(read_error_rates('generic_3_spatial'), epoch_200)\n",
    "\n",
    "axes[1,1].plot(epoch_200, smooth_generic_3_spectral, linewidth=2, color='blue')\n",
    "axes[1,1].plot(epoch_200, smooth_generic_3_spatial, linewidth=2, color='red')\n",
    "\n",
    "# Deep Size 5\n",
    "smooth_deep_5_spectral = get_smooth_curve(read_error_rates('deep_5_spectral'), epoch_200)\n",
    "smooth_deep_5_spatial = get_smooth_curve(read_error_rates('deep_5_spatial'), epoch_200)\n",
    "\n",
    "deep_5_min = np.min(smooth_deep_5_spatial)\n",
    "deep_5_intersection = find_intersection(smooth_deep_5_spectral, deep_5_min)\n",
    "\n",
    "axes[0,0].plot(epoch_200, smooth_deep_5_spectral, linewidth=2, color='blue')\n",
    "axes[0,0].plot(epoch_200, smooth_deep_5_spatial, linewidth=2, color='red')\n",
    "axes[0,0].plot((1, 200), (deep_5_min, deep_5_min), color='black', linestyle='--')\n",
    "axes[0,0].scatter(200, deep_5_min, marker='o', s=75, c='black')\n",
    "axes[0,0].scatter(deep_5_intersection, deep_5_min, marker='o', s=75, c='black')\n",
    "\n",
    "# Deep Size 3\n",
    "smooth_deep_3_spectral = get_smooth_curve(read_error_rates('deep_3_spectral'), epoch_200)\n",
    "smooth_deep_3_spatial = get_smooth_curve(read_error_rates('deep_3_spatial'), epoch_200)\n",
    "\n",
    "deep_3_min = np.min(smooth_deep_3_spatial)\n",
    "deep_3_intersection = find_intersection(smooth_deep_3_spectral, deep_3_min)\n",
    "\n",
    "axes[1,0].plot(epoch_200, smooth_deep_3_spectral, linewidth=2, color='blue')\n",
    "axes[1,0].plot(epoch_200, smooth_deep_3_spatial, linewidth=2, color='red')\n",
    "axes[1,0].plot((1, 200), (deep_3_min, deep_3_min), color='black', linestyle='--')\n",
    "axes[1,0].scatter(200, deep_3_min, marker='o', s=75, c='black')\n",
    "axes[1,0].scatter(deep_3_intersection, deep_3_min, marker='o', s=75, c='black')\n",
    "\n",
    "# Spectral Pool Size 5\n",
    "smooth_sp_5_spectral = get_smooth_curve(read_error_rates('spectral_pool_5_spectral'), epoch_150)\n",
    "smooth_sp_5_spatial = get_smooth_curve(read_error_rates('spectral_pool_5_spatial'), epoch_150)\n",
    "\n",
    "sp_5_min = np.min(smooth_sp_5_spatial)\n",
    "sp_5_intersection = find_intersection(smooth_sp_5_spectral, sp_5_min)\n",
    "\n",
    "axes[0,2].plot(epoch_150, smooth_sp_5_spectral, linewidth=2, color='blue')\n",
    "axes[0,2].plot(epoch_150, smooth_sp_5_spatial, linewidth=2, color='red')\n",
    "axes[0,2].plot((1, 150), (sp_5_min, sp_5_min), color='black', linestyle='--')\n",
    "axes[0,2].scatter(150, sp_5_min, marker='o', s=75, c='black')\n",
    "axes[0,2].scatter(sp_5_intersection, sp_5_min, marker='o', s=75, c='black')\n",
    "\n",
    "# Spectral Pool Size 3\n",
    "smooth_sp_3_spectral = get_smooth_curve(read_error_rates('spectral_pool_3_spectral'), epoch_150)\n",
    "smooth_sp_3_spatial = get_smooth_curve(read_error_rates('spectral_pool_3_spatial'), epoch_150)\n",
    "\n",
    "sp_3_min = np.min(smooth_sp_3_spatial)\n",
    "sp_3_intersection = find_intersection(smooth_sp_3_spectral, sp_3_min)\n",
    "\n",
    "axes[1,2].plot(epoch_150, smooth_sp_3_spectral, linewidth=2, color='blue')\n",
    "axes[1,2].plot(epoch_150, smooth_sp_3_spatial, linewidth=2, color='red')\n",
    "axes[1,2].plot((1, 150), (sp_3_min, sp_3_min), color='black', linestyle='--')\n",
    "axes[1,2].scatter(150, sp_3_min, marker='o', s=75, c='black')\n",
    "axes[1,2].scatter(sp_3_intersection, sp_3_min, marker='o', s=75, c='black')\n",
    "\n",
    "print('Deep 3 Speed Up:', 200 / deep_3_intersection)\n",
    "print('Deep 5 Speed Up:', 200 / deep_5_intersection)\n",
    "print('Spectral Pool 3 Speed Up:', 150 / sp_3_intersection)\n",
    "print('Spectral Pool 5 Speed Up:', 150 / sp_5_intersection)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
